[{"id":0,"href":"/docs/background/","title":"Background","section":"Docs","content":"Select a background topic from the menu.\n"},{"id":1,"href":"/docs/background/poly-iop/","title":"Poly Iop","section":"Background","content":" Notes on Polynomial Interactive Oracle Proofs (Draft) # Definitions # Definition 1 (Polynomial Commitment Scheme). A polynomial commitment scheme (PCS) is an interactive proof system that enables $\\mathcal{P}$ to convince $\\mathcal{V}$ that he knows a polynomial, without revealing the polynomial directly. $\\mathcal{P}$ and $\\mathcal{V}$ run the protocol in three moves: gen, com, and open. [Plonk]\nDefinition 2 (Polynomial IOP). Let $\\mathcal{R}$ be a set of the relations among polynomials $\\{P_i\\}$. Let $\\mathcal{C}_f$ is the commitment to $f$. Given common input $\\mathcal{R}(\\{P_i\\})$ to $\\mathcal{P}$ and $\\mathcal{V}$, and private input $\\{P_i\\}$ to $\\mathcal{P}$, they run the following protocol:\n$\\mathcal{P}$ converts the relations into polynomials $\\{Q_j\\}$ $\\mathcal{P}$ commits to $\\{P_i\\}$ and $\\{Q_j\\}$, and sends the commitments to $\\mathcal{V}$ $\\mathcal{V}$ sends a random challenge $\\xi$ $\\mathcal{P}$ runs open for $\\{P_i(\\xi)\\}$ and $\\{Q_j(\\xi)\\}$ and outputs the result $\\mathcal{V}$ checks: the evaluations of $P_i(\\xi)$ and $Q_j(\\xi)$ are correct $\\{Q_j\\}$ satisfy $\\mathcal{R}(\\{P_i\\})$ At the end of the protocol, $\\mathcal{V}$ outputs $\\textbf{acc}$ if and only if the two conditions hold, otherwise $\\textbf{rej}$.\nMoreover, a Poly-IOP has to satisfy the following properties.\nDefinition 3 (Completeness). If each pair of $(\\mathcal{C}_{P_i},P_i)$ and $(\\mathcal{C}_{Q_j},Q_j)$ is valid and $\\{Q_j\\}$ satisfy $\\mathcal{R}(\\{P_i\\})$, $\\text{Pr}[out_{\\mathcal{V}}=\\textbf{acc}]=1$.\nDefinition 4 (Soundness). If $(\\mathcal{C}_{P_i},P_i)$ or $(\\mathcal{C}_{Q_j},Q_j)$ are not a valid pair, or $\\{Q_j\\}$ does not satisfy $\\mathcal{R}(\\{P_i\\})$, $\\text{Pr}[out_{\\mathcal{V}}=\\textbf{rej}]\\ge{1-\\text{negl}(k)}$.\nDefinition 5 (Zero Knowledge). For every possible set of relations $\\mathcal{R}$, there exists a probabilistic polynomial time simulator $\\mathcal{S}$ that can produce $\\{\\mathcal{C}_{P_i}^*\\},\\{\\mathcal{C}_{Q_i}^*\\}$ and the corresponding proofs making $\\mathcal{V}$ output $\\textbf{acc}$; the proofs generated by $\\mathcal{S}$ are computationally indistinguishable from those produced by $\\mathcal{P}$.\nEncoding Arrays of Data into Polynomials # Data starts as a array of integers where integers in each slot are between 0 and $q-1$, where $q$ is a large (generally 256 bit) prime number. Recall that we call this set of integers $\\mathbb{Z}_q$.\n$\\mathsf{data}_0$ $\\mathsf{data}_1$ $\\mathsf{data}_2$ $\\mathsf{data}_3$ $\\mathsf{data}_4$ It is common to denote a polynomial like $P(X)$ where $X$ is the variable of the polynomial. We are going denote the variable with an empty box $\\square$ which can be interpreted as a place where you can put any integer in $\\mathbb{Z}_q$ you want evaluated (or equivalent, where you place an x-coordinate to learn what the y-coordinate is).\nA polynomial in this notation looks like:\n$P(\\square)=c_0+c_1\\cdot\\square+c_2\\cdot\\square^2+c_3\\cdot\\square^3+c_4\\cdot\\square^4=\\sum_{i=0}^d c_i\\cdot\\square^i$ The values $c_i$ are called coefficients. Different arrays of data will (depending on how data is encoded, next) result in different coefficients and thus different polynomials. The degree of the polynomial is the largest exponent. So the polynomial above has degree 4 and thus will have 5 coefficients and 5 terms of the form $c_i\\cdot\\square^i$ (including $i=0$). Sometimes the coefficient will be zero: the term is thus not written down but in a list of coefficients, it will be included as a 0.\nThe main question to tackle is how to \u0026ldquo;encode\u0026rdquo; a array of integers into a polynomial. This is generally done one of three ways:\nCoefficients Evaluation Points Roots Each has its advantages and disadvantages, which we discuss next.\nFast forwarding a bit, once the polynomial is created, it is not shared directly with anyone. Instead a commitment to it is shared. The commitment does two things: (1) it makes it succinct: e.g., constant size regardless of how long the array is; and (2) it can hide the data in the array as necessary. We will discuss one specific polynomial commitment scheme called KZG. KZG needs the polynomial in the format of a list of its coefficients. If we have the polynomial in a different form, we will have to convert to coefficients. Thus this needs to be considered when weighing the pros/cons of the three encoding methods.\nEncoding 1: Coefficients # Create polynomial as: $P_1(\\square)=\\mathsf{data}_0+\\square+\\mathsf{data}_2\\cdot\\square^2+\\mathsf{data}_3\\cdot\\square^3+\\mathsf{data}_4\\cdot\\square^4=\\sum_{i=0}^d \\mathsf{data}_i\\cdot\\square^i$\nProperties:\nFast üëç: fastest path to commitment as the output is already in coefficient form. Addition üëç: two arrays can be added together (slot-by-slot) by simply adding the polynomials together Multiplication üëé: no support for multiplication of arrays (Remark: multiplying the polynomials does not multiply the coefficients. It results in a cross multiplication of every term in the first polynomial with every term in the second polynomial. Further the degree of the resulting polynomial will double that of the starting polynomials). Opening ü§∑üèª: proving the value of the $i$th element in the array is $\\mathsf{data}_i$ doing polynomial math on $P_1(\\square)$ is not possible. However $\\Sigma$-protocols done directly on KZG may enable this kind of proof. In any case, this is not particularly well explored. Other useful properties üëç: the sum of all values in a array can be computed by evaluating the polynomial at $P_1(\\boxed{1})$! $\\sum_{i=0}^d \\mathsf{data}_i\\cdot\\boxed{1}^i=\\sum_{i=0}^d \\mathsf{data}_i$ . You can also show two arrays have the same sum (called a \u0026ldquo;sum check\u0026rdquo;) by subtracting them and showing $P(\\boxed{1})=0$. Other useful properties üëç: when all coefficients are 0, the polynomial will be the zero polynomial ($P_1(\\square)=0$). Coefficients can be entire polynomials, not just integers. A common optimization in Poly-IOP systems is taking a set of equations of polynomials that should equal 0, placing each into the coefficient of a super-polynomial, and showing the super-polynomial is the zero polynomial (which can be proven overwhelmingly by showing it is 0 at a randomly selected point). Encoding 2: Evaluation Points # Create a list of points $\\{x,y\\}$ for the data: $\\langle\\{0,\\mathsf{data}_0\\},\\{1,\\mathsf{data}_1\\},\\{2,\\mathsf{data}_2\\},\\{3,\\mathsf{data}_3\\},\\{4,\\mathsf{data}_4\\}\\rangle$ and interpolate a polynomial $P_2(\\square)$ through these points.\nProperties:\nSlow (or moderate) üëé: converting a set of points into a set of coefficients is called interpolation and is $O(n^2)$ time generally. A certain optimization allows $O(n\\log n)$ time by chosing $x$ coordinates with a mathematical relationship (more on this later). Addition üëç: two arrays can be added together (slot-by-slot) by simply adding the polynomials together Multiplication üëç: two arrays can be multiplied together (slot-by-slot) by simply multiplying the polynomials together Opening üëç: proving the value of the $i$th element in the array is $\\mathsf{data}_i$ is possible with polynomial math by showing $P_2(\\boxed{i})=\\mathsf{data}_i$ and KZG has a precise algorithm for this. Encoding 3: Roots # Create polynomial as: $P_3(\\square)=(\\square-\\mathsf{data}_0)(\\square-\\mathsf{data}_1)(\\square-\\mathsf{data}_2)(\\square-\\mathsf{data}_3)(\\square-\\mathsf{data}_4)$\nAlternatively, create a list of roots $\\{x,0\\}$ for the data: $\\langle\\{\\mathsf{data}_0,0\\},\\{\\mathsf{data}_1,0\\},\\{\\mathsf{data}_2,0\\},\\{\\mathsf{data}_3,0\\},\\{\\mathsf{data}_4,0\\}\\rangle$ and interpolate a polynomial $P_3(\\square)$ through these points.\nProperties:\nSlow üëé (or moderate): multiplying out naively requires $O(n^2)$ time. Treating as a set of points and interpolating also requires $O(n^2)$ time (because the x-coordinates are the data, they cannot be chosen freely to optimize interpolation). Applying divide and conquer can provide $O(n \\log^2 n)$.^[1] Addition üëé: two arrays cannot be added from adding (or otherwise manipulating) the polynomials. Multiplication üëé: two arrays cannot be multiplied from multiplying (or otherwise manipulating) the polynomials (but you can do a \u0026ldquo;union\u0026rdquo; operation below). Opening üëç: proving that a value is in the array somewhere is easy and KZG as a precise algorithm for this (opening a root is the same as opening a point, where the y-coordinate is 0). However you cannot show a value is specifically the $i$th value in the array because the polynomial loses the order of the data in the array (see next property). Other useful properties üëç: the order of the data in the array does not matter. The same polynomial will be produced even if the order is changed. This is useful when the array represents a \u0026ldquo;bag\u0026rdquo; of unordered data. You can easily prove two \u0026ldquo;bags\u0026rdquo; of data are the same because the polynomials will be the same. One use-case of this is proving the output of a shuffle/permutation is the same data as the input (just in a different order). Other useful properties üëç: multiplying two polynomials results in a concatenation of the data in the arrays (or conjunction/union of the data in both bags). This might be useful in some protocols. ^[1]: Hat tip Pratyush Mishra.\nDecision Tree for Encoding # Basically we decide if we specifically need unordered \u0026ldquo;bags\u0026rdquo; of data. If so, encoding as roots is the only option. If not, we consider if we need to ever get the data back from the polynomial. Generally we do and encoding as evaluation points is the most common encoding technique. When do we encode the data and never want it back? Usually when (1) the coefficients are all supposed to be zero so we are just showing that property, or (2) we want back the sum of the data and not the data itself. In these cases, you can still work with evaluation point encoding but it will be faster to just do coefficient encoding.\nflowchart LR; A[Array to Polynomial] --\u003e B{Is the data unordered?}; B -- Unordered --\u003e C[Roots]; B -- Ordered or don't care --\u003e D{Open data from polynomial later?}; D -- Yes --\u003e E[Evaluation Points]; D -- No --\u003e F[Coefficients]; The short answer is to start with evaluation point encoding until you realize you need something different.\nOptimizing Interpolation (Roots of Unity + FFT) # Moving forward, we will assume we are using Encoding 2: Evaluation Points. In short, this means placing the elements of our array into the $y$-coordinates ($\\mathsf{data}_i=P(\\boxed{x_i})$) of points on the polynomial. Before commiting to $P(\\square)$, we need to use interpolation to find the coefficients of the polynomial that is fitted to these points. General interpolation algorithms are $O(n^2)$ work for $n$ evaluation points but this can be reduced to $O(n\\log n)$ with an optimization.\nThe optimization we will explore enables interpolation via the fast Fourier transform (FFT). It concerns how to choose the $x$-coordinates, which will serve as the index for accessing the data: evaluating $P(X)$ at $x_i$ will reveal $\\mathsf{data}_i$. First note, $x$-coordinates are from the exponent group ($Z_q$) and the choices exceed what is feasible to use ($2^{255}$ values in bls). Any subset can be used and interpolated. The optimization is to chose them with a mathematical structure. Specifically, instead an additive sequence (e.g., $0,1,2,3,\\ldots$), we use a multiplicative sequence $1,\\omega,\\omega\\cdot\\omega,\\omega\\cdot\\omega\\cdot\\omega,\\ldots$ or equivalently: $\\omega^0,\\omega^1,\\omega^2,\\ldots,\\omega^{\\kappa-1}$. Further, the sequence is closed under multiplication which means that next index after $\\omega^{\\kappa-1}$ wraps back to the first index: $\\omega^{k-1} \\cdot \\omega = \\omega^\\kappa = \\omega^0=1$ (this property is also useful in proving relationships between data in the array and its neighbouring values).\nFor terminology, we say $\\omega$ is a generator with multiplicative order $\\kappa$ in $\\mathbb{Z}_q$ (or $\\omega \\in \\mathbb{G}_\\kappa$). This implies $\\omega^\\kappa=1$. Rearranging, $\\omega=\\sqrt[\\kappa]{1}$. Thus we can equivalently describe $\\omega$ as a $\\kappa$-th root of 1. Finally, as 1 is the unity element in $Z_q$, $\\omega$ is commonly called a $\\kappa$-th root of unity.\nFor practical purposes, $\\kappa$ represents the length of the longest array of data we can use in our protocol. Where does $\\kappa$ come from? Different elements of $Z_q$ will have different multiplicative orders but every order must be a divisor of $q-1$. Thus $\\kappa$ is the largest divisor of the exact value of $q$ used in an elliptic curve standard. BLS12-384 has $\\kappa=2^{32}$ (for terminology, this called a $2$-adicity of $32$). In summary, we can only encode data arrays of length up to $2^{32}=4,294,967,296$.\nZeroing Parts of an Array # Assuming an input array of size $n$: $\\langle \\mathsf{data}_0,\\mathsf{data}_1,\\ldots,\\mathsf{data}_{n-1}\\rangle$ and input array encoded into the polynomial. This uses \u0026ldquo;Encoding 2\u0026rdquo; from above (evaluation points) and uses \u0026ldquo;Roots of Unity + FFT\u0026rdquo; from above where $\\omega\\in\\mathbb{G}_\\kappa$ is a generator for the x-coordinates of the points.\n$\\bot$ is an arbitrary non-zero integer.\nOperation Input Array Input Polynomial Output Array Output Polynomial Zero all $\\langle 3,1,3,3,7 \\rangle$ $P(X)$ $\\langle 0,0,0,0,0 \\rangle$ $P(X)\\cdot(X^n-1)$ Zero first $\\langle 3,1,3,3,7 \\rangle$ $P(X)$ $\\langle 0,\\bot,\\bot,\\bot,\\bot \\rangle$ $P(X)\\cdot(X-\\omega^0)$ Zero last $\\langle 3,1,3,3,7 \\rangle$ $P(X)$ $\\langle \\bot,\\bot,\\bot,\\bot,0 \\rangle$ $P(X)\\cdot(X-\\omega^{n-1})$ Zero all but first $\\langle 3,1,3,3,7 \\rangle$ $P(X)$ $\\langle \\bot,0,0,0,0 \\rangle$ $P(X)\\cdot\\frac{(X^n-1)}{(X-\\omega^0)}$ Zero all but last $\\langle 3,1,3,3,7 \\rangle$ $P(X)$ $\\langle 0,0,0,0,\\bot \\rangle$ $P(X)\\cdot\\frac{(X^n-1)}{(X-\\omega^{n-1})}$ Why are these useful? Consider a range proof from Boneh, Fisch, Gabizon, and Williamson. At a certain point in the protocol, we reach the following:\nFirst note that $w$ and $\\omega$ look the same but are different: $w$ are three new polynomials we are creating, while $\\omega$ is the generator of $\\mathbb{G}_\\kappa$ we are using to pick x-coordinates for the polynomials.\nIn the first constraint, we want to prove the value of f(1) and g(1) are the same. So we subtract (g-f) which leaves a zero in the first element of the array but the rest of the array will contain other stuff. By applying \u0026ldquo;zero all but first\u0026rdquo;, we can zero out the rest of the array. We now have an array that is all zero (in polynomial form, this is called a vanshing polynomial and we can prove a polynomial vanishes easily and in a batch). In the second constraint, we prove the last element in g is a binary bit (0 or 1) and then we apply the \u0026ldquo;zero all but last\u0026rdquo; to make an array that is all zero (and vanishing polynomial). In the third constraint, the first two terms of the multiplication are proving $g(X)$ has a certain form that does not need to be understood here. What is important is that there is a relationship between each integer in the array ($g(X)$) and the integer right beside it ($g(X\\omega)$) in the array. When the relationship holds, the result is a zero in $w_3$. Unfortunately, there is a corner case: for the last element in the array, the \u0026ldquo;next\u0026rdquo; integer wraps back to the first integer and the relationship does not hold across this boundary. So we use \u0026ldquo;zero last\u0026rdquo; to manually zero out the last integer in the array, leaving us with a zero array (and vanishing polynomial). Additional Text to Merge # The prover interpolates $A$ and $B$ to get $P_A(x)$ and $P_B(x)$. To do so, an $n$th root of unity (which we will call $\\omega$) is used, and the values of $A$ and $B$ are paired with the powers of this root of unity as follows: $(\\omega^0, a_0), (\\omega^1, a_1), \\dots, (\\omega^{n-1}, a_{n-1})$ and similarly for $B$. Then the interpolation (using the fast fourier transform (FFT)) creates a polynomial that passes through the points represented by these tuples. We also define $H$ as the set $[\\omega^0, \\omega^1, \\dots, \\omega^{n-1}]$. We are assuming that $n$ is a power of 2, so that we can use FFT. In practice, if it is not, then a power of 2 greater than $n$, say $2^m$, is used and the last $2^m - n$ entries of $A$ are padded with 1s.\n"},{"id":2,"href":"/docs/gadgets/","title":"Gadgets","section":"Docs","content":"Select a gadget from the menu.\n"},{"id":3,"href":"/docs/gadgets/add1/","title":"Add1","section":"Gadgets","content":" Addition (Type 1) # Recap of types # Type Description Recap This add1 $\\mathsf{Arr}_3=\\mathsf{Arr}_1 + \\mathsf{Arr}_2$ $\\mathsf{Arr}_3$ is the element-wise addition of $\\mathsf{Arr}_1$ and $\\mathsf{Arr}_2$. ‚úÖ add2 $\\mathsf{Sum}_\\mathsf{Arr}=\\sum_{i = 0}^{n-1} \\mathsf{Arr}[i]$ $\\mathsf{Sum}_\\mathsf{Arr}$ is the disclosed sum of all the elements in $\\mathsf{Arr}$. add3 $\\sum_{i = 0}^{n-1} \\mathsf{Arr}_1[i]=\\sum_{i = 0}^{n-1} \\mathsf{Arr}_2[i]$ $\\mathsf{Arr}_1$ and $\\mathsf{Arr}_2$ have the same undisclosed sum. Relation # $ \\mathcal{R}_{\\mathtt{add1}} := \\left\\{ \\begin{array}{l} (K_\\mathsf{Arr_1},K_\\mathsf{Arr_2},K_\\mathsf{Arr_3}) \\end{array} \\middle | \\begin{array}{l} \\mathsf{Arr_3}[i]=\\mathsf{Arr_1}[i]+\\mathsf{Arr_2}[i], 0\\leq i \\leq n, \\\\ \\mathsf{Poly}_\\mathsf{Arr_j}=\\mathsf{FFT.Interp}(\\omega,\\mathsf{Arr_j}), 1\\leq j \\leq 3, \\\\ K_\\mathsf{Arr_j}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr_j}), 1\\leq j \\leq 3, \\end{array} \\right\\} $\nIntuition # The prover ($\\mathcal{P}$) holds two arrays $\\mathsf{Arr_1}$ and $\\mathsf{Arr_2}$ of $n$ integers from $\\mathbb{Z}_q$: $[a_0, a_1, a_2, \\dots, a_{n-1}]$. It will produce a succinct (independent of $n$) proof that $\\mathsf{Arr_3}$ is the element-wise sum of all the elements in the array: $\\mathsf{Arr_3}[i]=\\mathsf{Arr_1}[i]+\\mathsf{Arr_2}[i]$. The prover will encode the three arrays into three polynomials: $\\mathsf{Poly}_\\mathsf{Arr_1}$, $\\mathsf{Poly}_\\mathsf{Arr_2}$, and $\\mathsf{Poly}_\\mathsf{Arr_3}$ (using evaluation points on the domain $\\mathcal{H}_\\kappa$). It will commit to each polynomial: $K_\\mathsf{Arr_1}$,$K_\\mathsf{Arr_2}$, and $K_\\mathsf{Arr_3}$. The verifier ($\\mathcal{V}$) cannot check any of the $\\mathsf{Arr_i}$ or $\\mathsf{Poly}_\\mathsf{Arr_i}$ values directly (they may contain secret information, and even if they do not, they are too long to check) so the verifier only sees $K_\\mathsf{Arr_1}$,$K_\\mathsf{Arr_2}$, and $K_\\mathsf{Arr_3}$.\nIn order to prove $K_\\mathsf{Arr_1}$,$K_\\mathsf{Arr_2}$, and $K_\\mathsf{Arr_3}$ are consistent, the prover can use one of two methods.\nThe most straight-forward method is to use the additive homomorphic property of the KZG polynomial commitment scheme which states that for equal-sized polynomials on the same domain:\n$K_\\mathsf{Arr_1}\\otimes K_\\mathsf{Arr_2}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr_1}\\oplus \\mathsf{Poly}_\\mathsf{Arr_2})$ Here $\\otimes$ is multiplication in the KZG group (e.g., $\\mathbb{G}_1$ in BLS12-381) while $\\oplus$ is addition in $\\mathbb{Z}_q$ of each evaluation point in $ \\mathsf{Poly}_\\mathsf{Arr_1}$ with each evaluation point in $\\mathsf{Poly}_\\mathsf{Arr_2}$. If the prover ($\\mathcal{P}$) can set $K_\\mathsf{Arr_3}\\leftarrow K_\\mathsf{Arr_1}\\otimes K_\\mathsf{Arr_2}$, then the verifier can check $K_\\mathsf{Arr_3}\\stackrel{?}{=}K_\\mathsf{Arr_1}\\otimes K_\\mathsf{Arr_2}$.\nHowever a second method is needed in other cases. Note that there are many different polynomials that interpolate $\\mathsf{Arr_3}$ on the domain $\\mathcal{H}_\\kappa$ (but are different elsewhere in the polynomial outside of $\\mathcal{H}_\\kappa)$. Each of these polynomials will have a unique commitment value. So it is possible that $K_\\mathsf{Arr_3}\\neq K_\\mathsf{Arr_1}\\otimes K_\\mathsf{Arr_2}$, and yet $\\mathsf{Arr_3}[i]=\\mathsf{Arr_1}[i]+\\mathsf{Arr_2}[i]$ for all $i$. This arrises when $\\mathsf{Poly}_\\mathsf{Arr_3}$ comes from a different part of the protocol than $\\mathsf{Poly}_\\mathsf{Arr_1}$ and $\\mathsf{Poly}_\\mathsf{Arr_2}$.\nThe second method is more general so it can be used in place of the first method (but is more expensive), as well as covering all cases where $\\mathsf{Arr_3}[i]=\\mathsf{Arr_1}[i]+\\mathsf{Arr_2}[i]$. The idea is to show $\\mathsf{Arr_3}[i]-\\mathsf{Arr_1}[i]+\\mathsf{Arr_2}[i]=0$ for each evaluation point in the domain $\\mathcal{H}_\\kappa$. Showing a polynomial is zero on the domain (a \u0026ldquo;vanishing polynomial\u0026rdquo;) is a common sub-protocol used by many gadgets.\nProtocol Details # Array Level # $\\mathcal{P}$ holds an array $\\mathsf{Arr_1} = [a_{(1,0)}, a_{(1,1)}, a_{(1,2)}, \\dots, a_{(1,n-1)}]$ of $n$ integers ($a_{(1,i)} \\in \\mathbb{Z}_q$) $\\mathcal{P}$ holds an array $\\mathsf{Arr_2} = [a_{(2,0)}, a_{(2,1)}, a_{(2,2)}, \\dots, a_{(2,n-1)}]$ of $n$ integers ($a_{(2,i)} \\in \\mathbb{Z}_q$) $\\mathcal{P}$ computes or holds an array $\\mathsf{Arr_3} = [a_{(3,0)}, a_{(3,1)}, a_{(3,2)}, \\dots, a_{(3,n-1)}]$ of $n$ integers ($a_{(3,i)} \\in \\mathbb{Z}_q$) such that: $\\mathsf{Arr_3}[i]=\\mathsf{Arr_1}[i]+\\mathsf{Arr_2}[i]$ for $i$ from 0 to $n-1$ Polynomial Level # We assume the three arrays $\\mathsf{Arr_1}$, $\\mathsf{Arr_2}$, and $\\mathsf{Arr_3}$ are encoded as the y-coordinates into a univariant polynomial where the x-coordinates (called the domain $\\mathcal{H}_\\kappa$) are chosen as the multiplicative group of order $\\kappa$ with generator $\\omega\\in\\mathbb{G}_\\kappa$ (see Background for more). In short, $\\omega^0$ is the first element and $\\omega^{\\kappa-1}$ is the last element of $\\mathcal{H}_\\kappa$. If $\\kappa$ is larger than the length of the array, the array can be padded with elements of value 0 (which will not change the sum).\nRecall the constraint we want to prove:\n$\\mathsf{Arr_3}[i]=\\mathsf{Arr_1}[i]+\\mathsf{Arr_2}[i]$ for $i$ from 0 to $n-1$ In polynomial form, the constraint is:\nFor all $X$ from $\\omega^0$ to $\\omega^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Arr_3}(X)=\\mathsf{Poly}_\\mathsf{Arr_1}(X)+\\mathsf{Poly}_\\mathsf{Arr_2}(X)$ We adjust the constraints to show an equality with 0 and label it:\nFor all $X$ from $\\omega^0$ to $\\omega^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Vanish}(X)=\\mathsf{Poly}_\\mathsf{Arr_3}(X)-\\mathsf{Poly}_\\mathsf{Arr_1}(X)+\\mathsf{Poly}_\\mathsf{Arr_2}(X)=0$ This equation is true for every value of $X \\in \\mathcal{H}_\\kappa$ (but not necessarily true outside of these values). To show this, we divide the polynomial by $X^\\kappa - 1$, which is a minimal vanishing polynomial for $\\mathcal{H}_\\kappa$ that does not require interpolation to create. If the quotient is polynomial (and not a rational function), then $\\mathsf{Poly}_\\mathsf{Vanish}(X)$ must be vanishing on $\\mathcal{H}_\\kappa$ too. Specifically, the prover computes:\n$Q(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish}(X)}{X^\\kappa - 1}$ By rearranging, we can get $\\mathsf{Poly}_\\mathsf{Zero}(X)$ as a true zero polynomial (zero at every value both in $\\mathcal{H}_\\kappa$ and outside of it):\n$\\mathsf{Poly}_\\mathsf{Zero}(X)=\\mathsf{Poly}_\\mathsf{Vanish}(X) - Q(X)\\cdot (X^n - 1)=0$ Ultimately the add1 argument will satisfy the following constraints at the Commitment Level:\nShow $Q(X)$ exists (as a polynomial that evenly divides the divisor) Show $\\mathsf{Poly}_\\mathsf{Zero}(X)$ is correctly constructed from $\\mathsf{Poly}_\\mathsf{Arr_1}(X)$, $\\mathsf{Poly}_\\mathsf{Arr_2}(X)$, and $\\mathsf{Poly}_\\mathsf{Arr_3}(X)$. Show $\\mathsf{Poly}_\\mathsf{Zero}(X)$ is the zero polynomial Commitment Level # The verifier will never see the arrays or polynomials themselves. They are undisclosed because they either (i) contain private data or (ii) they are too large to examine and maintain a succinct proof system. Instead the prover will use commitments.\nThe prover will write the following commitments to the transcript:\n$K_\\mathsf{Arr_1}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr_1}(X))$\n$K_\\mathsf{Arr_2}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr_2}(X))$\n$K_\\mathsf{Arr_3}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr_3}(X))$\n$K_Q=\\mathsf{KZG.Commit}(Q(X))$\nThe prover will generate a random challenge evaluation point (using strong Fiat-Shamir) on the polynomial that is outside of $\\mathcal{H}_\\kappa$. Call this point $\\zeta$. The prover will write the point and opening proofs to the transcript:\n$\\zeta$\n$\\mathsf{Poly}_\\mathsf{Arr_1}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Arr_1},\\zeta)$\n$\\mathsf{Poly}_\\mathsf{Arr_2}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Arr_2},\\zeta)$\n$\\mathsf{Poly}_\\mathsf{Arr_3}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Arr_3},\\zeta)$\n$Q(\\zeta)=\\mathsf{KZG.Open}(K_Q,\\zeta)$\nTo check the proof, the verifier uses the transcript to construct the value $Y_\\mathsf{Zero}$ as follows:\n$Y_\\mathsf{Vanish}=\\mathsf{Poly}_\\mathsf{Arr_1}(\\zeta)-\\mathsf{Poly}_\\mathsf{Arr_2}(\\zeta)+\\mathsf{Poly}_\\mathsf{Arr_3}( \\zeta)$ $Y_\\mathsf{Zero}=Y_\\mathsf{Vanish1} - Q(\\zeta)\\cdot (\\zeta^n - 1)$ Finally, if the constraint system is true, the following constraint will be true (and will be false otherwise with overwhelming probability, due to the Schwartz-Zippel lemma on $\\zeta$) :\n$Y_\\mathsf{Zero}\\overset{?}{=}0$ Implementations # Rust Mathematica (Toy Example) Security Proof # Completeness # Any honest prover can do the computations explained above and create an accepting proof.\nSoundness # We prove knowledge soundness in the Algebraic Group Model (AGM). To do so, we must prove that there exists an efficient extractor $\\mathcal{E}$ such that for any algebraic adversary $\\mathcal{A}$ the probability of $\\mathcal{A}$ winning the following game is $\\mathsf{negl}(\\lambda)$.\nGiven $[g, g^\\tau, g^{\\tau^2}, \\dots,g^{\\tau^{n-1}}]$ $\\mathcal{A}$ outputs commitments to $\\mathsf{Poly}_\\mathsf{Arr1}(X)$, $\\mathsf{Poly}_\\mathsf{Arr2}(X)$, $\\mathsf{Poly}_\\mathsf{Arr3}(X)$, $Q$\n$\\mathcal{E}$, given access to $\\mathcal{A}$\u0026rsquo;s outputs from the previous step, outputs $\\mathsf{Poly}_\\mathsf{Arr1}(X)$, $\\mathsf{Poly}_\\mathsf{Arr2}(X)$, $\\mathsf{Poly}_\\mathsf{Arr3}(X)$, $Q$\n$\\mathcal{A}$ plays the part of the prover in showing that $Y_{\\mathsf{Zero}}$ is zero at a random challenge $\\zeta$\n$\\mathcal{A}$ wins if:\ni) $\\mathcal{\\mathcal{V}}$ accepts at the end of the protocol\nii) $\\mathsf{Arr}_3\\neq \\mathsf{Arr}_1 + \\mathsf{Arr}_2$\nOur proof is as follows:\nFor the second win condition to be fulfilled, the constraint must not hold for at least one index of the arrays. But then $\\mathsf{Poly}_\\mathsf{Vanish}(X)$ is not vanishing on $\\mathcal{H}_\\kappa$, so $Q(X)$ is not a polynomial (it is a rational function). This means that $\\mathcal{A}$ cannot calculate the correct commitment value $g^{Q(\\tau)}$ without solving the t-SDH. Thus, $\\mathcal{A}$ chooses an arbitrary value for $Q(\\tau)$ and sends $K_Q = g^{Q(\\tau)}$. It also sends commitments to $\\mathsf{Poly}_\\mathsf{Arr1}(X)$, $\\mathsf{Poly}_\\mathsf{Arr2}(X)$, and $\\mathsf{Poly}_\\mathsf{Arr3}(X)$. Each commitment $\\mathcal{A}$ has outputted is a linear combination of the elements in $[g, g^\\tau, g^{\\tau^2}, \\dots,g^{\\tau^{n-1}}]$. $\\mathcal{E}$ is given these coefficients (since $\\mathcal{A}$ is an algebraic adversary) so $\\mathcal{E}$ can output the original polynomials.\n$\\mathcal{A}$ then obtains the random challenge $\\zeta$ (using strong Fiat-Shamir). By the binding property of KZG commitments, $\\mathsf{Poly}_\\mathsf{Arr1}(\\zeta)$, $\\mathsf{Poly}_\\mathsf{Arr2}(\\zeta)$, and $\\mathsf{Poly}_\\mathsf{Arr3}(\\zeta)$ can only feasibliy be opened to one value each. For $\\mathcal{A}$ to have the verifier accept, they must send a proof that $Q(\\zeta)$ opens to $Q(\\zeta) = \\frac{Y_\\mathsf{Vanish1}}{(\\zeta^n - 1)}$. This means being able to send $g^{q(\\tau)}$ where $q(\\tau) = \\frac{Q(\\tau) - Q(\\zeta)}{\\tau - \\zeta}$ and $Q(\\zeta) = \\frac{Y_\\mathsf{Vanish1}}{(\\zeta^n - 1)}$. Since $Q(\\tau)$ and $Q(\\zeta)$ are known, this implies knowing $g^{\\frac{1}{\\tau - \\zeta}}$. Thus $\\mathcal{A}$ would have found $\\langle\\zeta,g^{\\frac{1}{\\tau - \\zeta}}\\rangle$, which is the t-SDH problem. We have shown that creating an accepting proof reduces to the t-SDH, so $\\mathcal{A}$\u0026rsquo;s probability of success is negligible.\nZero-Knowledge # We prove that the above protocol is zero-knowledge when $\\mathsf{PolyCommit}_\\mathsf{Ped}$ (from the KZG paper) is used for the polynomial commitments. We do so by constructing a probabilistic polynomial time simulator $\\mathcal{S}$ that knows the trapdoor $\\tau$, which, for every (possibly malicious) verifier $\\mathcal{V}$, can output a view of the execution of the protocol that is indistinguishable from the view produced by the real execution of the program.\nThe simulator $\\mathcal{S}$ choose arbitrary values for ${\\mathsf{Poly}_\\mathsf{Arr1}(\\tau)}$, ${\\mathsf{Poly}_\\mathsf{Arr2}(\\tau)}$, and $\\mathsf{Poly}_\\mathsf{Arr3}(\\tau)$, then computes $g^{\\mathsf{Poly}_\\mathsf{Arr1}(\\tau)}$, $g^{\\mathsf{Poly}_\\mathsf{Arr2}(\\tau)}$, and $g^{\\mathsf{Poly}_\\mathsf{Arr3}(\\tau)}$ to output as the commitments $K_\\mathsf{Arr1}$, $ K_\\mathsf{Arr2}$, and $ K_\\mathsf{Arr3}$. $\\mathcal{S}$ then generates the challenge evaluation pount $\\rho$ (by strong Fiat-Shamir) and computes $Q(\\tau)$ using $\\rho$ and the values they chose for ${\\mathsf{Poly}_\\mathsf{Arr1}(\\tau)}$, ${\\mathsf{Poly}_\\mathsf{Arr2}(\\tau)}$, and $\\mathsf{Poly}_\\mathsf{Arr3}(\\tau)$. $\\mathcal{S}$ outputs the commitment $K_Q = g^{Q(\\tau)}$.\nNow, $\\mathcal{S}$ generates the second random challenge point $\\zeta$ (which we assume is not in $\\mathcal{H}_\\kappa$; if it is in $\\mathcal{H}_\\kappa$, $\\mathcal{S}$ simply restarts and runs from the beginning). This is once again by strong Fiat-Shamir. $\\mathcal{S}$ then create fake opening proofs for ${\\mathsf{Poly}_\\mathsf{Arr1}(\\zeta)}$, ${\\mathsf{Poly}_\\mathsf{Arr2}(\\zeta)}$, and $\\mathsf{Poly}_\\mathsf{Arr3}(\\zeta)$, to arbitrary values. This is done using the knowledge of $\\tau$, calculating the respective witness $q(\\tau) = \\frac{{f(\\tau) - f(\\zeta)}}{\\tau - \\zeta}$ for each of the polynomials.\nFinally, $\\mathcal{S}$ creates a fake opening proof for $Q(\\zeta) = \\frac{Y_\\mathsf{Vanish1}}{(\\zeta^n - 1)}$. This is done using knowledge of $\\tau$ to calculate an accepting witness $q(\\tau)$, as above. This means that $Y_\\mathsf{Zero}$ will be zero, and the transcript will be accepted by the verifier. It is indistinguishable from a transcript generated from a real execution, since $\\mathsf{PolyCommit}_\\mathsf{Ped}$ has the property of Indistinguishability of Commitments due to the randomization by $h^{\\hat{\\phi}(x)}$.\nFor add2, the proof is written with a simulator that doesn\u0026rsquo;t know the trapdoor; however, with small alterations the proof for add2 should apply here and vice versa "},{"id":4,"href":"/docs/gadgets/add2/","title":"Add2","section":"Gadgets","content":" Addition (Type 2) # Recap of types # Type Description Recap This add1 $\\mathsf{Arr}_3=\\mathsf{Arr}_1 + \\mathsf{Arr}_2$ $\\mathsf{Arr}_3$ is the element-wise addition of $\\mathsf{Arr}_1$ and $\\mathsf{Arr}_2$. add2 $\\mathsf{Sum}_\\mathsf{Arr}=\\sum_{i = 0}^{n-1} \\mathsf{Arr}[i]$ $\\mathsf{Sum}_\\mathsf{Arr}$ is the disclosed sum of all the elements in $\\mathsf{Arr}$. ‚úÖ add3 $\\sum_{i = 0}^{n-1} \\mathsf{Arr}_1[i]=\\sum_{i = 0}^{n-1} \\mathsf{Arr}_2[i]$ $\\mathsf{Arr}_1$ and $\\mathsf{Arr}_2$ have the same undisclosed sum. Relation # $ \\mathcal{R}_{\\mathtt{add2}} := \\left\\{ \\begin{array}{l} (K_\\mathsf{Arr},\\mathsf{Sum}_\\mathsf{Arr}) \\end{array} \\middle | \\begin{array}{l} \\mathsf{Arr} = [a_0, a_1, a_2, \\dots, a_{n-1}], \\\\ \\mathsf{Sum}_\\mathsf{Arr} = \\sum_{i = 0}^{n-1} a_i, \\\\ \\mathsf{Poly}_\\mathsf{Arr}(X)=\\mathsf{FFT.Interp}(\\omega,\\mathsf{Arr}), \\\\ K_\\mathsf{Arr}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr}(X)) \\end{array} \\right\\} $\nIntuition # The prover ($\\mathcal{P}$) holds an array $\\mathsf{Arr} = [a_0, a_1, a_2, \\dots, a_{n-1}]$ of $n$ integers (from $\\mathbb{Z}_q$) and a disclosed integer $\\mathsf{Sum}_\\mathsf{Arr}$. It will produce a succinct (independent of $n$) proof that $\\mathsf{Sum}_\\mathsf{Arr}$ is the sum of all the elements in the array. The prover will encode the array into a polynomial $\\mathsf{Poly}_\\mathsf{Arr}$ (using evaluation points on the domain $\\mathcal{H}_\\kappa$) and commit to the polynomial $K_\\mathsf{Arr}$. The verifier ($\\mathcal{V}$) cannot check $\\textsf{Arr}$ or $\\mathsf{Poly}_\\mathsf{Arr}$ directly (they may contain secret information, and even if they do not, it is too long to check) so the verifier only sees $K_\\mathsf{Arr}$ and the asserted value $\\mathsf{Sum_\\mathsf{Arr}}$.\nIn order to prove $K_\\mathsf{Arr}$ and $\\mathsf{Sum}_\\mathsf{Arr}$ are consistent, the prover will build a helper array $\\mathsf{Acc}_\\mathsf{Arr}$ called an accumulator (or accumulating array or incremental array). This should not be confused with accumulators from cryptography, which are a concept related to succinct proofs but are distinct. As with $\\mathsf{Arr}$, the prover will also encode $\\mathsf{Acc}$ as a polynomial and provide a commitment of it to the verifier. The idea is that the prover will prove a relation between $\\mathsf{Arr}$ and $\\mathsf{Acc}$; and a relation between $\\mathsf{Acc}$ and $\\mathsf{Sum_\\mathsf{Arr}}$. Put together, it will imply the correct relation between $\\mathsf{Arr}$ and $\\mathsf{Sum_\\mathsf{Arr}}$.\nConsider a small numeric example in $\\mathbb{Z}_{97}$ where $\\mathsf{Arr}= [84,67,11,92,36,67]$ and $\\mathsf{Sum}_\\mathsf{Arr}=66$. The first idea is to get $\\mathsf{Sum}_\\mathsf{Arr}$ into an array. Say, we just append it: $\\mathsf{Arr}''= [84,67,11,92,36,67,66] $. How does the prover show $\\mathsf{Arr}''$ is correct? The last value of the array depends on every single element that precedes it, which will be a complex constraint to prove.\nAn alternative idea is to create a new array that starts the same as $\\mathsf{Arr}$ and ends up at $\\mathsf{Sum}_\\mathsf{Arr}$ by folding in the integers from $\\mathsf{Arr}$ one-by-one with addition. Then each value in the new array will depend on only two values, as below.\nThe first value in $\\mathsf{Acc}$ will be a copy of the first value from $\\mathsf{Arr}$:\n$\\mathsf{Arr}= [84,67,11,92,36,67]$\n$\\mathsf{Acc}= [84, \\bot,\\bot,\\bot,\\bot,\\bot] $\nThe next value will be the addition (mod 97) of: 67 (the value at the same index in $\\mathsf{Arr}$) and 84 (the previous value in $\\mathsf{Acc}$):\n$\\mathsf{Arr}= [84,67,11,92,36,67]$\n$ \\mathsf{Acc} = [84, (67+84),\\bot,\\bot,\\bot,\\bot] = [84, 54,\\bot,\\bot,\\bot,\\bot]$\nThe next value will be the addition of: 11 (the value at the same index in $\\mathsf{Arr}$) and 2 (the previous value in $\\mathsf{Acc}$):\n$\\mathsf{Arr}= [84,67,11,92,36,67]$ $ \\mathsf{Acc} = [84, 54,(11+54),\\bot,\\bot,\\bot] = [84,54,65,\\bot,\\bot,\\bot]$ $ \\mathsf{Acc} = [84, 54, 65,(92+65),\\bot,\\bot] = [84,54,65, 60,\\bot,\\bot]$ $ \\mathsf{Acc} = [84,54,65, 60,(36 + 60),\\bot] = [84,54,65, 60, 96,\\bot]$ $ \\mathsf{Acc} = [84,54,65, 60, 96, (67+96)] = [84,54,65, 60, 96, 66]$ $\\mathsf{Sum}_\\mathsf{Arr}=66$ Notice the last value in $\\mathsf{Acc}$ is $\\mathsf{Sum_\\mathsf{Arr}}$. The prover wants to show three constraints:\nThe first value in $\\mathsf{Acc}$ matches the first value in $\\mathsf{Arr}$, The rest of the values in $\\mathsf{Acc}$ are of the form $\\mathsf{Acc}[i]=\\mathsf{Arr}[i]+\\mathsf{Acc}[i-1]$, The last value in $\\mathsf{Acc}$ matches $\\mathsf{Sum}_\\mathsf{Arr}$. If all three constraints are true, then $\\mathsf{Sum}_\\mathsf{Arr}$ is the sum of the elements of $\\mathsf{Arr}$.\nLast, while it is not necessary to do, it is often convenient to hold the the value $\\mathsf{Sum}_\\mathsf{Arr}$ at the start of the array $\\mathsf{Acc}$ instead of the end. For this reason, the mathematical explaination below will construct $\\mathsf{Acc}$ \u0026ldquo;backwards\u0026rdquo; (or right-to-left) from the above example, where the last value of $\\mathsf{Acc}$ matches the last value of $\\mathsf{Arr}$, the values are folded in from right to left, and the first (leftmost) value of $\\mathsf{Acc}$ is $\\mathsf{Sum}_\\mathsf{Arr}$:\n$\\mathsf{Arr}= [84,67,11,92,36,67]$ $ \\mathsf{Acc} = [\\bot, \\bot, \\bot, \\bot, \\bot, 67]$ $ \\mathsf{Acc} = [\\bot, \\bot, \\bot, \\bot, 6, 67]$ $\\ldots$ $ \\mathsf{Acc} = [66, 79, 12, 1, 6, 67]$ $\\mathsf{Sum}_\\mathsf{Arr}=66$ Protocol Details # Array Level # $\\mathcal{P}$ holds an array $\\mathsf{Arr} = [a_0, a_1, a_2, \\dots, a_{n-1}]$ of $n$ integers ($a_i \\in \\mathbb{Z}_q$) $\\mathcal{P}$ computes array $\\mathsf{Acc}$ as follows: $\\mathsf{Acc}[n-1]\\leftarrow\\mathsf{Arr}[n-1]$ $\\mathsf{Acc}[i]\\leftarrow\\mathsf{Arr}[i]+\\mathsf{Acc}[i+1]$ for $i$ from $n-2$ to 0 $\\mathcal{P}$ computes $\\mathsf{Sum}_\\mathsf{Arr}\\leftarrow\\mathsf{Acc}[0]$ Polynomial Level # We assume arrays $\\mathsf{Arr}$ and $\\mathsf{Acc}$ are encoded as the y-coordinates into a univariant polynomial where the x-coordinates (called the domain $\\mathcal{H}_\\kappa$) are chosen as the multiplicative group of order $\\kappa$ with generator $\\omega\\in\\mathbb{G}_\\kappa$ (see Background for more). In short, $\\omega^0$ is the first element and $\\omega^{\\kappa-1}$ is the last element of $\\mathcal{H}_\\kappa$. If $\\kappa$ is larger than the length of the array, the array can be padded with elements of value 0 (which will not change the sum).\nRecall the three constraints we want to prove:\nThe first value in $\\mathsf{Acc}$ matches the first value in $\\mathsf{Arr}$, The rest of the values in $\\mathsf{Acc}$ are of the form $\\mathsf{Acc}[i]=\\mathsf{Arr}[i]+\\mathsf{Acc}[i-1]$, The last value in $\\mathsf{Acc}$ matches $\\mathsf{Sum}_\\mathsf{Arr}$. In polynomial form, the constraints are:\nFor $X=w^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Acc}(X)=\\mathsf{Poly}_\\mathsf{Arr}(X)$, For all $X$ except $X=\\omega^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Acc}(X)=\\mathsf{Poly}_\\mathsf{Arr}(X)+\\mathsf{Poly}_\\mathsf{Acc}(\\omega\\cdot X)$ For $X=w^0$: $\\mathsf{Poly}_\\mathsf{Acc}(X)=\\mathsf{Sum}_\\mathsf{Arr}$ In constraint 2, $\\mathsf{Poly}_\\mathsf{Acc}(\\omega\\cdot X)$ can also be conceptualized as rotate applied to $\\mathsf{Poly}_\\mathsf{Acc}(X)$ by one element (rightward in the array view). Also note that constraint 2 does not hold at $X=\\omega^{\\kappa-1}$ because this value is defined by constraint 1 (for the last value of $X$, the \u0026ldquo;next\u0026rdquo; value, $\\omega X$, wraps back to the first element of the array which is a boundary condition).\nWe adjust each of these constraints to show an equality with 0:\nFor $X=w^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Acc}(X)-\\mathsf{Poly}_\\mathsf{Arr}(X)=0$, For all $X$ except $X=\\omega^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Acc}(X)-\\mathsf{Poly}_\\mathsf{Arr}(X)+\\mathsf{Poly}_\\mathsf{Acc}(\\omega\\cdot X)=0$ For $X=w^0$: $\\mathsf{Poly}_\\mathsf{Acc}(X)-\\mathsf{Sum}_\\mathsf{Arr}=0$ Next we take care of the \u0026ldquo;for $X$\u0026rdquo; conditions by zeroing out the rest of the polynomial that is not zero. See the gadget zero1 for more on why this works.\n$\\mathsf{Poly}_\\mathsf{Vanish1}(X)=(\\mathsf{Poly}_\\mathsf{Acc}(X)-\\mathsf{Poly}_\\mathsf{Arr}(X))\\cdot\\frac{(X^\\kappa-1)}{(X-\\omega^{\\kappa-1})}=0$, $\\mathsf{Poly}_\\mathsf{Vanish2}(X)=(\\mathsf{Poly}_\\mathsf{Acc}(X)-\\mathsf{Poly}_\\mathsf{Arr}(X)+\\mathsf{Poly}_\\mathsf{Acc}(\\omega\\cdot X))\\cdot(X-\\omega^{\\kappa-1})=0$ $\\mathsf{Poly}_\\mathsf{Vanish3}(X)=(\\mathsf{Poly}_\\mathsf{Acc}(X)-\\mathsf{Sum}_\\mathsf{Arr})\\cdot\\frac{(X^\\kappa-1)}{(X-\\omega^0)}=0$ These equations are true for every value of $X \\in \\mathcal{H}_\\kappa$ (but not necessarily true outside of these values). To show this, we divide each polynomial by $X^\\kappa - 1$, which is a minimal vanishing polynomial for $\\mathcal{H}_\\kappa$ that does not require interpolation to create. If the quotients are polynomials (and not rational functions), then $\\mathsf{Poly}_\\mathsf{Vanish1}(X)$, $\\mathsf{Poly}_\\mathsf{Vanish2}(X)$, and $\\mathsf{Poly}_\\mathsf{Vanish3}(X)$ must be vanishing on $\\mathcal{H}_\\kappa$ too. Specifically, the prove computes,\n$Q_1(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish1}(X)}{X^\\kappa - 1}$ $Q_2(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish2}(X)}{X^\\kappa - 1}$ $Q_3(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish3}(X)}{X^\\kappa - 1}$ We can replace polynomials $Q_1(X)$, $Q_2(X)$, and $Q_3(X)$ with a single polynomial $Q(X)$. We can do this because all three constraints have the same format: $\\mathsf{Poly}_\\mathsf{Vanish_i}(X)=0$. The batching technique is to create a new polynomial with all three $\\mathsf{Poly}_\\mathsf{Vanish_i}(X)$ values as coefficients. If and (overwhelmingly) only if all three are vanishing, then so will the new polynomial. This polynomial will be evaluated at a random challenge point $\\rho$ selected after the commitments to the earlier polynomials are fixed.\n$Q(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish1}(X) + \\mathsf{Poly}_\\mathsf{Vanish2}(X) \\rho + \\mathsf{Poly}_\\mathsf{Vanish3}(X)\\rho^2}{X^n - 1}$\nBy rearranging, we can get $\\mathsf{Poly}_\\mathsf{Zero}(X)$ as a true zero polynomial (zero at every value both in $\\mathcal{H}_\\kappa$ and outside of it):\n$\\mathsf{Poly}_\\mathsf{Zero}(X)=\\mathsf{Poly}_\\mathsf{Vanish1}(X) + \\rho \\mathsf{Poly}_\\mathsf{Vanish2}(X) + \\rho^2 \\mathsf{Poly}_\\mathsf{Vanish3}(X) - Q(X)\\cdot (X^n - 1)=0$\nUltimately the add2 argument will satisfy the following constraints at the Commitment Level:\nShow $Q(X)$ exists (as a polynomial that evenly divides the divisor) Show $\\mathsf{Poly}_\\mathsf{Zero}(X)$ is correctly constructed from $\\mathsf{Poly}_\\mathsf{Acc}(X)$, $\\mathsf{Poly}_\\mathsf{Acc}(\\omega X)$, $\\mathsf{Poly}_\\mathsf{Arr}(X)$, and $\\mathsf{Sum}_\\mathsf{Arr}$ Show $\\mathsf{Poly}_\\mathsf{Zero}(X)$ is the zero polynomial Commitment Level # The verifier will never see the arrays or polynomials themselves. They are undisclosed because they either (i) contain private data or (ii) they are too large to examine and maintain a succinct proof system. Instead the prover will use commitments.\nThe prover will write the following commitments to the transcript:\n$K_\\mathsf{Arr}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr}(X))$ $K_\\mathsf{Acc}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Acc}(X))$ The prover will generate a random challenge evaluation point (using strong Fiat-Shamir) on the polynomial that is outside of $\\mathcal{H}_\\kappa$. Call this point $\\rho$. It will be used by the prover to create polynomial $Q(X)$ (see above) and the prover will write to the transcript:\n$\\rho$ $K_Q=\\mathsf{KZG.Commit}(Q(X))$ The prover will generate a second random challenge evaluation point (using strong Fiat-Shamir) on the polynomial that is outside of $\\mathcal{H}_\\kappa$. Call this point $\\zeta$. The prover will write the point and opening proofs to the transcript:\n$\\zeta$ $\\mathsf{Poly}_\\mathsf{Arr}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Arr},\\zeta)$ $\\mathsf{Poly}_\\mathsf{Arr}(\\zeta\\omega)=\\mathsf{KZG.Open}(K_\\mathsf{Arr},\\zeta\\omega)$ $\\mathsf{Poly}_\\mathsf{Acc}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Acc},\\zeta)$ $Q(\\zeta)=\\mathsf{KZG.Open}(K_Q,\\zeta)$ To check the proof, the verifier uses the transcript to construct the value $Y_\\mathsf{Zero}$ as follows:\n$Y_\\mathsf{Vanish1}=(\\mathsf{Poly}_\\mathsf{Acc}(\\zeta)-\\mathsf{Poly}_\\mathsf{Arr}(\\zeta))\\cdot\\frac{(\\zeta^\\kappa-1)}{(\\zeta-\\omega^{\\kappa-1})}$ $Y_\\mathsf{Vanish2}=(\\mathsf{Poly}_\\mathsf{Acc}(\\zeta)-\\mathsf{Poly}_\\mathsf{Arr}(\\zeta)+\\mathsf{Poly}_\\mathsf{Acc}(\\omega\\cdot \\zeta))\\cdot(\\zeta-\\omega^{\\kappa-1})$ $Y_\\mathsf{Vanish3}=(\\mathsf{Poly}_\\mathsf{Acc}(\\zeta)-\\mathsf{Sum}_\\mathsf{Arr})\\cdot\\frac{(\\zeta^\\kappa-1)}{(\\zeta-\\omega^0)}$ $Y_\\mathsf{Zero}=Y_\\mathsf{Vanish1} + \\rho Y_\\mathsf{Vanish2} + \\rho^2 Y_\\mathsf{Vanish3} - Q(\\zeta)\\cdot (\\zeta^n - 1)$ Finally, if the constraint system is true, the following constraint will be true (and will be false otherwise with overwhelming probability, due to the Schwartz-Zippel lemma on $\\rho$ and $\\zeta$) :\n$Y_\\mathsf{Zero}\\overset{?}{=}0$ Implementations # Rust Mathematica (Toy Example) Security Proof # Completeness # Any honest prover can do the computations explained above and create an accepting proof.\nSoundness # We prove knowledge soundness in the Algebraic Group Model (AGM). To do so, we must prove that there exists an efficient extractor $\\mathcal{E}$ such that for any algebraic adversary $\\mathcal{A}$ the probability of $\\mathcal{A}$ winning the following game is $\\mathsf{negl}(\\lambda)$.\nGiven $[g, g^\\tau, g^{\\tau^2}, \\dots,g^{\\tau^{n-1}}]$ $\\mathcal{A}$ outputs commitments to $\\mathsf{Poly}_\\mathsf{Acc}(X)$, $\\mathsf{Poly}_\\mathsf{Arr}(X)$, $Q$\n$\\mathcal{E}$, given access to $\\mathcal{A}$\u0026rsquo;s outputs from the previous step, outputs $\\mathsf{Poly}_\\mathsf{Acc}(X)$, $\\mathsf{Poly}_\\mathsf{Arr}(X)$, $Q$\n$\\mathcal{A}$ plays the part of the prover in showing that $Y_\\mathsf{Zero}$ is zero at a random challenge $\\zeta$\n$\\mathcal{A}$ wins if:\ni) $\\mathcal{V}$ accepts at the end of the protocol\nii) $\\mathsf{Sum}_\\mathsf{Arr}\\neq\\sum_{i = 0}^{n-1} \\mathsf{Arr}[i]$\nOur proof is as follows:\nFor the second win condition to be fulfilled, one of the three constraints must be false. But then the $\\mathsf{Poly}_\\mathsf{Vanish}$ corresponding to that constraint is not vanishing on $\\mathcal{H}_\\kappa$, so $Q(X)$ is not a polynomial (it is a rational function). This means that $\\mathcal{A}$ cannot calcuated the correct commitment value $g^{Q(\\tau)}$ without solving the t-SDH. Thus, $\\mathcal{A}$ chooses an arbitrary value for $Q(\\tau)$ and sends $K_Q = g^{Q(\\tau)}$. It also sends commitments to $\\mathsf{Poly}_\\mathsf{Acc}(X)$, and $\\mathsf{Poly}_\\mathsf{Arr}(X)$. Each commitment $\\mathcal{A}$ has outputted is a linear combination of the elements in $[g, g^\\tau, g^{\\tau^2}, \\dots,g^{\\tau^{n-1}}]$. $\\mathcal{E}$ is given these coefficients (since $\\mathcal{A}$ is an algebraic adversary) so $\\mathcal{E}$ can output the original polynomials.\n$\\mathcal{A}$ then obtains the random challenge $\\zeta$ (using strong Fiat-Shamir). By the binding property of KZG commitments, $\\mathsf{Poly}_\\mathsf{Acc}(\\zeta)$, $\\mathsf{Poly}_\\mathsf{Arr}(\\zeta)$, and $\\mathsf{Poly}_\\mathsf{Acc}(\\zeta \\cdot \\omega)$ can only feasibliy be opened to one value each. For $\\mathcal{A}$ to have the verifier accept, they must send a proof that $Q(\\zeta)$ opens to $Q(\\zeta) = \\frac{Y_\\mathsf{Vanish1} + \\rho Y_\\mathsf{Vanish2} + \\rho^2Y_\\mathsf{Vanish3}}{\\zeta^n - 1}$. This means being able to send $g^{q(\\tau)}$ where $q(\\tau) = \\frac{Q(\\tau) - Q(\\zeta)}{\\tau - \\zeta}$ and $Q(\\zeta) = \\frac{Y_\\mathsf{Vanish1} + \\rho Y_\\mathsf{Vanish2} + \\rho^2Y_\\mathsf{Vanish3}}{\\zeta^n - 1}$. Since $Q(\\tau)$ and $Q(\\zeta)$ are known, this implies knowing $g^{\\frac{1}{\\tau - \\zeta}}$. Thus $\\mathcal{A}$ would have found $\\langle\\zeta,g^{\\frac{1}{\\tau - \\zeta}}\\rangle$, which is the t-SDH problem. We have shown that creating an accepting proof reduces to the t-SDH, so $A$\u0026rsquo;s probability of success is negligible.\nZero-Knowledge # We prove that the above protocol is zero-knowledge when $\\mathsf{PolyCommit}_\\mathsf{Ped}$ (from the KZG paper) is used for the polynomial commitments. We do so by constructing a probabilistic polynomial time simulator $\\mathcal{S}$ which, for every (possibly malicious) verifier $\\mathcal{V}$, can output a view of the execution of the protocol that is indistinguishable from the view produced by the real execution of the program.\nThe simulator $\\mathcal{S}$ generates an array $\\mathsf{Arr'}$ whose product is equal to the disclosed value $\\mathsf{Sum}_\\mathsf{Arr}$ (this array could just have $\\mathsf{Prod}_\\mathsf{Sum}$ in one entry, and $0$\u0026rsquo;s elsewhere), then follows the same steps a prover would to prove the sum of this array. So, $\\mathcal{S}$ computes the accumulator $\\mathsf{Acc'}$ and interpolates the two arrays into their respective polynomials, $\\mathsf{Poly}_\\mathsf{Acc'}(X)$ and $\\mathsf{Poly}_\\mathsf{Arr'}(X)$. It computes $Q(X)'$ using $\\mathsf{Poly}_\\mathsf{Acc'}(X)$ and $\\mathsf{Poly}_\\mathsf{Arr'}(X)$ and the random challenge point $\\rho'$ (by strong Fiat-Shamir). $\\mathcal{S}$ commits to each of these three polynomials (and writes the commitments to the transcript). Then, it generates the random challenge $\\zeta'$ (once again this is by strong Fiat-Shamir). It creates opening proofs for $\\mathsf{Poly}_\\mathsf{Acc'}(\\zeta'), \\space \\mathsf{Poly}_\\mathsf{Arr'}(\\zeta'), \\space Q(\\zeta')'$, and $\\mathsf{Poly}_\\mathsf{Acc'}(\\zeta' \\cdot \\omega)$, and writes these to the transcript as well. Since $\\mathcal{S}$ knows each of the above polynomials, it can honestly compute this step and the proof will be accepted by $V\\mathcal{V}$. The transcript it generates this way will be indistinguishable from a transcript generated from a real execution, since $\\mathsf{PolyCommit}_\\mathsf{Ped}$ has the property of Indistinguishability of Commitments due to the randomization by $h^{\\hat{\\phi}(x)}$.\nThis proof could also b doe by defining a simulator knows the trapdoor $\\tau$ and thus can create a passing witness for any commitment. The proof for add1 is done in this style, but with small alterations would work here as well (and vice versa with this style of proof working for add1) "},{"id":5,"href":"/docs/gadgets/add3/","title":"Add3","section":"Gadgets","content":" Addition (Type 3) # Recap of types # Type Description Recap This add1 $\\mathsf{Arr}_3=\\mathsf{Arr}_1 + \\mathsf{Arr}_2$ $\\mathsf{Arr}_3$ is the element-wise addition of $\\mathsf{Arr}_1$ and $\\mathsf{Arr}_2$. add2 $\\mathsf{Sum}_\\mathsf{Arr}=\\sum_{i = 0}^{n-1} \\mathsf{Arr}[i]$ $\\mathsf{Sum}_\\mathsf{Arr}$ is the disclosed sum of all the elements in $\\mathsf{Arr}$. add3 $\\sum_{i = 0}^{n-1} \\mathsf{Arr}_1[i]=\\sum_{i = 0}^{n-1} \\mathsf{Arr}_2[i]$ $\\mathsf{Arr}_1$ and $\\mathsf{Arr}_2$ have the same undisclosed sum. ‚úÖ Relation # $ \\mathcal{R}_{\\mathtt{add3}} := \\left\\{ \\begin{array}{l} (K_\\mathsf{Arr_1},K_\\mathsf{Arr2}) \\end{array} \\middle | \\begin{array}{l} \\mathsf{Arr_1} = [a_{(1,0)}, a_{(1,1)}, a_{(1,2)}, \\dots, a_{(1,n-1)}],\\\\ \\mathsf{Arr_2} = [a_{(2,0)}, a_{(2,1)}, a_{(2,2)}, \\dots, a_{(2,n-1)}], \\\\ \\mathsf{Poly}_\\mathsf{Arr_1}=\\mathsf{FFT.Interp}(\\omega,\\mathsf{Arr_1}), \\\\ \\mathsf{Poly}_\\mathsf{Arr_2}=\\mathsf{FFT.Interp}(\\omega,\\mathsf{Arr_2}), \\\\ K_\\mathsf{Arr_1}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr_1}),\\\\ K_\\mathsf{Arr_2}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr_2}), \\end{array} \\right\\} $\nIntuition # The prover ($\\mathcal{P}$) holds two arrays $\\mathsf{Arr_1}$ and $\\mathsf{Arr_2}$ of $n$ integers from $\\mathbb{Z}_q$: $[a_0, a_1, a_2, \\dots, a_{n-1}]$. It will produce a succinct (independent of $n$) proof that they have the same undisclosed sum. The prover will encode the two arrays into polynomials, $\\mathsf{Poly}_\\mathsf{Arr_1}$ and $\\mathsf{Poly}_\\mathsf{Arr_2}$ (using evaluation points on the domain $\\mathcal{H}_\\kappa$) and commit to them as $K_\\mathsf{Arr_1}$ and $K_\\mathsf{Arr_2}$. The verifier ($\\mathcal{V}$) cannot check either array directly (they may contain secret information, and even if they do not, it is too long to check) so the verifier only sees $K_\\mathsf{Arr_1}$ and $K_\\mathsf{Arr_2}$.\nIn order to prove $K_\\mathsf{Arr_1}$ and $K_\\mathsf{Arr_2}$ are consistent, the prover will build two helper arrays $\\mathsf{Acc_1}$ and $\\mathsf{Acc_2}$ called accumulators (or accumulating arrays or incremental arrays). This should not be confused with accumulators from cryptography, which are a concept related to succinct proofs but are distinct. As with $\\mathsf{Arr_1}$ and $\\mathsf{Arr_2}$, the prover will also encode $\\mathsf{Acc_1}$ and $\\mathsf{Acc_2}$ as a polynomials and provide a commitment to the verifier of each one. The idea is that the prover will prove a relation between each $\\mathsf{Arr}$ and its $\\mathsf{Acc}$; and a relation between $\\mathsf{Acc_1}$ and $\\mathsf{Acc_2}$. Put together, it will imply the correct relation between $\\mathsf{Arr_1}$ and $\\mathsf{Arr_2}$.\nWe will illustrate a small numerical example in $\\mathbb{Z}_{97}$ of constructing an accumulator $\\mathsf{Acc}$ for the array $\\mathsf{Arr}= [84,67,11,92,36,67]$. The idea is to create a new array, $\\mathsf{Acc}$, that starts the same as $\\mathsf{Arr}$ and ends with the sum of all entries of $\\mathsf{Arr}$, by folding in the integers from $\\mathsf{Arr}$ one-by-one with multiplication. Then each value in the new array will depend on only two values, as below.\nThe first value in $\\mathsf{Acc}$ will be a copy of the first value from $\\mathsf{Arr}$:\n$\\mathsf{Arr}= [84,67,11,92,36,67]$\n$\\mathsf{Acc}= [84, \\bot,\\bot,\\bot,\\bot,\\bot] $\nThe next value will be the addition (mod 97) of: 67 (the value at the same index in $\\mathsf{Arr}$) and 84 (the previous value in $\\mathsf{Acc}$):\n$\\mathsf{Arr}= [84,67,11,92,36,67]$\n$ \\mathsf{Acc} = [84, (67+84),\\bot,\\bot,\\bot,\\bot] = [84, 54,\\bot,\\bot,\\bot,\\bot]$\nThe next value will be the addition of: 11 (the value at the same index in $\\mathsf{Arr}$) and 2 (the previous value in $\\mathsf{Acc}$):\n$\\mathsf{Arr}= [84,67,11,92,36,67]$ $ \\mathsf{Acc} = [84, 54,(11+54),\\bot,\\bot,\\bot] = [84,54,65,\\bot,\\bot,\\bot]$ $ \\mathsf{Acc} = [84, 54, 65,(92+65),\\bot,\\bot] = [84,54,65, 60,\\bot,\\bot]$ $ \\mathsf{Acc} = [84,54,65, 60,(36 + 60),\\bot] = [84,54,65, 60, 96,\\bot]$ $ \\mathsf{Acc} = [84,54,65, 60, 96, (67+96)] = [84,54,65, 60, 96, 66]$ $\\mathsf{Sum}_\\mathsf{Arr}=66$ Notice the last value in $\\mathsf{Acc}$ is $\\mathsf{Sum_\\mathsf{Arr}}$. The prover wants to show three constraints:\nThe first value in $\\mathsf{Acc}$ matches the first value in $\\mathsf{Arr}$, The rest of the values in $\\mathsf{Acc}$ are of the form $\\mathsf{Acc}[i]=\\mathsf{Arr}[i]+\\mathsf{Acc}[i-1]$, The last value in $\\mathsf{Acc}$ matches $\\mathsf{Sum}_\\mathsf{Arr}$. If all three constraints are true, then $\\mathsf{Sum}_\\mathsf{Arr}$ is the sum of the elements of $\\mathsf{Arr}$.\nLast, while it is not necessary to do, it is often convenient to hold the the value $\\mathsf{Sum}_\\mathsf{Arr}$ at the start of the array $\\mathsf{Acc}$ instead of the end. For this reason, the mathematical explaination below will construct $\\mathsf{Acc}$ \u0026ldquo;backwards\u0026rdquo; (or right-to-left) from the above example, where the last value of $\\mathsf{Acc}$ matches the last value of $\\mathsf{Arr}$, the values are folded in from right to left, and the first (leftmost) value of $\\mathsf{Acc}$ is $\\mathsf{Sum}_\\mathsf{Arr}$:\n$\\mathsf{Arr}= [84,67,11,92,36,67]$ $ \\mathsf{Acc} = [\\bot, \\bot, \\bot, \\bot, \\bot, 67]$ $ \\mathsf{Acc} = [\\bot, \\bot, \\bot, \\bot, 6, 67]$ $\\ldots$ $ \\mathsf{Acc} = [66, 79, 12, 1, 6, 67]$ and the sum of all entries in $\\mathsf{Acc}$ is 66 Protocol Details # Array Level # $\\mathcal{P}$ holds an array $\\mathsf{Arr_1} = [a_{(1,0)}, a_{(1,1)}, a_{(1,2)}, \\dots, a_{(1,n-1)}]$ of $n$ integers ($a_{(1,i)} \\in \\mathbb{Z}_q$) $\\mathcal{P}$ holds an array $\\mathsf{Arr_2} = [a_{(2,0)}, a_{(2,1)}, a_{(2,2)}, \\dots, a_{(2,n-1)}]$ of $n$ integers ($a_{(2,i)} \\in \\mathbb{Z}_q$) $\\mathcal{P}$ computes array $\\mathsf{Acc_j}$ as follows for $j \\in [1,2]$: $\\mathsf{Acc_j}[n-1]\\leftarrow\\mathsf{Arr_j}[n-1]$ $\\mathsf{Acc_j}[i]\\leftarrow\\mathsf{Arr_j}[i]+\\mathsf{Acc_j}[i+1]$ for $i$ from $n-2$ to 0 Polynomial Level # We assume arrays $\\mathsf{Arr_1}$, $\\mathsf{Arr_2}$, $\\mathsf{Acc_1}$ and $\\mathsf{Acc_2}$ are encoded as the y-coordinates into a univariant polynomial where the x-coordinates (called the domain $\\mathcal{H}_\\kappa$) are chosen as the multiplicative group of order $\\kappa$ with generator $\\omega\\in\\mathbb{G}_\\kappa$ (see Background for more). In short, $\\omega^0$ is the first element and $\\omega^{\\kappa-1}$ is the last element of $\\mathcal{H}_\\kappa$. If $\\kappa$ is larger than the length of the array, the array can be padded with elements of value 0 (which will not change the sum).\nRecall the five constraints we want to prove:\nThe first value in $\\mathsf{Acc_1}$ matches the first value in $\\mathsf{Arr_1}$ The first value in $\\mathsf{Acc_2}$ matches the first value in $\\mathsf{Arr_2}$ The rest of the values in $\\mathsf{Acc}_1$ are of the form $\\mathsf{Acc_1}[i]=\\mathsf{Arr_1}[i]+\\mathsf{Acc_1}[i-1]$ The rest of the values in $\\mathsf{Acc}_2$ are of the form $\\mathsf{Acc_2}[i]=\\mathsf{Arr_2}[i]+\\mathsf{Acc_2}[i-1]$ The last value in $\\mathsf{Acc_1}$ matches the last value in $\\mathsf{Acc_2}$ In polynomial form, the constraints are:\nFor $X=w^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Acc_1}(X)=\\mathsf{Poly}_\\mathsf{Arr_1}(X)$, For $X=w^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Acc_2}(X)=\\mathsf{Poly}_\\mathsf{Arr_2}(X)$, For all $X$ except $X=\\omega^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Acc_1}(X)=\\mathsf{Poly}_\\mathsf{Arr_1}(X)+\\mathsf{Poly}_\\mathsf{Acc_1}(\\omega\\cdot X)$ For all $X$ except $X=\\omega^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Acc_2}(X)=\\mathsf{Poly}_\\mathsf{Arr_2}(X)+\\mathsf{Poly}_\\mathsf{Acc_2}(\\omega\\cdot X)$ For $X=w^0$: $\\mathsf{Poly}_\\mathsf{Acc_1}(X)=\\mathsf{Poly}_\\mathsf{Acc_2}(X)$ In constraints 2 and 3, $\\mathsf{Poly}_\\mathsf{Acc}(\\omega\\cdot X)$ can also be conceptualized as rotate applied to $\\mathsf{Poly}_\\mathsf{Acc}(X)$ by one element (rightward in the array view). Also note that constraints 2 and 3 do not hold at $X=\\omega^{\\kappa-1}$ because this value is defined by constraint 1 (for the last value of $X$, the \u0026ldquo;next\u0026rdquo; value, $\\omega X$, wraps back to the first element of the array which is a boundary condition).\nWe adjust each of these constraints to show an equality with 0:\nFor $X=w^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Acc_1}(X)-\\mathsf{Poly}_\\mathsf{Arr_1}(X)=0$, For $X=w^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Acc_2}(X)-\\mathsf{Poly}_\\mathsf{Arr_2}(X)=0$, For all $X$ except $X=\\omega^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Acc_1}(X)-\\mathsf{Poly}_\\mathsf{Arr_1}(X)+\\mathsf{Poly}_\\mathsf{Acc_1}(\\omega\\cdot X)=0$ For all $X$ except $X=\\omega^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Acc_2}(X)-\\mathsf{Poly}_\\mathsf{Arr_2}(X)+\\mathsf{Poly}_\\mathsf{Acc_2}(\\omega\\cdot X)=0$ For $X=w^0$: $\\mathsf{Poly}_\\mathsf{Acc_1}(X)-\\mathsf{Poly}_\\mathsf{Acc_2}(X)=0$ Next we take care of the \u0026ldquo;for $X$\u0026rdquo; conditions by zeroing out the rest of the polynomial that is not zero. See the gadget zero1 for more on why this works.\n$\\mathsf{Poly}_\\mathsf{Vanish1}(X)=(\\mathsf{Poly}_\\mathsf{Acc_1}(X)-\\mathsf{Poly}_\\mathsf{Arr_1}(X))\\cdot\\frac{(X^\\kappa-1)}{(X-\\omega^{\\kappa-1})}=0$, $\\mathsf{Poly}_\\mathsf{Vanish2}(X)=(\\mathsf{Poly}_\\mathsf{Acc_2}(X)-\\mathsf{Poly}_\\mathsf{Arr_2}(X))\\cdot\\frac{(X^\\kappa-1)}{(X-\\omega^{\\kappa-1})}=0$, $\\mathsf{Poly}_\\mathsf{Vanish3}(X)=(\\mathsf{Poly}_\\mathsf{Acc_1}(X)-(\\mathsf{Poly}_\\mathsf{Arr_1}(X)+\\mathsf{Poly}_\\mathsf{Acc_1}(\\omega\\cdot X)))\\cdot(X-\\omega^{\\kappa-1})=0$ $\\mathsf{Poly}_\\mathsf{Vanish4}(X)=(\\mathsf{Poly}_\\mathsf{Acc_2}(X)-(\\mathsf{Poly}_\\mathsf{Arr_2}(X)+\\mathsf{Poly}_\\mathsf{Acc_2}(\\omega\\cdot X)))\\cdot(X-\\omega^{\\kappa-1})=0$ $\\mathsf{Poly}_\\mathsf{Vanish5}(X)=(\\mathsf{Poly}_\\mathsf{Acc_1}(X)-\\mathsf{Poly}_\\mathsf{Acc_2}(X)\\cdot\\frac{(X^\\kappa-1)}{(X-\\omega^0)}=0$ These equations are true for every value of $X \\in \\mathcal{H}_\\kappa$ (but not necessarily true outside of these values). To show this, we divide each polynomial by $X^\\kappa - 1$, which is a minimal vanishing polynomial for $\\mathcal{H}_\\kappa$ that does not require interpolation to create. If the quotients are polynomials (and not rational functions), then $\\mathsf{Poly}_\\mathsf{Vanish1}(X)$, $\\mathsf{Poly}_\\mathsf{Vanish2}(X)$, $\\mathsf{Poly}_\\mathsf{Vanish3}(X)$, $\\mathsf{Poly}_\\mathsf{Vanish4}(X)$, and $\\mathsf{Poly}_\\mathsf{Vanish5}(X)$ must be vanishing on $\\mathcal{H}_\\kappa$ too. Specifically, the prove computes,\n$Q_1(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish1}(X)}{X^\\kappa - 1}$ $Q_2(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish2}(X)}{X^\\kappa - 1}$ $Q_3(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish3}(X)}{X^\\kappa - 1}$ $Q_4(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish4}(X)}{X^\\kappa - 1}$ $Q_5(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish5}(X)}{X^\\kappa - 1}$ We can replace polynomials $Q_1(X)$, $Q_2(X)$, $Q_3(X)$, $Q_4(X)$, and $Q_5(X)$ with a single polynomial $Q(X)$. We can do this because all three constraints have the same format: $\\mathsf{Poly}_\\mathsf{Vanish_i}(X)=0$. The batching technique is to create a new polynomial with all five $\\mathsf{Poly}_\\mathsf{Vanish_i}(X)$ values as coefficients. If and (overwhelmingly) only if all five are vanishing, then so will the new polynomial. This polynomial will be evaluated at a random challenge point $\\rho$ selected after the commitments to the earlier polynomials are fixed.\n$Q(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish1}(X) + \\mathsf{Poly}_\\mathsf{Vanish2}(X) \\rho + \\mathsf{Poly}_\\mathsf{Vanish3}(X)\\rho^2 + \\mathsf{Poly}_\\mathsf{Vanish4}(X)\\rho^3 + \\mathsf{Poly}_\\mathsf{Vanish5}(X)\\rho^4}{X^n - 1}$\nBy rearranging, we can get $\\mathsf{Poly}_\\mathsf{Zero}(X)$ as a true zero polynomial (zero at every value both in $\\mathcal{H}_\\kappa$ and outside of it):\n$\\mathsf{Poly}_\\mathsf{Zero}(X)=\\mathsf{Poly}_\\mathsf{Vanish1}(X) + \\mathsf{Poly}_\\mathsf{Vanish2} (X) \\rho + \\mathsf{Poly}_\\mathsf{Vanish3}(X) \\rho^2 + \\mathsf{Poly}_\\mathsf{Vanish4}(X)\\rho^3 + \\mathsf{Poly}_\\mathsf{Vanish5}(X)\\rho^4 - Q(X)\\cdot (X^n - 1)=0$\nUltimately the add3 argument will satisfy the following constraints at the Commitment Level:\nShow $Q(X)$ exists (as a polynomial that evenly divides the divisor) Show $\\mathsf{Poly}_\\mathsf{Zero}(X)$ is correctly constructed from $\\mathsf{Poly}_\\mathsf{Acc_1}(X)$, $\\mathsf{Poly}_\\mathsf{Acc_1}(\\omega X)$, $\\mathsf{Poly}_\\mathsf{Arr_1}(X)$, $\\mathsf{Poly}_\\mathsf{Acc_2}(X)$, $\\mathsf{Poly}_\\mathsf{Acc_2}(\\omega X)$, and $\\mathsf{Poly}_\\mathsf{Arr_2}(X)$ Show $\\mathsf{Poly}_\\mathsf{Zero}(X)$ is the zero polynomial Commitment Level # The verifier will never see the arrays or polynomials themselves. They are undisclosed because they either (i) contain private data or (ii) they are too large to examine and maintain a succinct proof system. Instead the prover will use commitments.\nThe prover will write the following commitments to the transcript:\n$K_\\mathsf{Arr_1}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr_1}(X))$ $K_\\mathsf{Acc_1}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Acc_1}(X))$ $K_\\mathsf{Arr_2}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr_2}(X))$ $K_\\mathsf{Acc_2}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Acc_2}(X))$ The prover will generate a random challenge evaluation point (using strong Fiat-Shamir) on the polynomial that is outside of $\\mathcal{H}_\\kappa$. Call this point $\\rho$. It will be used by the prover to create polynomial $Q(X)$ (see above) and the prover will write to the transcript:\n$\\rho$ $K_Q=\\mathsf{KZG.Commit}(Q(X))$ The prover will generate a second random challenge evaluation point (using strong Fiat-Shamir) on the polynomial that is outside of $\\mathcal{H}_\\kappa$. Call this point $\\zeta$. The prover will write the point and opening proofs to the transcript:\n$\\zeta$ $\\mathsf{Poly}_\\mathsf{Arr_1}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Arr_1},\\zeta)$ $\\mathsf{Poly}_\\mathsf{Acc_1}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Arr_1},\\zeta)$ $\\mathsf{Poly}_\\mathsf{Acc_1}(\\zeta\\omega)=\\mathsf{KZG.Open}(K_\\mathsf{Acc_1},\\zeta\\omega)$ $\\mathsf{Poly}_\\mathsf{Arr_2}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Arr_2},\\zeta)$ $\\mathsf{Poly}_\\mathsf{Acc_2}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Arr_2},\\zeta)$ $\\mathsf{Poly}_\\mathsf{Acc_2}(\\zeta\\omega)=\\mathsf{KZG.Open}(K_\\mathsf{Acc_2},\\zeta\\omega)$ $Q(\\zeta)=\\mathsf{KZG.Open}(K_Q,\\zeta)$ To check the proof, the verifier uses the transcript to construct the value $Y_\\mathsf{Zero}$ as follows:\n$Y_\\mathsf{Vanish1}= (\\mathsf{Poly}_\\mathsf{Acc_1}(\\zeta)-\\mathsf{Poly}_\\mathsf{Arr_1}(\\zeta))\\cdot\\frac{(\\zeta^\\kappa-1)}{(\\zeta-\\omega^{\\kappa-1})}$ $Y_\\mathsf{Vanish2}= (\\mathsf{Poly}_\\mathsf{Acc_2}(\\zeta)-\\mathsf{Poly}_\\mathsf{Arr_2}(\\zeta))\\cdot\\frac{(\\zeta^\\kappa-1)}{(\\zeta-\\omega^{\\kappa-1})}$ $Y_\\mathsf{Vanish3}=(\\mathsf{Poly}_\\mathsf{Acc_1}(\\zeta)-(\\mathsf{Poly}_\\mathsf{Arr_1}(\\zeta)+\\mathsf{Poly}_\\mathsf{Acc_1}(\\omega\\cdot \\zeta)))\\cdot(\\zeta-\\omega^{\\kappa-1})$ $Y_\\mathsf{Vanish4}= (\\mathsf{Poly}_\\mathsf{Acc_2}(\\zeta)-(\\mathsf{Poly}_\\mathsf{Arr_2}(\\zeta)+\\mathsf{Poly}_\\mathsf{Acc_2}(\\omega\\cdot \\zeta)))\\cdot(\\zeta-\\omega^{\\kappa-1})$ $Y_\\mathsf{Vanish5}= (\\mathsf{Poly}_\\mathsf{Acc_1}(\\zeta)-\\mathsf{Poly}_\\mathsf{Acc_2}(\\zeta)\\cdot\\frac{(\\zeta^\\kappa-1)}{(\\zeta-\\omega^0)}$ $Y_\\mathsf{Zero}=Y_\\mathsf{Vanish1} + \\rho Y_\\mathsf{Vanish2} + \\rho^2 Y_\\mathsf{Vanish3} + \\rho^3 Y_\\mathsf{Vanish4} + \\rho^4 Y_\\mathsf{Vanish5}- Q(\\zeta)\\cdot (\\zeta^n - 1)$ Finally, if the constraint system is true, the following constraint will be true (and will be false otherwise with overwhelming probability, due to the Schwartz-Zippel lemma on $\\rho$ and $\\zeta$) :\n$Y_\\mathsf{Zero}\\overset{?}{=}0$ Implementations # Security Proof # Completeness # Any honest prover can do the computations explained above and create an accepting proof.\nSoundness # We prove knowledge soundness in the Algebraic Group Model (AGM). To do so, we must prove that there exists an efficient extractor $\\mathcal{E}$ such that for any algebraic adversary $\\mathcal{A}$ the probability of $\\mathcal{A}$ winning the following game is $\\mathsf{negl}(\\lambda)$.\nGiven $[g, g^\\tau, g^{\\tau^2}, \\dots,g^{\\tau^{n-1}}]$ $\\mathcal{A}$ outputs commitments to $\\mathsf{Poly}_\\mathsf{Acc_1}(X)$, $\\mathsf{Poly}_\\mathsf{Arr_1}(X)$, $\\mathsf{Poly}_\\mathsf{Acc_{2}}(X)$, $\\mathsf{Poly}_\\mathsf{Arr_{2}}(X)$, $Q$\n$\\mathcal{E}$, given access to $\\mathcal{A}$\u0026rsquo;s outputs from the previous step, outputs $\\mathsf{Poly}_\\mathsf{Acc_1}(X)$, $\\mathsf{Poly}_\\mathsf{Arr_1}(X)$, $\\mathsf{Poly}_\\mathsf{Acc_{2}}(X)$, $\\mathsf{Poly}_\\mathsf{Arr_{2}}(X)$, $Q$\n$\\mathcal{A}$ plays the part of the prover in showing that $Y_\\mathsf{Zero}$ is zero at a random challenge $\\zeta$\n$\\mathcal{A}$ wins if:\ni) $\\mathcal{V}$ accepts at the end of the protocol\nii) $\\sum_{i = 0}^{n-1} \\mathsf{Arr_1}[i]\\neq\\sum_{i = 0}^{n-1} \\mathsf{Arr_2}[i]$\nOur proof is as follows:\nFor the second win condition to be fulfilled, one of the five constraints must be false. But then the $\\mathsf{Poly}_\\mathsf{Vanish}$ corresponding to that constraint is not vanishing on $\\mathcal{H}_\\kappa$, so $Q(X)$ is not a polynomial (it is a rational function). This means that $\\mathcal{A}$ cannot calcuated the correct commitment value $g^{Q(\\tau)}$ without solving the t-SDH. Thus, $\\mathcal{A}$ chooses an arbitrary value for $Q(\\tau)$ and sends $K_Q = g^{Q(\\tau)}$. It also sends commitments to $\\mathsf{Poly}_\\mathsf{Acc_1}(X)$, $\\mathsf{Poly}_\\mathsf{Arr_1}(X)$, $\\mathsf{Poly}_\\mathsf{Acc_2}(X)$, and $\\mathsf{Poly}_\\mathsf{Arr_2}(X)$. Each commitment $\\mathcal{A}$ has outputted is a linear combination of the elements in $[g, g^\\tau, g^{\\tau^2}, \\dots,g^{\\tau^{n-1}}]$. $\\mathcal{E}$ is given these coefficients (since $\\mathcal{A}$ is an algebraic adversary) so $\\mathcal{E}$ can output the original polynomials.\n$\\mathcal{A}$ then obtains the random challenge $\\zeta$ (using strong Fiat-Shamir). By the binding property of KZG commitments, $\\mathsf{Poly}_\\mathsf{Arr_1}(\\zeta)$, $\\mathsf{Poly}_\\mathsf{Acc_1}(\\zeta)$, $\\mathsf{Poly}_\\mathsf{Acc_1}(\\zeta \\cdot \\omega)$, $\\mathsf{Poly}_\\mathsf{Arr_2}(\\zeta)$, $\\mathsf{Poly}_\\mathsf{Acc_2}(\\zeta)$, and $\\mathsf{Poly}_\\mathsf{Acc_2}(\\zeta \\cdot \\omega)$ can each only feasibliy be opened to one value. For $\\mathcal{A}$ to have the verifier accept, they must send a proof that $Q(\\zeta)$ opens to $Q(\\zeta) = \\frac{Y_\\mathsf{Vanish1} + \\rho Y_\\mathsf{Vanish2} + \\rho^2 Y_\\mathsf{Vanish3} + \\rho^3 Y_\\mathsf{Vanish4} + \\rho^4Y_\\mathsf{Vanish5}}{(\\zeta^n - 1)}$. This means being able to send $g^{q(\\tau)}$ where $q(\\tau) = \\frac{Q(\\tau) - Q(\\zeta)}{\\tau - \\zeta}$ and $Q(\\zeta) = \\frac{Y_\\mathsf{Vanish1} + \\rho Y_\\mathsf{Vanish2} + \\rho^2 Y_\\mathsf{Vanish3} + \\rho^3 Y_\\mathsf{Vanish4} + \\rho^4Y_\\mathsf{Vanish5}}{(\\zeta^n - 1)}$. Since $Q(\\tau)$ and $Q(\\zeta)$ are known, this implies knowing $g^{\\frac{1}{\\tau - \\zeta}}$. Thus $\\mathcal{A}$ would have found $\\langle\\zeta,g^{\\frac{1}{\\tau - \\zeta}}\\rangle$, which is the t-SDH problem. We have shown that creating an accepting proof reduces to the t-SDH, so $\\mathcal{A}$\u0026rsquo;s probability of success is negligible.\nZero-Knowledge # We prove that the above protocol is zero-knowledge when $\\mathsf{PolyCommit}_\\mathsf{Ped}$ (from the KZG paper) is used for the polynomial commitments. We do so by constructing a probabilistic polynomial time simulator $\\mathcal{S}$ that knows the trapdoor $\\tau$, which, for every (possibly malicious) verifier $\\mathcal{V}$, can output a view of the execution of the protocol that is indistinguishable from the view produced by the real execution of the program.\nThe simulator $\\mathcal{S}$ choose arbitrary values for ${\\mathsf{Poly}_\\mathsf{Arr_1}(\\tau)}$, ${\\mathsf{Poly}_\\mathsf{Acc_1}(\\tau)}$, ${\\mathsf{Poly}_\\mathsf{Arr_2}(\\tau)}$ and $\\mathsf{Poly}_\\mathsf{Acc_2}(\\tau)$, then computes $g^{\\mathsf{Poly}_\\mathsf{Arr_1}(\\tau)}$, $g^{\\mathsf{Poly}_\\mathsf{Acc_1}(\\tau)}$, $g^{\\mathsf{Poly}_\\mathsf{Arr_2}(\\tau)}$, and $g^{\\mathsf{Poly}_\\mathsf{Acc_2}(\\tau)}$ to output as the commitments $K_\\mathsf{Arr_1}$, $ K_\\mathsf{Acc_1}$, $K_\\mathsf{Arr_2}$, and $ K_\\mathsf{Acc_2}$. $\\mathcal{S}$ then generates the challenge evaluation point $\\rho$ (by strong Fiat-Shamir) and computes $Q(\\tau)$ using $\\rho$ and the values they chose for ${\\mathsf{Poly}_\\mathsf{Arr_1}(\\tau)}$, ${\\mathsf{Poly}_\\mathsf{Acc_1}(\\tau)}$, ${\\mathsf{Poly}_\\mathsf{Arr_2}(\\tau)}$ and $\\mathsf{Poly}_\\mathsf{Acc_2}(\\tau)$. $\\mathcal{S}$ outputs the commitment $K_Q = g^{Q(\\tau)}$.\nNow, $\\mathcal{S}$ generates the second random challenge point $\\zeta$ (which we assume is not in $\\mathcal{H}_\\kappa$; if it is in $\\mathcal{H}_\\kappa$, $\\mathcal{S}$ simply restarts and runs from the beginning). This is once again by strong Fiat-Shamir. $\\mathcal{S}$ then create fake opening proofs for ${\\mathsf{Poly}_\\mathsf{Arr_1}(\\zeta)}$, ${\\mathsf{Poly}_\\mathsf{Acc_1}(\\zeta)}$, ${\\mathsf{Poly}_\\mathsf{Acc_1}(\\zeta \\cdot \\omega)}$, ${\\mathsf{Poly}_\\mathsf{Arr_2}(\\zeta)}$, ${\\mathsf{Poly}_\\mathsf{Acc_2}(\\zeta)}$, and $\\mathsf{Poly}_\\mathsf{Acc_2}(\\zeta\\cdot\\omega)$, to arbitrary values. This is done using the knowledge of $\\tau$, calculating the respective witness $q(\\tau) = \\frac{{f(\\tau) - f(\\zeta)}}{\\tau - \\zeta}$ for each of the polynomials.\nFinally, $\\mathcal{S}$ creates a fake opening proof for $Q(\\zeta) = \\frac{Y_\\mathsf{Vanish1} + \\rho Y_\\mathsf{Vanish2} + \\rho^2 Y_\\mathsf{Vanish3} + \\rho^3 Y_\\mathsf{Vanish4} + \\rho^4Y_\\mathsf{Vanish5}}{(\\zeta^n - 1)}$. This is done using knowledge of $\\tau$ to calculate an accepting witness $q(\\tau)$, as above. This means that $Y_\\mathsf{Zero}$ will be zero, and the transcript will be accepted by the verifier. It is indistinguishable from a transcript generates from a real execution, since $\\mathsf{PolyCommit}_\\mathsf{Ped}$ has the property of Indistinguishability of Commitments due to the randomization by $h^{\\hat{\\phi}(x)}$.\nFor mult2, the proof is written with a simulator that doesn\u0026rsquo;t know the trapdoor; however, with small alterations the proof for mult2 should apply here and vice versa "},{"id":6,"href":"/docs/gadgets/lookup1/","title":"Lookup1","section":"Gadgets","content":" Lookup (Type 1) # Recap of types # Type Description Recap This lookup1 $\\mathsf{Arr}[i]\\in \\{0,1\\}$ Each element of array $\\mathsf{Arr}$ is in $\\{0,1\\}$ (or another small set). ‚úÖ lookup2 $\\mathsf{Arr}[i]\\in \\mathsf{Table}$ Each element of array $\\mathsf{Arr}$ is in a disclosed table of values $\\mathsf{Table}$. Relation # $ \\mathcal{R}_{\\mathtt{lookup1}} := \\left\\{ \\begin{array}{l} (K_\\mathsf{Arr}) \\end{array} \\middle | \\begin{array}{l} \\mathsf{Arr} = [a_0, a_1, a_2, \\dots, a_{n-1}], \\\\ \\mathsf{Poly}_\\mathsf{Arr}=\\mathsf{FFT.Interp}(\\omega,\\mathsf{Arr}), \\\\ K_\\mathsf{Arr}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr}), \\end{array} \\right\\} $\nIntuition # The prover ($\\mathcal{P}$) holds an array $\\mathsf{Arr}$ of $n$ integers from $\\mathbb{Z}_q$: $[a_0, a_1, a_2, \\dots, a_{n-1}]$. It will produce a succinct (independent of $n$) proof that each element in $\\mathsf{Arr}$ is in $\\{0,1\\}$ (or another small set). The prover will encode $\\mathsf{Arr}$ into the polynomial $\\mathsf{Poly}_\\mathsf{Arr}$ (using evaluation points on the domain $\\mathcal{H}_\\kappa$). It will commit to the polynomial: $K_\\mathsf{Arr}$. The verifier ($\\mathcal{V}$) cannot check any of the $\\mathsf{Arr}$ values directly (they may contain secret information, and even if they do not, they are too long to check) so the verifier only sees $K_\\mathsf{Arr}$.\nIn order to check that each element of $\\mathsf{Arr}$ is either 0 or 1, consider the expression $\\mathsf{Arr}[i] \\cdot (\\mathsf{Arr}[i] - 1)$. If $\\mathsf{Arr}[i]$ is 0, then the first part of the product is zero, and if $\\mathsf{Arr}[i]$ is 1, then the second part of the product is zero. If $\\mathsf{Arr}[i]$ is not 0 or 1, then the expression will be non-zero. Thus, to check our condition, it suffices to check that $\\mathsf{Arr}[i] \\cdot (\\mathsf{Arr}[i] - 1) = 0$ for $i$ from 0 to $n-1$.\nProtocol Details # Array Level # $\\mathcal{P}$ holds an array $\\mathsf{Arr} = [a_0, a_1, a_2, \\dots, a_{n-1}]$ of $n$ integers ($a_i \\in \\mathbb{Z}_q$) Polynomial Level # We assume that $\\mathsf{Arr}$ is encoded as the y-coordinates into a univariant polynomial where the x-coordinates (called the domain $\\mathcal{H}_\\kappa$) are chosen as the multiplicative group of order $\\kappa$ with generator $\\omega\\in\\mathbb{G}_\\kappa$ (see Background for more). In short, $\\omega^0$ is the first element and $\\omega^{\\kappa-1}$ is the last element of $\\mathcal{H}_\\kappa$. If $\\kappa$ is larger than the length of the array, the array can be padded with elements of value 0 or 1.\nRecall the constraint we want to prove:\n$\\mathsf{Arr}[i] \\cdot (\\mathsf{Arr}[i] - 1) = 0$ for $i$ from 0 to $n-1$ We write our constraint in polynomial form and label it:\nFor all $X$ from $\\omega^0$ to $\\omega^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Vanish}(X)=\\mathsf{Poly}_\\mathsf{Arr}(X) \\cdot (\\mathsf{Poly}_\\mathsf{Arr}(X) - 1) =0$ This equation is true for every value of $X \\in \\mathcal{H}_\\kappa$ (but not necessarily true outside of these values). To show this, we divide each polynomial by $X^\\kappa - 1$, which is a minimal vanishing polynomial for $\\mathcal{H}_\\kappa$ that does not require interpolation to create. If the quotient is polynomial (and not a rational function), then $\\mathsf{Poly}_\\mathsf{Vanish}(X)$ must be vanishing on $\\mathcal{H}_\\kappa$ too. Specifically, the prover computes:\n$Q(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish}(X)}{X^\\kappa - 1}$ By rearranging, we can get $\\mathsf{Poly}_\\mathsf{Zero}(X)$ as a true zero polynomial (zero at every value both in $\\mathcal{H}_\\kappa$ and outside of it):\n$\\mathsf{Poly}_\\mathsf{Zero}(X)=\\mathsf{Poly}_\\mathsf{Vanish}(X) - Q(X)\\cdot (X^n - 1)=0$ Ultimately the lookup1 argument will satisfy the following constraints at the Commitment Level:\nShow $Q(X)$ exists (as a polynomial that evenly divides the divisor) Show $\\mathsf{Poly}_\\mathsf{Zero}(X)$ is correctly constructed from $\\mathsf{Poly}_\\mathsf{Arr}(X)$ Show $\\mathsf{Poly}_\\mathsf{Zero}(X)$ is the zero polynomial Commitment Level # The verifier will never see the arrays or polynomials themselves. They are undisclosed because they either (i) contain private data or (ii) they are too large to examine and maintain a succinct proof system. Instead the prover will use commitments.\nThe prover will write the following commitments to the transcript:\n$K_\\mathsf{Arr}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr}(X))$ $K_Q=\\mathsf{KZG.Commit}(Q(X))$ The prover will generate a random challenge evaluation point (using strong Fiat-Shamir) on the polynomial that is outside of $\\mathcal{H}_\\kappa$. Call this point $\\zeta$. The prover will write the point and opening proofs to the transcript:\n$\\zeta$ $\\mathsf{Poly}_\\mathsf{Arr}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Arr},\\zeta)$ $Q(\\zeta)=\\mathsf{KZG.Open}(K_Q,\\zeta)$ To check the proof, the verifier uses the transcript to construct the value $Y_\\mathsf{Zero}$ as follows:\n$Y_\\mathsf{Vanish}=\\mathsf{Poly}_\\mathsf{Arr}(\\zeta) \\cdot (\\mathsf{Poly}_\\mathsf{Arr}(\\zeta) - 1)$ $Y_\\mathsf{Zero}=Y_\\mathsf{Vanish1} - Q(\\zeta)\\cdot (\\zeta^n - 1)$ Finally, if the constraint system is true, the following constraint will be true (and will be false otherwise with overwhelming probability, due to the Schwartz-Zippel lemma on $\\zeta$) :\n$Y_\\mathsf{Zero}\\overset{?}{=}0$ Implementations # Security Proof # Completeness # Any honest prover can do the computations explained above and create an accepting proof.\nSoundness # We prove knowledge soundness in the Algebraic Group Model (AGM). To do so, we must prove that there exists an efficient extractor $\\mathcal{E}$ such that for any algebraic adversary $\\mathcal{A}$ the probability of $\\mathcal{A}$ winning the following game is $\\mathsf{negl}(\\lambda)$.\nGiven $[g, g^\\tau, g^{\\tau^2}, \\dots,g^{\\tau^{n-1}}]$ $\\mathcal{A}$ outputs commitments to $\\mathsf{Poly}_\\mathsf{Arr}(X)$, $Q$\n$\\mathcal{E}$, given access to $\\mathcal{A}$\u0026rsquo;s outputs from the previous step, outputs $\\mathsf{Poly}_\\mathsf{Arr}(X)$, $Q$.\n$\\mathcal{A}$ plays the part of the prover in showing that $Y_{\\mathsf{Zero}}$ is zero at a random challenge $\\zeta$\n$\\mathcal{A}$ wins if:\ni) $\\mathcal{V}$ accepts at the end of the protocol\nii) $\\mathsf{Arr}[i]\\neq 0$ and $\\mathsf{Arr}[i]\\neq 1$ for some $i \\in [0, n-1]$\nOur proof is as follows:\nFor the second win condition to be fulfilled, there must be at least one entry is $\\mathsf{Arr}$ that is not 0 or 1. But then $\\mathsf{Poly}_\\mathsf{Vanish}(X)$ is not vanishing on $\\mathcal{H}_\\kappa$, so $Q(X)$ is not a polynomial (it is a rational function). This means that $\\mathcal{A}$ cannot calcuated the correct commitment value $g^{Q(\\tau)}$ without solving the t-SDH. Thus, $\\mathcal{A}$ chooses an arbitrary value for $Q(\\tau)$ and sends $K_Q = g^{Q(\\tau)}$. It also sends a commitment to $\\mathsf{Poly}_\\mathsf{Arr}(X)$. Both commitments $\\mathcal{A}$ has outputted is are linear combinations of the elements in $[g, g^\\tau, g^{\\tau^2}, \\dots,g^{\\tau^{n-1}}]$. $\\mathcal{E}$ is given these coefficients (since $\\mathcal{A}$ is an algebraic adversary) so $\\mathcal{E}$ can output the original polynomials.\n$\\mathcal{A}$ then obtains the random challenge $\\zeta$ (using strong Fiat-Shamir). By the binding property of KZG commitments, $\\mathsf{Poly}_\\mathsf{Arr}(\\zeta)$, can only feasibliy be opened to one value. For $\\mathcal{A}$ to have the verifier accept, it must send a proof that $Q(\\zeta)$ opens to $Q(\\zeta) = \\frac{Y_\\mathsf{Vanish1}}{(\\zeta^n - 1)}$. This means being able to send $g^{q(\\tau)}$ where $q(\\tau) = \\frac{Q(\\tau) - Q(\\zeta)}{\\tau - \\zeta}$ and $Q(\\zeta) = \\frac{Y_\\mathsf{Vanish1}}{(\\zeta^n - 1)}$. Since $Q(\\tau)$ and $Q(\\zeta)$ are known, this implies knowing $g^{\\frac{1}{\\tau - \\zeta}}$. Thus $\\mathcal{A}$ would have found $\\langle\\zeta,g^{\\frac{1}{\\tau - \\zeta}}\\rangle$, which is the t-SDH problem. We have shown that creating an accepting proof reduces to the t-SDH, so $\\mathcal{A}$\u0026rsquo;s probability of success is negligible.\nZero-Knowledge # We prove that the above protocol is zero-knowledge when $\\mathsf{PolyCommit}_\\mathsf{Ped}$ (from the KZG paper) is used for the polynomial commitments. We do so by constructing a probabilistic polynomial time simulator $\\mathcal{S}$ that knows the trapdoor $\\tau$, which, for every (possibly malicious) verifier $\\mathcal{V}$, can output a view of the execution of the protocol that is indistinguishable from the view produced by the real execution of the program.\nThe simulator $\\mathcal{S}$ choose an arbitrary value for ${\\mathsf{Poly}_\\mathsf{Arr}(\\tau)}$, then computes $g^{\\mathsf{Poly}_\\mathsf{Arr}(\\tau)}$ to output as the commitment $ K_\\mathsf{Arr}$. $\\mathcal{S}$ then generates the challenge evaluation point $\\rho$ (by strong Fiat-Shamir) and computes $Q(\\tau)$ using $\\rho$ and the value it chose for ${\\mathsf{Poly}_\\mathsf{Arr}(\\tau)}$. $\\mathcal{S}$ outputs the commitment $K_Q = g^{Q(\\tau)}$.\nNow, $\\mathcal{S}$ generates the second random challenge point $\\zeta$ (which we assume is not in $\\mathcal{H}_\\kappa$; if it is in $\\mathcal{H}_\\kappa$, $\\mathcal{S}$ simply restarts and runs from the beginning). This is once again by strong Fiat-Shamir. $\\mathcal{S}$ then create fake opening proofs for ${\\mathsf{Poly}_\\mathsf{Arr}(\\zeta)}$, to an arbitrary value. This is done using the knowledge of $\\tau$, calculating the witness polynomial $q(\\tau) = \\frac{{f(\\tau) - f(\\zeta)}}{\\tau - \\zeta}$.\nFinally, $\\mathcal{S}$ creates a fake opening proof for $Q(\\zeta) = \\frac{Y_\\mathsf{Vanish1}}{(\\zeta^n - 1)}$. This is done using knowledge of $\\tau$ to calculate an accepting witness $q(\\tau)$, as above. This means that $Y_\\mathsf{Zero}$ will be zero, and the transcript will be accepted by the verifier. It is indistinguishable from a transcript generates from a real execution, since $\\mathsf{PolyCommit}_\\mathsf{Ped}$ has the property of Indistinguishability of Commitments due to the randomization by $h^{\\hat{\\phi}(x)}$.\n"},{"id":7,"href":"/docs/gadgets/lookup2/","title":"Lookup2","section":"Gadgets","content":" Lookup (Type 2) # Recap of types # Type Description Recap This lookup1 $\\mathsf{Arr}[i]\\in \\{0,1\\}$ Each element of array $\\mathsf{Arr}$ is in $\\{0,1\\}$ (or another small set). lookup2 $\\mathsf{Arr}[i]\\in \\mathsf{Table}$ Each element of array $\\mathsf{Arr}$ is in a disclosed table of values $\\mathsf{Table}$. ‚úÖ Relation # $ \\mathcal{R}_{\\mathtt{lookup2}} := \\left\\{ \\begin{array}{l} (\\mathsf{Arr},\\mathsf{T}) \\end{array} \\middle | \\begin{array}{l} \\mathsf{Arr}[i]\\in\\mathsf{T}, 0\\leq i \\leq n-1, \\\\ \\mathsf{Poly}_\\mathsf{Arr}=\\mathsf{FFT.Interp}(\\omega,\\mathsf{Arr}), \\\\ \\mathsf{Poly}_\\mathsf{T}=\\mathsf{FFT.Interp}(\\omega,\\mathsf{T}), \\\\ K_\\mathsf{Arr}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr}), \\\\ K_\\mathsf{T}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{T}), \\end{array} \\right\\} $\nIntuition # The prover ($\\mathcal{P}$) holds an array $\\mathsf{Arr}$ of $n$ integers from $\\mathbb{Z}_q$: $[a_0, a_1, a_2, \\dots, a_{n-1}]$. It will produce a succinct (independent of $n$) proof that each value in $\\mathsf{Arr}$ is the element of a public table $\\mathsf{T}$. The prover will encode $\\mathsf{Arr}$ and $\\mathsf{T}$ into polynomials: $\\mathsf{Poly}_\\mathsf{Arr}$ and $\\mathsf{Poly}_\\mathsf{T}$. Assume $\\mathsf{Arr}$ is equal to $\\mathsf{T}$, then the prover can complete the proof by simply performing the product check or the permutation check between $\\mathsf{Arr}$ and $\\mathsf{T}$. However, if $\\mathsf{Arr}$ is not equal to $\\mathsf{T}$ (this is the case we want to solve), the prover needs to reveal the points where $\\mathsf{Arr}$ equals to $\\mathsf{T}$, which makes zero knowledge impossible. Thus, the prover needs to construct auxiliary polynomial(s) to prove the constraints between $\\mathsf{Arr}$ and $\\mathsf{T}$ are desired.\nThere are different approaches to achieving the lookup argument, e.g., halo2 and Plookup. We will discuss these two approaches as follows.\nhalo2 # The lookup argument in halo2 requires the prover to construct two auxiliary vectors, $\\mathsf{Arr}^\\prime$ and $\\mathsf{T}^\\prime$, where $\\mathsf{Arr}^\\prime$ is the permutation of $\\mathsf{Arr}$ and sorted (ascending or descending does not matter), $\\mathsf{T}^\\prime$ is the permutation of $\\mathsf{T}$ and sorted by $\\mathsf{Arr}$. For any two sets $A,B$ such that $A\\subset{B}$, we say $B$ is sorted by $A$ when the elements in $A$ have the same order as they do in $B$. Let us demonstrate the halo2 lookup argument with a concrete example, $\\mathsf{Arr}=\\{1,2,1,6,4,5,3,0\\},\\mathsf{T}=\\mathbb{Z}_8$. The prover constructs $\\mathsf{Arr}^\\prime$ and $\\mathsf{T}^\\prime$ such that $$ \\mathsf{Arr}^\\prime=\\{0,1,1,2,3,4,5,6\\} $$ $$ \\mathsf{T}^\\prime=\\{0,1,7,2,3,4,5,6\\} $$ We can observe that $\\mathsf{Arr}^\\prime[i]$ is equal to $\\mathsf{T}^\\prime[i]$ or $\\mathsf{Arr}^\\prime[i-1]$. Since $\\mathsf{Arr}^\\prime[i-1]$ does not exist when $i=0$, we have to enforce the other rule, $\\mathsf{Arr}^\\prime[0]=\\mathsf{T}^\\prime[0]$. With these two constraints and the proof that $\\mathsf{Arr}^\\prime$ is the permutation of $\\mathsf{Arr}$ and $\\mathsf{T}^\\prime$ is the permutation of $\\mathsf{T}$, the prover can prove each element in $\\mathsf{Arr}$ exists in $\\mathsf{T}$.\nPlookup # Unlike halo2, Plookup requires only one auxiliary vector, $\\mathsf{S}$, where $\\mathsf{S}$ is the union set of $\\mathsf{Arr}$ and $\\mathsf{T}$, and sorted by $\\mathsf{T}$. The prover encodes $\\mathsf{Arr}$, $\\mathsf{T}$, and $\\mathsf{S}$ into polynomials: $\\mathsf{Poly}_\\mathsf{Arr}$, $\\mathsf{Poly}_\\mathsf{T}$, and $\\mathsf{Poly}_\\mathsf{S}$, and computes $\\prod{\\mathsf{Poly}_\\mathsf{Arr}\\cdot\\prod\\mathsf{Poly}_\\mathsf{T}}$ and $\\prod{\\mathsf{Poly}_\\mathsf{S}}$ with some random challenges. The theorem tells us the two products are equal if and only if: $\\mathsf{Arr}\\subset\\mathsf{T}$, and $\\mathsf{S}=(\\mathsf{Arr},\\mathsf{T})$ and sorted by $\\mathsf{T}$.\nProtocol Details # halo2 # Array Level # $\\mathcal{P}$ and $\\mathcal{V}$ are given a public table $\\mathsf{T}$ $\\mathcal{P}$ holds an array $\\mathsf{Arr}=[a_0,a_1,a_2,\\dots,a_{n-1}]$ of $n$ integers ($a_i\\in\\mathbb{Z}_q$) $\\mathcal{P}$ computes an array $\\mathsf{Arr}^\\prime=[a_0^\\prime,a_1^\\prime,a_2^\\prime,\\dots,a_{n-1}^\\prime]$ of $n$ integers ($a_i^\\prime\\in\\mathbb{Z}_q$) such that: $\\mathsf{Arr}^\\prime$ is a permutation of $\\mathsf{Arr}$ and sorted in ascending or descending $\\mathcal{P}$ computes an array $\\mathsf{T}^\\prime$ such that: $\\mathsf{T}^\\prime$ is a permutation of $\\mathsf{T}$ and sorted by $\\mathsf{Arr}^\\prime$ $\\mathsf{Arr}^\\prime$ and $\\mathsf{T}^\\prime$ have the following relations: $\\mathsf{Arr}^\\prime[0]=\\mathsf{T}^\\prime[0]$ $\\mathsf{Arr}^\\prime[i]=\\mathsf{T}^\\prime[i]\\mid\\mathsf{Arr}^\\prime[i-1],i\\ne{0}$ Polynomial Level # We assume arrays $\\mathsf{Arr}$, $\\mathsf{Arr}^\\prime$, $\\mathsf{T}$, and $\\mathsf{T}^\\prime$ are encoded as the y-coordinates into a univariant polynomial where the x-coordinates (called the domain $\\mathcal{H}_\\kappa$) are chosen as the multiplicative group of order $\\kappa$ with generator $\\omega\\in\\mathbb{G}_\\kappa$ (see Background for more). In short, $\\omega^0$ is the first element and $\\omega^{\\kappa-1}$ is the last element of $\\mathcal{H}_\\kappa$. If $\\kappa$ is larger than the length of the array, the array can be padded with elements of value 1 (which will not change the product).\nRecall the four constraints we want to prove:\n$\\mathsf{Arr}^\\prime$ is a permutation of $\\mathsf{Arr}$ $\\mathsf{T}^\\prime$ is a permutation of $\\mathsf{T}$ The first value in $\\mathsf{Arr}^\\prime$ equals to the first value in $\\mathsf{T}^\\prime$ The rest of the values in $\\mathsf{Arr}^\\prime$ are of the form $\\mathsf{Arr}^\\prime[i]=\\mathsf{T}^\\prime[i]\\mid\\mathsf{Arr}^\\prime[i-1],i\\ne{0}$ In polynomial form, the constraints are ($\\alpha,\\beta$ are challenges from $\\mathcal{V}$):\n$\\prod[\\alpha-\\mathsf{Poly}_{\\mathsf{Arr}}(X)]=\\prod[\\alpha-\\mathsf{Poly}_{\\mathsf{Arr}^\\prime}(X)]$ $\\prod[\\beta-\\mathsf{Poly}_{\\mathsf{T}}(X)]=\\prod[\\beta-\\mathsf{Poly}_{\\mathsf{T}^\\prime}(X)]$ For $X=\\omega^0$: $\\mathsf{Poly}_{\\mathsf{Arr}^\\prime}(X)=\\mathsf{Poly}_{\\mathsf{T}^\\prime}(X)$ For all $X\\in\\mathcal{H}_\\kappa\\setminus{\\omega^0}$: $[\\mathsf{Poly}_{\\mathsf{Arr}^\\prime}(X)-\\mathsf{Poly}_{\\mathsf{T}^\\prime}(X)]\\cdot[\\mathsf{Poly}_{\\mathsf{Arr}^\\prime}(X)-\\mathsf{Poly}_{\\mathsf{Arr}^\\prime}(X\\cdot\\omega^{-1})]=0$ We take care of the \u0026ldquo;for $X$\u0026rdquo; conditions by zeroing out the rest of the polynomial that is not zero. See the gadget zero1 for more on why this works.\n$\\mathsf{Poly}_\\mathsf{Vanish1}(X)=\\prod[\\alpha-\\mathsf{Poly}_{\\mathsf{Arr}}(X)]-\\prod[\\alpha-\\mathsf{Poly}_{\\mathsf{Arr}^\\prime}(X)]=0$ $\\mathsf{Poly}_\\mathsf{Vanish2}(X)=\\prod[\\beta-\\mathsf{Poly}_{\\mathsf{T}}(X)]-\\prod[\\beta-\\mathsf{Poly}_{\\mathsf{T}^\\prime}(X)]=0$ $\\mathsf{Poly}_\\mathsf{Vanish3}(X)=[\\mathsf{Poly}_{\\mathsf{Arr^\\prime}}(X)-\\mathsf{Poly}_{\\mathsf{T^\\prime}}(X)]\\cdot\\frac{X^\\kappa-1}{X-\\omega^0}=0$ $\\mathsf{Poly}_\\mathsf{Vanish4}(X)=[\\mathsf{Poly}_{\\mathsf{Arr}^\\prime}(X)-\\mathsf{Poly}_{\\mathsf{T}^\\prime}(X)]\\cdot[\\mathsf{Poly}_{\\mathsf{Arr}^\\prime}(X)-\\mathsf{Poly}_{\\mathsf{Arr}^\\prime}(X\\cdot\\omega^{-1})]\\cdot(X-\\omega^0)=0$ Instead of proving $\\mathsf{Poly}_\\mathsf{Vanish1}$ and $\\mathsf{Poly}_\\mathsf{Vanish2}$ are vanishing through two permutation checks, we can construct an accumulator $\\mathsf{Poly}_\\mathsf{Z}$ to make it more efficient (the domain needs to be expanded to $2\\kappa$, denoted by $k$):\n$\\mathsf{Poly}_\\mathsf{Z}(\\omega^0)=\\mathsf{Poly}_\\mathsf{Z}(\\omega^{k-1})=1$ For all $X\\in\\mathcal{H}_\\kappa\\setminus{\\omega^{k-1}}$: $\\mathsf{Poly}_\\mathsf{Z}(X\\cdot\\omega)=\\mathsf{Poly}_\\mathsf{Z}(X)\\cdot\\frac{[\\mathsf{Poly}_\\mathsf{Arr}(X)+\\alpha]\\cdot[\\mathsf{Poly}_\\mathsf{T}(X)+\\beta]}{[\\mathsf{Poly}_\\mathsf{Arr^\\prime}(X)+\\alpha]\\cdot[\\mathsf{Poly}_\\mathsf{T^\\prime}(X)+\\beta]}$ Now we have the new $\\mathsf{Poly}_\\mathsf{Vanish1}$ and $\\mathsf{Poly}_\\mathsf{Vanish2}$:\n$\\mathsf{Poly}_\\mathsf{Vanish1}=[\\mathsf{Poly}_\\mathsf{Z}(X)-1]\\cdot\\frac{X^k-1}{(X-\\omega^0)\\cdot(X-\\omega^{k-1})}=0$ $\\mathsf{Poly}_\\mathsf{Vanish2}=\\{\\mathsf{Poly}_\\mathsf{Z}(X\\cdot\\omega)\\cdot[\\mathsf{Poly}_\\mathsf{Arr^\\prime}(X)+\\alpha]\\cdot[\\mathsf{Poly}_\\mathsf{T^\\prime}(X)+\\beta]-\\mathsf{Poly}_\\mathsf{Z}(X)\\cdot[\\mathsf{Poly}_\\mathsf{Arr}(X)+\\alpha]\\cdot[\\mathsf{Poly}_\\mathsf{T}(X)+\\beta]\\}\\cdot(X-\\omega^{k-1})=0$ These equations are true for every value of $X \\in \\mathcal{H}_k$ (but not necessarily true outside of these values). To show this, we divide each polynomial by $X^k - 1$, which is a minimal vanishing polynomial for $\\mathcal{H}_k$ that does not require interpolation to create. If the quotients are polynomials (and not rational functions), then $\\mathsf{Poly}_\\mathsf{Vanish1}(X)$, $\\mathsf{Poly}_\\mathsf{Vanish2}(X)$, $\\mathsf{Poly}_\\mathsf{Vanish3}(X)$, and $\\mathsf{Poly}_\\mathsf{Vanish4}(X)$ must be vanishing on $\\mathcal{H}_k$ too. Specifically, the prover computes,\n$Q_1(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish1}(X)}{X^k - 1}$ $Q_2(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish2}(X)}{X^k - 1}$ $Q_3(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish3}(X)}{X^k - 1}$ $Q_4(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish4}(X)}{X^k - 1}$ Instead of proving the four polynomials are zero polynomials one by one, we can linearly combine the four polynomials with a random challenge $\\rho$ sent by $\\mathcal{V}$ to compute:\n$W(X)=\\mathsf{Poly}_\\mathsf{Vanish1}(X)+\\rho\\cdot{\\mathsf{Poly}_\\mathsf{Vanish2}(X)}+\\rho^2\\cdot{\\mathsf{Poly}_\\mathsf{Vanish3}(X)}+\\rho^3\\cdot{\\mathsf{Poly}_\\mathsf{Vanish4}(X)}=0$ When $\\mathsf{Poly}_\\mathsf{Vanish1}(X),\\mathsf{Poly}_\\mathsf{Vanish2}(X),\\mathsf{Poly}_\\mathsf{Vanish3}(X),\\mathsf{Poly}_\\mathsf{Vanish4}(X)$ are vanishing on the domain $\\mathcal{H}_k$, $W(X)$ is also vanishing with high probability. Again, if and only if $W(X)$ is vanishing over the field $\\mathcal{H}_k$, $Q(X)=W(X)/(X^k-1)$ exists.\nBy rearranging, we can get $\\mathsf{Poly}_\\mathsf{Zero}(X)$ as a true zero polynomial (zero at every value both in $\\mathcal{H}_\\kappa$ and outside of it): $$ \\mathsf{Poly}_\\mathsf{Zero}(X)=\\mathsf{Poly}_\\mathsf{Vanish1}(X)+\\rho\\cdot\\mathsf{Poly}_\\mathsf{Vanish2}(X)+\\rho^2\\cdot\\mathsf{Poly}_\\mathsf{Vanish3}(X)+\\rho^3\\cdot\\mathsf{Poly}_\\mathsf{Vanish4}(X)-Q(X)\\cdot(X^n-1)=0 $$ Ultimately the halo2 lookup argument will satisfy the following constraints at the Commitment Level:\nShow $Q(X)$ exists Show $\\mathsf{Poly}_\\mathsf{Zero}(X)$ is correctly constructed from $\\mathsf{Poly}_\\mathsf{Z}(X)$, $\\mathsf{Poly}_\\mathsf{Arr}(X)$, $\\mathsf{Poly}_\\mathsf{T}(X)$, $\\mathsf{Poly}_\\mathsf{Arr^\\prime}(X)$, and $\\mathsf{Poly}_\\mathsf{T^\\prime}(X)$ Show $\\mathsf{Poly}_\\mathsf{Zero}(X)$ is a zero polynomial Commitment Level # The verifier will never see the arrays or polynomials themselves. They are undisclosed because they either (i) contain private data or (ii) are too large to examine and maintain a succinct proof system. Instead, the prover will use commitments.\nThe prover will write the following commitments to the transcript:\n$K_\\mathsf{Z}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Z}(X))$ $K_\\mathsf{Arr}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr}(X))$ $K_\\mathsf{T}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{T}(X))$ $K_\\mathsf{Arr^\\prime}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr^\\prime}(X))$ $K_\\mathsf{T^\\prime}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{T^\\prime}(X))$ The prover will generate a random challenge evaluation point (using strong Fiat-Shamir) on the polynomial that is outside of $\\mathcal{H}_k$. Call this point $\\rho$. It will be used by the prover to create polynomial $Q(X)$ (see above) and the prover will write to the transcript:\n$\\rho$ $K_Q=\\mathsf{KZG.Commit}(Q(X))$ The prover will generate a second random challenge evaluation point (using strong Fiat-Shamir) on the polynomial that is outside of $\\mathcal{H}_k$. Call this point $\\zeta$. The prover will write the three points and opening proofs to the transcript:\n$\\zeta$ $\\mathsf{Poly}_\\mathsf{Z}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Z},\\zeta)$ $\\mathsf{Poly}_\\mathsf{Z}(\\zeta\\omega)=\\mathsf{KZG.Open}(K_\\mathsf{Z},\\zeta\\omega)$ $\\mathsf{Poly}_\\mathsf{Arr}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Arr},\\zeta)$ $\\mathsf{Poly}_\\mathsf{Arr^\\prime}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Arr^\\prime},\\zeta)$ $\\mathsf{Poly}_\\mathsf{Arr^\\prime}(\\zeta\\omega^{-1})=\\mathsf{KZG.Open}(K_\\mathsf{Arr^\\prime},\\zeta\\omega^{-1})$ $\\mathsf{Poly}_\\mathsf{T}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{T},\\zeta)$ $\\mathsf{Poly}_\\mathsf{T^\\prime}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{T^\\prime},\\zeta)$ $Q(\\zeta)=\\mathsf{KZG.Open}(K_Q,\\zeta)$ To check the proof, the verifier uses the transcript to construct the value $Y_\\mathsf{Zero}$ as follows:\n$Y_\\mathsf{Vanish1}=[\\mathsf{Poly}_\\mathsf{Z}(\\zeta)-1]\\cdot\\frac{(\\zeta^k-1)}{(\\zeta-\\omega^0)\\cdot(\\zeta-\\omega^{k-1})}$ $Y_\\mathsf{Vanish2}=\\{\\mathsf{Poly}_\\mathsf{Z}(\\zeta\\omega)\\cdot[\\mathsf{Poly}_\\mathsf{Arr^\\prime}(\\zeta)+\\alpha]\\cdot[\\mathsf{Poly}_\\mathsf{T^\\prime}(\\zeta)+\\beta]-\\mathsf{Poly}_\\mathsf{Z}(\\zeta)\\cdot[\\mathsf{Poly}_\\mathsf{Arr}(\\zeta)+\\alpha]\\cdot[\\mathsf{Poly}_\\mathsf{T}(\\zeta)+\\beta]\\}\\cdot(\\zeta-\\omega^{k-1})$ $Y_\\mathsf{Vanish3}=[\\mathsf{Poly}_{\\mathsf{Arr^\\prime}}(\\zeta)-\\mathsf{Poly}_{\\mathsf{T^\\prime}}(\\zeta)]\\cdot\\frac{\\zeta^k-1}{\\zeta-\\omega^0}$ $Y_\\mathsf{Vanish4}=[\\mathsf{Poly}_{\\mathsf{Arr}^\\prime}(\\zeta)-\\mathsf{Poly}_{\\mathsf{T}^\\prime}(\\zeta)]\\cdot[\\mathsf{Poly}_{\\mathsf{Arr}^\\prime}(\\zeta)-\\mathsf{Poly}_{\\mathsf{Arr}^\\prime}(\\zeta\\omega^{-1})]\\cdot(\\zeta-\\omega^0)$ $Y_\\mathsf{Zero}=Y_\\mathsf{Vanish1}+\\rho\\cdot{Y_\\mathsf{Vanish2}}+\\rho^2\\cdot{Y_\\mathsf{Vanish3}}+\\rho^3\\cdot{Y_\\mathsf{Vanish4}}-Q(\\zeta)\\cdot(\\zeta^k - 1)$ Finally, if the constraint system is true, the following constraint will be true (and will be false otherwise with overwhelming probability, due to the Schwartz-Zippel lemma on $\\rho$ and $\\zeta$) :\n$Y_\\mathsf{Zero}\\overset{?}{=}0$ Plookup # Array Level # $\\mathcal{P}$ and $\\mathcal{V}$ are given a public table $\\mathsf{T}=[t_0,t_1,t_2,\\dots,t_{d-1}]$ of $d$ integers ($t_i\\in\\mathbb{Z}_q$) $\\mathcal{P}$ holds an array $\\mathsf{Arr}=[a_0,a_1,a_2,\\dots,a_{n-1}]$ of $n$ integers ($a_i\\in\\mathbb{Z}_q$) $\\mathcal{P}$ constructs an array $\\mathsf{S}=(\\mathsf{Arr},\\mathsf{T})=[s_0,s_1,s_2,\\dots,s_{n+d-1}]$ of $n+d$ integers ($s_i\\in\\mathbb{Z}_q$) such that: $\\mathsf{S}$ is a union set of $\\mathsf{Arr}$ and $\\mathsf{T}$ $\\mathsf{S}$ is sorted by $\\mathsf{T}$ $\\mathsf{Arr}$, $\\mathsf{T}$, and $\\mathsf{S}$ have the following relations: For each $i\\in[0,d-1)$, there exists a $j\\in[0,n+d-1)$ such that $(t_i,t_{i+1})=(s_j,s_{j+1})$ Let $I$ be the set of those $d-1$ indices, and let $I^\\prime:=[0,n+d-1)\\setminus{I}$. For each $i\\in{I^\\prime}$, there exists a $j\\in[0,n)$ such that $s_i=s_{i+1}=a_{j}$ Polynomial Level # We assume arrays $\\mathsf{Arr}$, $\\mathsf{T}$, and $\\mathsf{S}$ are encoded as the y-coordinates into a univariant polynomial where the x-coordinates (called the domain $\\mathcal{H}_\\kappa$) are chosen as the multiplicative group of order $\\kappa$ with generator $\\omega\\in\\mathbb{G}_\\kappa$ (see Background for more). In short, $\\omega^0$ is the first element and $\\omega^{\\kappa-1}$ is the last element of $\\mathcal{H}_\\kappa$. If $\\kappa$ is larger than the length of the array, the array can be padded with elements of value 1 (which will not change the product).\nRecall the two constraints we want to prove:\nFor each $i\\in[0,d-1)$, there exists a $j\\in[0,n+d-1)$ such that $(t_i,t_{i+1})=(s_j,s_{j+1})$ Let $I$ be the set of those $d-1$ indices, and let $I^\\prime:=[0,n+d-1)\\setminus{I}$. For each $i\\in{I^\\prime}$, there exists a $j\\in[0,n)$ such that $s_i=s_{i+1}=a_{j}$ In polynomial form, the constraints are ($\\alpha,\\beta$ are challenges from $\\mathcal{V}$):\n$(1+\\beta)^n\\prod_{i\u003c{n}}[\\alpha+\\mathsf{Poly}_{\\mathsf{Arr}}(\\omega^i)]\\cdot\\prod_{i\u003c{d-1}}[\\alpha(1+\\beta)+\\mathsf{Poly}_{\\mathsf{T}}(\\omega^i)+\\beta\\mathsf{Poly}_{\\mathsf{T}}(\\omega^{i+1})]=\\prod_{i\u003c{n+d-1}}[\\alpha(1+\\beta)+\\mathsf{Poly}_{\\mathsf{S}}(\\omega^i)+\\beta\\mathsf{Poly}_{\\mathsf{S}}(\\omega^{i+1})]$ To efficiently prove the above polynomial holds, we can use a similar trick in halo2 lookup by constructing an accumulator :\n$\\mathsf{Poly}_\\mathsf{Z}(\\omega^0)=\\mathsf{Poly}_\\mathsf{Z}(\\omega^{n+d-1})=1$ For $i\\in[0,n+d-1)$: $\\mathsf{Poly}_\\mathsf{Z}(X\\omega)=\\mathsf{Poly}_\\mathsf{Z}(X)\\cdot\\frac{(1+\\beta)[\\alpha+\\mathsf{Poly}_{\\mathsf{Arr}}(X)]\\cdot[\\alpha(1+\\beta)+\\mathsf{Poly}_{\\mathsf{T}}(X)+\\beta\\mathsf{Poly}_{\\mathsf{T}}(X\\omega)]}{\\alpha(1+\\beta)+\\mathsf{Poly}_{\\mathsf{S}}(X)+\\beta\\mathsf{Poly}_{\\mathsf{S}}(X\\omega)}$ However, the above accumulator does not exist because the degree of the denominator, $\\mathsf{Poly}_\\mathsf{S}$, is different from $\\mathsf{Poly}_\\mathsf{Arr}$ and $\\mathsf{Poly}_\\mathsf{T}$. Specifically, there are $n$ elements in $\\mathsf{Arr}$, $d$ elements in $\\mathsf{T}$, but $n+d$ elements in $\\mathsf{S}$. Thus we have to decompose the denominator to make it have the same iteration as $\\mathsf{Arr}$ and $\\mathsf{T}$ do. It is worth noting for the numerator, the left term contains $\\mathsf{Poly}_\\mathsf{Arr}(X)$ while the right term contains $\\mathsf{Poly}_\\mathsf{T}(X)$ and $\\mathsf{Poly}_\\mathsf{T}(X\\omega)$. Therefore, it will be convenient to assume $d=n+1$. The order of $\\mathsf{S}$ is $2n+1$. To traverse $\\mathsf{S}$ in $n$ steps, we can halve it to $\\mathsf{S}_\\mathsf{l}=[s_0,s_1,\\dots,s_{n-1},s_n]$ and $\\mathsf{S}_\\mathsf{h}=[s_{n},s_{n+1},\\dots,s_{2n-1},s_{2n}]$, and prove $\\mathsf{S}_\\mathsf{l}[n]=\\mathsf{S}_\\mathsf{h}[0]$. Then we can compute the accumulator such that:\n$\\mathsf{Poly}_\\mathsf{Z}(\\omega^0)=\\mathsf{Poly}_\\mathsf{Z}(\\omega^n)=1$ For $X\\in\\mathcal{H}_n\\setminus{\\omega^n}$: $\\mathsf{Poly}_\\mathsf{Z}(X\\omega)=\\mathsf{Poly}_\\mathsf{Z}(X)\\cdot\\frac{(1+\\beta)[\\alpha+\\mathsf{Poly}_{\\mathsf{Arr}}(X)]\\cdot[\\alpha(1+\\beta)+\\mathsf{Poly}_{\\mathsf{T}}(X)+\\beta\\mathsf{Poly}_{\\mathsf{T}}(X\\omega)]}{[\\alpha(1+\\beta)+\\mathsf{Poly}_{\\mathsf{S}_\\mathsf{l}}(X)+\\beta\\mathsf{Poly}_{\\mathsf{S}_\\mathsf{l}}(X\\omega)]\\cdot[\\alpha(1+\\beta)+\\mathsf{Poly}_{\\mathsf{S}_\\mathsf{h}}(X)+\\beta\\mathsf{Poly}_{\\mathsf{S}_\\mathsf{h}}(X\\omega)]}$ For $X=\\omega^n$: $\\mathsf{Poly}_{\\mathsf{S}_\\mathsf{l}}(X)=\\mathsf{Poly}_{\\mathsf{S}_\\mathsf{h}}(X\\omega^{n+1})$ Similarly, we take care of the \u0026ldquo;for $X$\u0026rdquo; conditions by zeroing out the rest of the polynomial that is not zero. See the gadget zero1 for more on why this works.\n$\\mathsf{Poly}_\\mathsf{Vanish1}(X)=[\\mathsf{Poly}_{\\mathsf{Z}}(X)-1]\\cdot\\frac{X^n-1}{(X-\\omega^0)(X-\\omega^n)}=0$ $\\displaylines{\\mathsf{Poly}_\\mathsf{Vanish2}(X)=\\{\\mathsf{Poly}_\\mathsf{Z}(X\\omega)\\cdot[\\alpha(1+\\beta)+\\mathsf{Poly}_{\\mathsf{S}_\\mathsf{l}}(X)+\\beta\\mathsf{Poly}_{\\mathsf{S}_\\mathsf{l}}(X\\omega)]\\cdot[\\alpha(1+\\beta)+\\mathsf{Poly}_{\\mathsf{S}_\\mathsf{h}}(X)+\\beta\\mathsf{Poly}_{\\mathsf{S}_\\mathsf{h}}(X\\omega)]-\\\\\\mathsf{Poly}_\\mathsf{Z}(X)\\cdot(1+\\beta)[\\alpha+\\mathsf{Poly}_{\\mathsf{Arr}}(X)]\\cdot[\\alpha(1+\\beta)+\\mathsf{Poly}_{\\mathsf{T}}(X)+\\beta\\mathsf{Poly}_{\\mathsf{T}}(X\\omega)]\\}\\cdot(X-\\omega^n)}=0$ $\\mathsf{Poly}_\\mathsf{Vanish3}(X)=[\\mathsf{Poly}_{\\mathsf{S}_\\mathsf{l}}(X)-\\mathsf{Poly}_{\\mathsf{S}_\\mathsf{h}}(X\\omega^{n+1})]\\cdot\\frac{X^n-1}{X-\\omega^n}=0$ These equations are true for every value of $X\\in\\mathcal{H}_n$ (but not necessarily true outside of these values). To show this, we divide each polynomial by $X^n-1$, which is a minimal vanishing polynomial for $\\mathcal{H}_n$ that does not require interpolation to create. If the quotients are polynomials (and not rational functions), then $\\mathsf{Poly}_\\mathsf{Vanish1}(X)$, $\\mathsf{Poly}_\\mathsf{Vanish2}(X)$, and $\\mathsf{Poly}_\\mathsf{Vanish3}(X)$ must be vanishing on $\\mathcal{H}_n$ too. Specifically, the prover computes,\n$Q_1(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish1}(X)}{X^n - 1}$ $Q_2(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish2}(X)}{X^n - 1}$ $Q_3(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish3}(X)}{X^n - 1}$ Instead of proving the three polynomials are zero polynomials one by one, we can linearly combine the three polynomials with a random challenge $\\rho$ sent by $\\mathcal{V}$ to compute:\n$W(X)=\\mathsf{Poly}_\\mathsf{Vanish1}(X)+\\rho\\cdot{\\mathsf{Poly}_\\mathsf{Vanish2}(X)}+\\rho^2\\cdot{\\mathsf{Poly}_\\mathsf{Vanish3}(X)}=0$ When $\\mathsf{Poly}_\\mathsf{Vanish1}(X),\\mathsf{Poly}_\\mathsf{Vanish2}(X),\\mathsf{Poly}_\\mathsf{Vanish3}(X)$ are vanishing on the domain $\\mathcal{H}_n$, $W(X)$ is also vanishing with high probability. Again, if and only if $W(X)$ is vanishing over the field $\\mathcal{H}_n$, $Q(X)=W(X)/(X^n-1)$ exists.\nBy rearranging, we can get $\\mathsf{Poly}_\\mathsf{Zero}(X)$ as a true zero polynomial (zero at every value both in $\\mathcal{H}_n$ and outside of it): $$ \\mathsf{Poly}_\\mathsf{Zero}(X)=\\mathsf{Poly}_\\mathsf{Vanish1}(X)+\\rho\\cdot\\mathsf{Poly}_\\mathsf{Vanish2}(X)+\\rho^2\\cdot\\mathsf{Poly}_\\mathsf{Vanish3}(X)-Q(X)\\cdot(X^n-1)=0 $$ Ultimately the Plookup will satisfy the following constraints at the Commitment Level:\nShow $Q(X)$ exists Show $\\mathsf{Poly}_\\mathsf{Zero}(X)$ is correctly constructed from $\\mathsf{Poly}_\\mathsf{Z}(X)$, $\\mathsf{Poly}_\\mathsf{Arr}(X)$, $\\mathsf{Poly}_\\mathsf{T}(X)$, $\\mathsf{Poly}_{\\mathsf{S}_\\mathsf{l}}(X)$, and $\\mathsf{Poly}_{\\mathsf{S}_\\mathsf{h}}(X)$ Show $\\mathsf{Poly}_\\mathsf{Zero}(X)$ is a zero polynomial Commitment Level # The verifier will never see the arrays or polynomials themselves. They are undisclosed because they either (i) contain private data or (ii) are too large to examine and maintain a succinct proof system. Instead, the prover will use commitments.\nThe prover will write the following commitments to the transcript:\n$K_\\mathsf{Z}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Z}(X))$ $K_\\mathsf{Arr}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr}(X))$ $K_\\mathsf{T}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{T}(X))$ $K_{\\mathsf{S}_\\mathsf{l}}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_{\\mathsf{S}_\\mathsf{l}}(X))$ $K_{\\mathsf{S}_\\mathsf{h}}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_{\\mathsf{S}_\\mathsf{h}}(X))$ The prover will generate a random challenge evaluation point (using strong Fiat-Shamir) on the polynomial that is outside of $\\mathcal{H}_n$. Call this point $\\rho$. It will be used by the prover to create polynomial $Q(X)$ (see above) and the prover will write to the transcript:\n$\\rho$ $K_Q=\\mathsf{KZG.Commit}(Q(X))$ The prover will generate a second random challenge evaluation point (using strong Fiat-Shamir) on the polynomial that is outside of $\\mathcal{H}_n$. Call this point $\\zeta$. The prover will write the three points and opening proofs to the transcript:\n$\\zeta$ $\\mathsf{Poly}_\\mathsf{Z}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Z},\\zeta)$ $\\mathsf{Poly}_\\mathsf{Z}(\\zeta\\omega)=\\mathsf{KZG.Open}(K_\\mathsf{Z},\\zeta\\omega)$ $\\mathsf{Poly}_\\mathsf{Arr}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Arr},\\zeta)$ $\\mathsf{Poly}_\\mathsf{T}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{T},\\zeta)$ $\\mathsf{Poly}_\\mathsf{T}(\\zeta\\omega)=\\mathsf{KZG.Open}(K_\\mathsf{T},\\zeta\\omega)$ $\\mathsf{Poly}_{\\mathsf{S}_\\mathsf{l}}(\\zeta)=\\mathsf{KZG.Open}(K_{\\mathsf{S}_\\mathsf{l}},\\zeta)$ $\\mathsf{Poly}_{\\mathsf{S}_\\mathsf{l}}(\\zeta\\omega)=\\mathsf{KZG.Open}(K_{\\mathsf{S}_\\mathsf{l}},\\zeta\\omega)$ $\\mathsf{Poly}_{\\mathsf{S}_\\mathsf{h}}(\\zeta)=\\mathsf{KZG.Open}(K_{\\mathsf{S}_\\mathsf{h}},\\zeta)$ $\\mathsf{Poly}_{\\mathsf{S}_\\mathsf{h}}(\\zeta\\omega)=\\mathsf{KZG.Open}(K_{\\mathsf{S}_\\mathsf{h}},\\zeta\\omega)$ $Q(\\zeta)=\\mathsf{KZG.Open}(K_Q,\\zeta)$ To check the proof, the verifier uses the transcript to construct the value $Y_\\mathsf{Zero}$ as follows:\n$Y_\\mathsf{Vanish1}=[\\mathsf{Poly}_\\mathsf{Z}(\\zeta)-1]\\cdot\\frac{(\\zeta^n-1)}{(\\zeta-\\omega^0)\\cdot(\\zeta-\\omega^n)}$ $\\displaylines{Y_\\mathsf{Vanish2}=\\{\\mathsf{Poly}_\\mathsf{Z}(\\zeta\\omega)\\cdot[\\alpha(1+\\beta)+\\mathsf{Poly}_{\\mathsf{S}_\\mathsf{l}}(\\zeta)+\\beta\\mathsf{Poly}_{\\mathsf{S}_\\mathsf{l}}(\\zeta\\omega)]\\cdot[\\alpha(1+\\beta)+\\mathsf{Poly}_{\\mathsf{S}_\\mathsf{h}}(\\zeta)+\\beta\\mathsf{Poly}_{\\mathsf{S}_\\mathsf{h}}(\\zeta\\omega)]-\\\\\\mathsf{Poly}_\\mathsf{Z}(\\zeta)\\cdot(1+\\beta)[\\alpha+\\mathsf{Poly}_\\mathsf{Arr}(\\zeta)]\\cdot[\\alpha(1+\\beta)+\\mathsf{Poly}_\\mathsf{T}(\\zeta)+\\beta\\mathsf{Poly}_\\mathsf{T}(\\zeta\\omega)]\\}\\cdot(\\zeta-\\omega^n)}$ $Y_\\mathsf{Vanish3}=[\\mathsf{Poly}_{\\mathsf{S}_\\mathsf{l}}(\\zeta)-\\mathsf{Poly}_{\\mathsf{S}_\\mathsf{l}}(\\zeta\\omega^{n+1})]\\cdot\\frac{\\zeta^n-1}{\\zeta-\\omega^n}$ $Y_\\mathsf{Zero}=Y_\\mathsf{Vanish1}+\\rho\\cdot{Y_\\mathsf{Vanish2}}+\\rho^2\\cdot{Y_\\mathsf{Vanish3}}-Q(\\zeta)\\cdot(\\zeta^k - 1)$ Finally, if the constraint system is true, the following constraint will be true (and will be false otherwise with overwhelming probability, due to the Schwartz-Zippel lemma on $\\rho$ and $\\zeta$) :\n$Y_\\mathsf{Zero}\\overset{?}{=}0$ Security Proof # halo2 # Completeness # Any honest prover can do the computations explained above and create an accepting proof.\nSoundness # We prove knowledge soundness in the Algebraic Group Model (AGM). To do so, we must prove that there exists an efficient extractor $\\mathcal{E}$ such that for any algebraic adversary $\\mathcal{A}$ the probability of $\\mathcal{A}$ winning the following game is $\\mathsf{negl}(\\lambda)$.\nGiven $[g,g^\\tau,g^{\\tau^2},\\dots,g^{\\tau^{n-1}}]$, $\\mathcal{A}$ outputs commitments to $\\mathsf{Poly}_\\mathsf{Arr}(X)$, $\\mathsf{Poly}_\\mathsf{Arr^\\prime}(X)$, $\\mathsf{Poly}_\\mathsf{T}(X)$, $\\mathsf{Poly}_\\mathsf{T^\\prime}(X)$, $Q$ $\\mathcal{E}$, given access to $\\mathcal{A}$\u0026rsquo;s outputs from the previous step, outputs $\\mathsf{Poly}_\\mathsf{Arr}(X)$, $\\mathsf{Poly}_\\mathsf{Arr^\\prime}(X)$, $\\mathsf{Poly}_\\mathsf{T}(X)$, $\\mathsf{Poly}_\\mathsf{T^\\prime}(X)$, $Q$ $\\mathcal{A}$ plays the part of the prover in showing that $Y_\\mathsf{Zero}$ is zero at a random challenge $\\zeta$ $\\mathcal{A}$ wins if $\\mathcal{V}$ accepts at the end of the protocol For some $i\\in[0,\\kappa-1]$, $\\mathsf{Arr}[i]\\notin\\mathsf{T}$ Our proof is as follows:\nTo make $Y_\\mathsf{Zero}$ a zero polynomial, $\\mathcal{A}$ has to prove the four vanishing polynomials are correct. For $\\mathsf{Poly}_\\mathsf{Vanish1}$ and $\\mathsf{Poly}_\\mathsf{Vanish2}$, the permutation check tells us the probability that $\\mathcal{V}$ accepts the proof is negligible if some elements in $\\mathsf{Arr}$ are not in $\\mathsf{T}$. By the Schwartz-Zippel lemma, we know the probability that $\\mathsf{Poly}_\\mathsf{Vanish3}$ is vanishing is negligible if $\\mathsf{Poly}_\\mathsf{Arr^\\prime}(\\omega^0)\\ne\\mathsf{Poly}_\\mathsf{T^\\prime}(\\omega^0)$. Therefore, to win the KS game, $\\mathcal{A}$ has to prove $\\mathsf{Poly}_\\mathsf{Vanish4}$ is correct with the winning condition (some elements in $\\mathsf{Arr}$ do not appear in $\\mathsf{T}$). Assume $\\mathsf{Arr}[i^\\prime]\\notin\\mathsf{T},i\u003e0$, to make such $\\mathsf{Poly}_\\mathsf{Vanish4}$ exist, $\\mathsf{Arr}[i^\\prime]$ has to equal to $\\mathsf{Arr}[i^\\prime-1]$. And because $\\mathsf{Arr}[i^\\prime-1]\\ne{\\mathsf{T}[i^\\prime-1]}$, $\\mathsf{Arr}[i^\\prime-1]$ has to equal to $\\mathsf{Arr}[i^\\prime-2]$. Thus, to make the winning condition hold, $\\mathsf{Arr}[i^\\prime]=\\mathsf{Arr}[0]$ must hold, which contradicts to the condition of $\\mathsf{Poly}_\\mathsf{Vanish3}$, $\\mathsf{Arr}[0]=\\mathsf{T}[0]$.\nZero-Knowledge # Before we prove the above protocol is zero-knowledge, it is worth noting the protocol is different from the lookup argument of halo2 in the real world. Specifically, the real halo2 lookup optimizes the two permutation checks into one and fills the table with some random numbers for the PLONK-based proof system. We refer to the official halo2 handbook to see the details. To prove the above protocol is zero-knowledge, we do so by constructing a probabilistic polynomial time simulator $\\mathcal{S}$ which, for every (possibly malicious) verifier $\\mathcal{V}$, can output a view of the execution of the protocol that is indistinguishable from the view produced by the real execution of the program.\nThe simulator $\\mathcal{S}$ generates an array $\\mathsf{Arr^*}$ by randomly filling it with elements from $\\mathsf{T}$, then follows the same steps a prover would prove the lookup argument. $\\mathcal{S}$ computes $\\mathsf{Arr^{*^\\prime}},\\mathsf{T^\\prime}$ and interpolates the four arrays into their respective polynomials, $\\mathsf{Poly}_\\mathsf{Arr^*}(X)$, $\\mathsf{Poly}_\\mathsf{Arr^{*^\\prime}}(X)$, $\\mathsf{Poly}_\\mathsf{T}(X)$, and $\\mathsf{Poly}_\\mathsf{T^\\prime}(X)$. It computes $Q^*(X)$ and finally outputs the commitments to each of these polynomials (and writes the commitments to the transcript). Then, it generates the random challenge $\\zeta^*$ (once again this is by strong Fiat-Shamir). It creates opening proofs for $\\mathsf{Poly}_\\mathsf{Arr^*}(\\zeta^*),\\mathsf{Poly}_\\mathsf{Arr^{*^\\prime}}(\\zeta^*),Q^*(\\zeta^*)$, $\\mathsf{Poly}_\\mathsf{T}(\\zeta^*\\omega)$, and $\\mathsf{Poly}_\\mathsf{T^\\prime}(\\zeta^*\\omega)$, and writes these to the transcript as well. Since $\\mathcal{S}$ knows each of the above polynomials, it can honestly compute this step and the proof will be accepted by $\\mathcal{V}$. The transcript it generates this way will be indistinguishable from a transcript generated from a real execution, since $\\mathsf{PolyCommit}_\\mathsf{Ped}$ has the property of Indistinguishability of Commitments due to the randomization by $h^{\\hat{\\phi}(x)}$.\nPlookup # Completeness # Any honest prover can do the computations explained above and create an accepting proof.\nSoundness # We prove knowledge soundness in the Algebraic Group Model (AGM). To do so, we must prove that there exists an efficient extractor $\\mathcal{E}$ such that for any algebraic adversary $\\mathcal{A}$ the probability of $\\mathcal{A}$ winning the following game is $\\mathsf{negl}(\\lambda)$.\nGiven $[g,g^\\tau,g^{\\tau^2},\\dots,g^{\\tau^{n-1}}]$, $\\mathcal{A}$ outputs commitments to $\\mathsf{Poly}_\\mathsf{Arr}(X)$, $\\mathsf{Poly}_\\mathsf{T}(X)$, $\\mathsf{Poly}_\\mathsf{S}(X)$, $Q$ $\\mathcal{E}$, given access to $\\mathcal{A}$\u0026rsquo;s outputs from the previous step, outputs $\\mathsf{Poly}_\\mathsf{Arr}(X)$, $\\mathsf{Poly}_\\mathsf{T}(X)$, $\\mathsf{Poly}_\\mathsf{S}(X)$, $Q$ $\\mathcal{A}$ plays the part of the prover in showing that $Y_\\mathsf{Zero}$ is zero at a random challenge $\\zeta$ $\\mathcal{A}$ wins if $\\mathcal{V}$ accepts at the end of the protocol For some $i\\in[0,\\kappa-1]$, $\\mathsf{Arr}[i]\\notin\\mathsf{T}$ Our proof is as follows:\nTo make $Y_\\mathsf{Zero}$ a zero polynomial, $\\mathcal{A}$ has to prove the three vanishing polynomials are correct. It is easy to observe that $\\mathsf{Poly}_\\mathsf{Vanish1}$ and $\\mathsf{Poly}_\\mathsf{Vanish3}$ can be constructed even if some elements in $\\mathsf{Arr}$ do not appear in $\\mathsf{T}$, so we focus on the $\\mathsf{Poly}_\\mathsf{Vanish2}$. By the soundness of the product check, we know $\\mathsf{S}$ must be the union set of $\\mathsf{Arr}$ and $\\mathsf{T}$ if we want to the product of $\\mathsf{S}[i]$ equals to the product of $\\mathsf{Arr}[i]$ and $\\mathsf{T}[i]$. Recall the equation $\\mathcal{A}$ needs to prove: $$ (1+\\beta)^n\\prod_{i\u003c{n}}[\\alpha+\\mathsf{Poly}_{\\mathsf{Arr}}(\\omega^i)]\\cdot\\prod_{i\u003c{d-1}}[\\alpha(1+\\beta)+\\mathsf{Poly}_{\\mathsf{T}}(\\omega^i)+\\beta\\mathsf{Poly}_{\\mathsf{T}}(\\omega^{i+1})]=\\prod_{i\u003c{n+d-1}}[\\alpha(1+\\beta)+\\mathsf{Poly}_{\\mathsf{S}}(\\omega^i)+\\beta\\mathsf{Poly}_{\\mathsf{S}}(\\omega^{i+1})] $$ Thus, for each $i\\in[0,d-1]$, there exists a factor in the right-hand side of the equation equal to $\\alpha(1+\\beta)+\\mathsf{Poly}_{\\mathsf{T}}(\\omega^i)+\\beta\\mathsf{Poly}_{\\mathsf{T}}(\\omega^{i+1})$, which means $\\alpha(1+\\beta)+\\mathsf{Poly}_{\\mathsf{T}}(\\omega^i)+\\beta\\mathsf{Poly}_{\\mathsf{T}}(\\omega^{i+1})=\\alpha(1+\\beta)+\\mathsf{Poly}_{\\mathsf{S}}(\\omega^i)+\\beta\\mathsf{Poly}_{\\mathsf{S}}(\\omega^{i+1})$. We can get $\\mathsf{Poly}_{\\mathsf{T}}(\\omega^i)=\\mathsf{Poly}_{\\mathsf{S}}(\\omega^i)$ and $\\mathsf{Poly}_{\\mathsf{T}}(\\omega^{i+1})=\\mathsf{Poly}_{\\mathsf{S}}(\\omega^{i+1})$ for $i\\in[0,d-1]$. Similarly, we can get $\\mathsf{Poly}_{\\mathsf{Arr}}(\\omega^i)=\\mathsf{Poly}_{\\mathsf{S}}(\\omega^i)=\\mathsf{Poly}_{\\mathsf{S}}(\\omega^{i+1})$ for $i\\in[0,n]$. Since $n$ should be equal to or less than $d$, when $\\mathsf{Poly}_{\\mathsf{Arr}}(\\omega^i)=\\mathsf{Poly}_{\\mathsf{S}}(\\omega^i)$, $\\mathsf{Poly}_{\\mathsf{T}}(\\omega^i)=\\mathsf{Poly}_{\\mathsf{S}}(\\omega^i)$ must hold at the same time, which contradicts to the winning assumption. Therefore, the protocol is sound.\nZero-Knowledge # To prove the above protocol is zero-knowledge, we do so by constructing a probabilistic polynomial time simulator $\\mathcal{S}$ which, for every (possibly malicious) verifier $\\mathcal{V}$, can output a view of the execution of the protocol that is indistinguishable from the view produced by the real execution of the program.\nThe simulator $\\mathcal{S}$ generates an array $\\mathsf{Arr^*}$ by randomly filling it with elements from $\\mathsf{T}$, then follows the same steps a prover would prove the lookup argument. $\\mathcal{S}$ computes $\\mathsf{S}_\\mathsf{l}$, $\\mathsf{S}_\\mathsf{h}$, and $\\mathsf{Z}$ and interpolates the five arrays into their respective polynomials, $\\mathsf{Poly}_\\mathsf{Arr^*}(X)$, $\\mathsf{Poly}_\\mathsf{T}(X)$, $\\mathsf{Poly}_{\\mathsf{S}_\\mathsf{l}}(X)$, $\\mathsf{Poly}_{\\mathsf{S}_\\mathsf{h}}(X)$, and $\\mathsf{Poly}_{\\mathsf{Z}}(X)$. It computes $Q^*(X)$ and finally outputs the commitments to each of these polynomials (and writes the commitments to the transcript). Then, it generates the random challenge $\\zeta^*$ (once again this is by strong Fiat-Shamir). It creates opening proofs for $\\mathsf{Poly}_\\mathsf{Arr^*}(\\zeta^*),\\mathsf{Poly}_\\mathsf{T}(\\zeta^*),\\mathsf{Poly}_\\mathsf{T}(\\zeta^*\\omega),\\mathsf{Poly}_{\\mathsf{S}_\\mathsf{l}}(\\zeta^*),\\mathsf{Poly}_{\\mathsf{S}_\\mathsf{l}}(\\zeta^*\\omega),\\mathsf{Poly}_{\\mathsf{S}_\\mathsf{h}}(\\zeta^*),\\mathsf{Poly}_{\\mathsf{S}_\\mathsf{h}}(\\zeta^*\\omega),Q^*(\\zeta^*),\\mathsf{Poly}_\\mathsf{Z}(\\zeta^*)$, and $\\mathsf{Poly}_\\mathsf{Z}(\\zeta^*\\omega)$, and writes these to the transcript as well. Since $\\mathcal{S}$ knows each of the above polynomials, it can honestly compute this step and the proof will be accepted by $\\mathcal{V}$. The transcript it generates this way will be indistinguishable from a transcript generated from a real execution since $\\mathsf{PolyCommit}_\\mathsf{Ped}$ has the property of Indistinguishability of Commitments due to the randomization by $h^{\\hat{\\phi}(x)}$.\n"},{"id":8,"href":"/docs/gadgets/mult1/","title":"Mult1","section":"Gadgets","content":" Multiplication (Type 1) # Recap of types # Type Description Recap This mult1 $\\mathsf{Arr}_3=\\mathsf{Arr}_1 \\cdot \\mathsf{Arr}_2$ $\\mathsf{Arr}_3$ is the element-wise multiplication of $\\mathsf{Arr}_1$ and $\\mathsf{Arr}_2$. ‚úÖ mult2 $\\mathsf{Prod}_\\mathsf{Arr}=\\prod_{i = 0}^{n-1} \\mathsf{Arr}[i]$ $\\mathsf{Prod}_\\mathsf{Arr}$ is the disclosed product of all the elements in $\\mathsf{Arr}$. mult3 $\\prod_{i = 0}^{n-1} \\mathsf{Arr}_1[i]=\\prod_{i = 0}^{n-1} \\mathsf{Arr}_2[i]$ $\\mathsf{Arr}_1$ and $\\mathsf{Arr}_2$ have the same undisclosed product. Relation # $ \\mathcal{R}_{\\mathtt{mult1}} := \\left\\{ \\begin{array}{l} (K_\\mathsf{Arr_1},K_\\mathsf{Arr_2},K_\\mathsf{Arr_3}) \\end{array} \\middle | \\begin{array}{l} \\mathsf{Arr_3}[i]=\\mathsf{Arr_1}[i]\\cdot\\mathsf{Arr_2}[i], 0\\leq i \\leq n-1, \\\\ \\mathsf{Poly}_\\mathsf{Arr_j}=\\mathsf{FFT.Interp}(\\omega,\\mathsf{Arr_j}), 1\\leq j \\leq 3, \\\\ K_\\mathsf{Arr_j}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr_j}), 1\\leq j \\leq 3, \\end{array} \\right\\} $\nIntuition # The prover ($\\mathcal{P}$) holds two arrays $\\mathsf{Arr_1}$ and $\\mathsf{Arr_2}$ of $n$ integers from $\\mathbb{Z}_q$: $[a_0, a_1, a_2, \\dots, a_{n-1}]$. It will produce a succinct (independent of $n$) proof that $\\mathsf{Arr_3}$ is the element-wise product of all the elements in the array: $\\mathsf{Arr_3}[i]=\\mathsf{Arr_1}[i]\\cdot\\mathsf{Arr_2}[i]$. The prover will encode the three arrays into three polynomials: $\\mathsf{Poly}_\\mathsf{Arr_1}$, $\\mathsf{Poly}_\\mathsf{Arr_2}$, and $\\mathsf{Poly}_\\mathsf{Arr_3}$ (using evaluation points on the domain $\\mathcal{H}_\\kappa$). It will commit to each polynomial: $K_\\mathsf{Arr_1}$, $K_\\mathsf{Arr_2}$, and $K_\\mathsf{Arr_3}$. The verifier ($\\mathcal{V}$) cannot check any of the $\\mathsf{Arr_i}$ or $\\mathsf{Poly}_\\mathsf{Arr_i}$ values directly (they may contain secret information, and even if they do not, they are too long to check) so the verifier only sees $K_\\mathsf{Arr_1}$,$K_\\mathsf{Arr_2}$, and $K_\\mathsf{Arr_3}$.\nIn order to prove$K_\\mathsf{Arr_1}$,$K_\\mathsf{Arr_2}$, and $K_\\mathsf{Arr_3}$ are consistent, the prover will compute the difference between $(\\mathsf{Poly}_\\mathsf{Arr_1}\\cdot\\mathsf{Poly}_\\mathsf{Arr_2})$ and $(\\mathsf{Poly}_\\mathsf{Arr_3})$ using add1. Next, it will show it is 0 for each evaluation point in the domain $\\mathcal{H}_\\kappa$. Showing a polynomial is zero on the domain is a common sub-protocol used by many gadgets.\nProtocol Details # Array Level # $\\mathcal{P}$ holds an array $\\mathsf{Arr_1} = [a_{(1,0)}, a_{(1,1)}, a_{(1,2)}, \\dots, a_{(1,n-1)}]$ of $n$ integers ($a_{(1,i)} \\in \\mathbb{Z}_q$) $\\mathcal{P}$ holds an array $\\mathsf{Arr_2} = [a_{(2,0)}, a_{(2,1)}, a_{(2,2)}, \\dots, a_{(2,n-1)}]$ of $n$ integers ($a_{(2,i)} \\in \\mathbb{Z}_q$) $\\mathcal{P}$ computes or holds an array $\\mathsf{Arr_3} = [a_{(3,0)}, a_{(3,1)}, a_{(3,2)}, \\dots, a_{(3,n-1)}]$ of $n$ integers ($a_{(3,i)} \\in \\mathbb{Z}_q$) such that: $\\mathsf{Arr_3}[i]=\\mathsf{Arr_1}[i]\\cdot\\mathsf{Arr_2}[i]$ for $i$ from 0 to $n-1$ Polynomial Level # We assume the three arrays $\\mathsf{Arr_1}$, $\\mathsf{Arr_2}$ and $\\mathsf{Arr_3}$ are encoded as the y-coordinates into a univariant polynomial where the x-coordinates (called the domain $\\mathcal{H}_\\kappa$) are chosen as the multiplicative group of order $\\kappa$ with generator $\\omega\\in\\mathbb{G}_\\kappa$ (see Background for more). In short, $\\omega^0$ is the first element and $\\omega^{\\kappa-1}$ is the last element of $\\mathcal{H}_\\kappa$. If $\\kappa$ is larger than the length of the array, the array can be padded.\nRecall the constraint we want to prove:\n$\\mathsf{Arr_3}[i]=\\mathsf{Arr_1}[i]\\cdot\\mathsf{Arr_2}[i]$ for $i$ from 0 to $n-1$ In polynomial form, the constraint is:\nFor all $X$ from $\\omega^0$ to $\\omega^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Arr_3}(X)=\\mathsf{Poly}_\\mathsf{Arr_1}(X)\\cdot\\mathsf{Poly}_\\mathsf{Arr_2}(X)$ We adjust the constraints to show an equality with 0:\nFor all $X$ from $\\omega^0$ to $\\omega^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Vanish}(X)=\\mathsf{Poly}_\\mathsf{Arr_3}(X)-\\mathsf{Poly}_\\mathsf{Arr_1}(X)\\cdot\\mathsf{Poly}_\\mathsf{Arr_2}(X)=0$ This equation is true for every value of $X \\in \\mathcal{H}_\\kappa$ (but not necessarily true outside of these values). To show this, we divide the polynomial by $X^\\kappa - 1$, which is a minimal vanishing polynomial for $\\mathcal{H}_\\kappa$ that does not require interpolation to create. If the quotient is polynomial (and not a rational function), then $\\mathsf{Poly}_\\mathsf{Vanish}(X)$ must be vanishing on $\\mathcal{H}_\\kappa$ too. Specifically, the prover computes:\n$Q(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish}(X)}{X^\\kappa - 1}$ By rearranging, we can get $\\mathsf{Poly}_\\mathsf{Zero}(X)$ as a true zero polynomial (zero at every value both in $\\mathcal{H}_\\kappa$ and outside of it):\n$\\mathsf{Poly}_\\mathsf{Zero}(X)=\\mathsf{Poly}_\\mathsf{Vanish}(X) - Q(X)\\cdot (X^n - 1)=0$ Ultimately the mult1 argument will satisfy the following constraints at the Commitment Level:\nShow $Q(X)$ exists (as a polynomial that evenly divides the divisor) Show $\\mathsf{Poly}_\\mathsf{Zero}(X)$ is correctly constructed from $\\mathsf{Poly}_\\mathsf{Arr_1}(X)$, $\\mathsf{Poly}_\\mathsf{Arr_1}(X)$, and $\\mathsf{Poly}_\\mathsf{Arr_1}(X)$. Show $\\mathsf{Poly}_\\mathsf{Zero}(X)$ is the zero polynomial Commitment Level # The verifier will never see the arrays or polynomials themselves. They are undisclosed because they either (i) contain private data or (ii) they are too large to examine and maintain a succinct proof system. Instead the prover will use commitments.\nThe prover will write the following commitments to the transcript:\n$K_\\mathsf{Arr_1}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr_1}(X))$\n$K_\\mathsf{Arr_2}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr_2}(X))$\n$K_\\mathsf{Arr_3}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr_3}(X))$\n$K_Q=\\mathsf{KZG.Commit}(Q(X))$\nThe prover will generate a random challenge evaluation point (using strong Fiat-Shamir) on the polynomial that is outside of $\\mathcal{H}_\\kappa$. Call this point $\\zeta$. The prover will write the point and opening proofs to the transcript:\n$\\zeta$\n$\\mathsf{Poly}_\\mathsf{Arr_1}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Arr_1},\\zeta)$\n$\\mathsf{Poly}_\\mathsf{Arr_2}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Arr_2},\\zeta)$\n$\\mathsf{Poly}_\\mathsf{Arr_3}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Arr_3},\\zeta)$\n$Q(\\zeta)=\\mathsf{KZG.Open}(K_Q,\\zeta)$\nTo check the proof, the verifier uses the transcript to construct the value $Y_\\mathsf{Zero}$ as follows:\n$Y_\\mathsf{Vanish}=\\mathsf{Poly}_\\mathsf{Arr_1}(\\zeta)-\\mathsf{Poly}_\\mathsf{Arr_2}(\\zeta)\\cdot\\mathsf{Poly}_\\mathsf{Arr_3}( \\zeta)$ $Y_\\mathsf{Zero}=Y_\\mathsf{Vanish1} - Q(\\zeta)\\cdot (\\zeta^n - 1)$ Finally, if the constraint system is true, the following constraint will be true (and will be false otherwise with overwhelming probability, due to the Schwartz-Zippel lemma on $\\zeta$) :\n$Y_\\mathsf{Zero}\\overset{?}{=}0$ Implementations # Rust Mathematica (Toy Example) Security Proof # Completeness # Any honest prover can do the computations explained above and create an accepting proof.\nSoundness # We prove knowledge soundness in the Algebraic Group Model (AGM). To do so, we must prove that there exists an efficient extractor $\\mathcal{E}$ such that for any algebraic adversary $\\mathcal{A}$ the probability of $\\mathcal{A}$ winning the following game is $\\mathsf{negl}(\\lambda)$.\nGiven $[g, g^\\tau, g^{\\tau^2}, \\dots,g^{\\tau^{n-1}}]$ $\\mathcal{A}$ outputs commitments to $\\mathsf{Poly}_\\mathsf{Arr1}(X)$, $\\mathsf{Poly}_\\mathsf{Arr2}(X)$, $\\mathsf{Poly}_\\mathsf{Arr3}(X)$, $Q$.\n$\\mathcal{E}$, given access to $\\mathcal{A}$\u0026rsquo;s outputs from the previous step, outputs $\\mathsf{Poly}_\\mathsf{Arr1}(X)$, $\\mathsf{Poly}_\\mathsf{Arr2}(X)$, $\\mathsf{Poly}_\\mathsf{Arr3}(X)$, $Q$.\n$\\mathcal{A}$ plays the part of the prover in showing that $Y_{\\mathsf{Zero}}$ is zero at a random challenge $\\zeta$\n$\\mathcal{A}$ wins if:\ni) $\\mathcal{V}$ accepts at the end of the protocol\nii) $\\mathsf{Arr}_3\\neq \\mathsf{Arr}_1 \\cdot \\mathsf{Arr}_2$\nOur proof is as follows:\nFor the second win condition to be fulfilled, the constraint must not hold for at least one index of the arrays. But then $\\mathsf{Poly}_\\mathsf{Vanish}(X)$ is not vanishing on $\\mathcal{H}_\\kappa$, so $Q(X)$ is not a polynomial (it is a rational function). This means that $\\mathcal{A}$ cannot calcuated the correct commitment value $g^{Q(\\tau)}$ without solving the t-SDH. Thus, $\\mathcal{A}$ chooses an arbitrary value for $Q(\\tau)$ and sends $K_Q = g^{Q(\\tau)}$. It also sends commitments to $\\mathsf{Poly}_\\mathsf{Arr1}(X)$, $\\mathsf{Poly}_\\mathsf{Arr2}(X)$, and $\\mathsf{Poly}_\\mathsf{Arr3}(X)$. Each commitment $\\mathcal{A}$ has outputted is a linear combination of the elements in $[g, g^\\tau, g^{\\tau^2}, \\dots,g^{\\tau^{n-1}}]$. $\\mathcal{E}$ is given these coefficients (since $\\mathcal{A}$ is an algebraic adversary) so $\\mathcal{E}$ can output the original polynomials.\n$\\mathcal{A}$ then obtains the random challenge $\\zeta$ (using strong Fiat-Shamir). By the binding property of KZG commitments, $\\mathsf{Poly}_\\mathsf{Arr1}(\\zeta)$, $\\mathsf{Poly}_\\mathsf{Arr2}(\\zeta)$, and $\\mathsf{Poly}_\\mathsf{Arr3}(\\zeta)$ can only feasibliy be opened to one value each. For $\\mathcal{A}$ to have the verifier accept, they must send a proof that $Q(\\zeta)$ opens to $Q(\\zeta) = \\frac{Y_\\mathsf{Vanish1}}{(\\zeta^n - 1)}$. This means being able to send $g^{q(\\tau)}$ where $q(\\tau) = \\frac{Q(\\tau) - Q(\\zeta)}{\\tau - \\zeta}$ and $Q(\\zeta) = \\frac{Y_\\mathsf{Vanish1}}{(\\zeta^n - 1)}$. Since $Q(\\tau)$ and $Q(\\zeta)$ are known, this implies knowing $g^{\\frac{1}{\\tau - \\zeta}}$. Thus $\\mathcal{A}$ would have found $\\langle\\zeta,g^{\\frac{1}{\\tau - \\zeta}}\\rangle$, which is the t-SDH problem. We have shown that creating an accepting proof reduces to the t-SDH, so $\\mathcal{A}$\u0026rsquo;s probability of success is negligible.\nZero-Knowledge # We prove that the above protocol is zero-knowledge when $\\mathsf{PolyCommit}_\\mathsf{Ped}$ (from the KZG paper) is used for the polynomial commitments. We do so by constructing a probabilistic polynomial time simulator $\\mathcal{S}$ that knows the trapdoor $\\tau$, which, for every (possibly malicious) verifier $\\mathcal{V}$, can output a view of the execution of the protocol that is indistinguishable from the view produced by the real execution of the program.\nThe simulator $\\mathcal{S}$ choose arbitrary values for ${\\mathsf{Poly}_\\mathsf{Arr1}(\\tau)}$, ${\\mathsf{Poly}_\\mathsf{Arr2}(\\tau)}$, and $\\mathsf{Poly}_\\mathsf{Arr3}(\\tau)$, then computes $g^{\\mathsf{Poly}_\\mathsf{Arr1}(\\tau)}$, $g^{\\mathsf{Poly}_\\mathsf{Arr2}(\\tau)}$ , and $g^{\\mathsf{Poly}_\\mathsf{Arr3}(\\tau)}$ to output as the commitments $K_\\mathsf{Arr1}$, $ K_\\mathsf{Arr2}$, and $ K_\\mathsf{Arr3}$. $\\mathcal{S}$ then generates the challenge evaluation point $\\rho$ (by strong Fiat-Shamir) and computes $Q(\\tau)$ using $\\rho$ and the values they chose for ${\\mathsf{Poly}_\\mathsf{Arr1}(\\tau)}$, ${\\mathsf{Poly}_\\mathsf{Arr2}(\\tau)}$, and $\\mathsf{Poly}_\\mathsf{Arr3}(\\tau)$. $\\mathcal{S}$ outputs the commitment $K_Q = g^{Q(\\tau)}$.\nNow, $\\mathcal{S}$ generates the second random challenge point $\\zeta$ (which we assume is not in $\\mathcal{H}_\\kappa$; if it is in $\\mathcal{H}_\\kappa$, $\\mathcal{S}$ simply restarts and runs from the beginning). This is once again by strong Fiat-Shamir. $\\mathcal{S}$ then create fake opening proofs for ${\\mathsf{Poly}_\\mathsf{Arr1}(\\zeta)}$, ${\\mathsf{Poly}_\\mathsf{Arr2}(\\zeta)}$, and $\\mathsf{Poly}_\\mathsf{Arr3}(\\zeta)$, to arbitrary values. This is done using the knowledge of $\\tau$, calculating the respective witness $q(\\tau) = \\frac{{f(\\tau) - f(\\zeta)}}{\\tau - \\zeta}$ for each of the polynomials.\nFinally, $\\mathcal{S}$ creates a fake opening proof for $Q(\\zeta) = \\frac{Y_\\mathsf{Vanish1}}{(\\zeta^n - 1)}$. This is done using knowledge of $\\tau$ to calculate an accepting witness $q(\\tau)$, as above. This means that $Y_\\mathsf{Zero}$ will be zero, and the transcript will be accepted by the verifier. It is indistinguishable from a transcript generates from a real execution, since $\\mathsf{PolyCommit}_\\mathsf{Ped}$ has the property of Indistinguishability of Commitments due to the randomization by $h^{\\hat{\\phi}(x)}$.\nFor mult2, the proof is written with a simulator that doesn\u0026rsquo;t know the trapdoor; however, with small alterations the proof for mult2 should apply here and vice versa "},{"id":9,"href":"/docs/gadgets/mult2/","title":"Mult2","section":"Gadgets","content":" Multiplication (Type 2) # Recap of types # Type Description Recap This mult1 $\\mathsf{Arr}_3=\\mathsf{Arr}_1 \\cdot \\mathsf{Arr}_2$ $\\mathsf{Arr}_3$ is the element-wise multiplication of $\\mathsf{Arr}_1$ and $\\mathsf{Arr}_2$. mult2 $\\mathsf{Prod}_\\mathsf{Arr}=\\prod_{i = 0}^{n-1} \\mathsf{Arr}[i]$ $\\mathsf{Prod}_\\mathsf{Arr}$ is the disclosed product of all the elements in $\\mathsf{Arr}$. ‚úÖ mult3 $\\prod_{i = 0}^{n-1} \\mathsf{Arr}_1[i]=\\prod_{i = 0}^{n-1} \\mathsf{Arr}_2[i]$ $\\mathsf{Arr}_1$ and $\\mathsf{Arr}_2$ have the same undisclosed product. Relation # $ \\mathcal{R}_{\\mathtt{mult2}} := \\left\\{ \\begin{array}{l} (K_\\mathsf{Arr},\\mathsf{Prod}_\\mathsf{Arr}) \\end{array} \\middle | \\begin{array}{l} \\mathsf{Arr} = [a_0, a_1, a_2, \\dots, a_{n-1}], \\\\ \\mathsf{Prod}_\\mathsf{Arr} = \\prod_{i = 0}^{n-1} a_i, \\\\ \\mathsf{Poly}_\\mathsf{Arr}=\\mathsf{FFT.Interp}(\\omega,\\mathsf{Arr}), \\\\ K_\\mathsf{Arr}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr}) \\end{array} \\right\\} $\nIntuition # The prover ($\\mathcal{P}$) holds an array $\\mathsf{Arr} = [a_0, a_1, a_2, \\dots, a_{n-1}]$ of $n$ integers (from $\\mathbb{Z}_q$) and a disclosed integer $\\mathsf{Prod}_\\mathsf{Arr}$. It will produce a succinct (independent of $n$) proof that $\\mathsf{Prod}_\\mathsf{Arr}$ is the product of all the elements in the array. The prover will encode the array into a polynomial $\\mathsf{Poly}_\\mathsf{Arr}$ (using evaluation points on the domain $\\mathcal{H}_\\kappa$) and commit to the polynomial $K_\\mathsf{Arr}$. The verifier ($\\mathcal{V}$) cannot check $\\textsf{Arr}$ or $\\mathsf{Poly}_\\mathsf{Arr}$ directly (they may contain secret information, and even if they do not, it is too long to check) so the verifier only sees $K_\\mathsf{Arr}$ and the asserted value $\\mathsf{Prod_\\mathsf{Arr}}$.\nIn order to prove $K_\\mathsf{Arr}$ and $\\mathsf{Prod}_\\mathsf{Arr}$ are consistent, the prover will build a helper array $\\mathsf{Acc}_\\mathsf{Arr}$ called an accumulator (or accumulating array or incremental array). This should not be confused with accumulators from cryptography, which are a concept related to succinct proofs but are distinct. As with $\\mathsf{Arr}$, the prover will also encode $\\mathsf{Acc}$ as a polynomial and provide a commitment of it to the verifier. The idea is that the prover will prove a relation between $\\mathsf{Arr}$ and $\\mathsf{Acc}$; and a relation between $\\mathsf{Acc}$ and $\\mathsf{Prod_\\mathsf{Arr}}$. Put together, it will imply the correct relation between $\\mathsf{Arr}$ and $\\mathsf{Prod_\\mathsf{Arr}}$.\nConsider a small numeric example in $\\mathbb{Z}_{97}$ where $\\mathsf{Arr}= [84,67,11,92,36,67]$ and $\\mathsf{Prod}_\\mathsf{Arr}=72$. The first idea is to get $\\mathsf{Prod}_\\mathsf{Arr}$ into an array. Say, we just append it: $\\mathsf{Arr}''= [84,67,11,92,36,67,72] $. How does the prover show $\\mathsf{Arr}''$ is correct? The last value of the array depends on every single element that precedes it, which will be a complex constraint to prove.\nAn alternative idea is to create a new array that starts the same as $\\mathsf{Arr}$ and ends up at $\\mathsf{Prod}_\\mathsf{Arr}$ by folding in the integers from $\\mathsf{Arr}$ one-by-one with multiplication. Then each value in the new array will depend on only two values, as below.\nThe first value in $\\mathsf{Acc}$ will be a copy of the first value from $\\mathsf{Arr}$:\n$\\mathsf{Arr}= [84,67,11,92,36,67]$\n$\\mathsf{Acc}= [84, \\bot,\\bot,\\bot,\\bot,\\bot] $\nThe next value will be the multiplication (mod 97) of: 67 (the value at the same index in $\\mathsf{Arr}$) and 84 (the previous value in $\\mathsf{Acc}$):\n$\\mathsf{Arr}= [84,67,11,92,36,67]$\n$ \\mathsf{Acc} = [84, (67\\cdot84),\\bot,\\bot,\\bot,\\bot] = [84, 2,\\bot,\\bot,\\bot,\\bot]$\nThe next value will be the multiplication of: 11 (the value at the same index in $\\mathsf{Arr}$) and 2 (the previous value in $\\mathsf{Acc}$):\n$\\mathsf{Arr}= [84,67,11,92,36,67]$ $ \\mathsf{Acc} = [84, 2,(11\\cdot2),\\bot,\\bot,\\bot] = [84,2,22,\\bot,\\bot,\\bot]$ $ \\mathsf{Acc} = [84, 2,22,(92\\cdot22),\\bot,\\bot] = [84,2,22,84,\\bot,\\bot]$ $ \\mathsf{Acc} = [84, 2,22,84,(36\\cdot84),\\bot] = [84,2,22,84,17,\\bot]$ $ \\mathsf{Acc} = [84,2,22,84,17,(67\\cdot17)] = [84, 2, 22, 84, 17, 72]$ $\\mathsf{Prod}_\\mathsf{Arr}=72$ Notice the last value in $\\mathsf{Acc}$ is $\\mathsf{Prod_\\mathsf{Arr}}$. The prover wants to show three constraints:\nThe first value in $\\mathsf{Acc}$ matches the first value in $\\mathsf{Arr}$, The rest of the values in $\\mathsf{Acc}$ are of the form $\\mathsf{Acc}[i]=\\mathsf{Arr}[i]\\cdot\\mathsf{Acc}[i-1]$, The last value in $\\mathsf{Acc}$ matches $\\mathsf{Prod}_\\mathsf{Arr}$. If all three constraints are true, then $\\mathsf{Prod}_\\mathsf{Arr}$ is the product of the elements of $\\mathsf{Arr}$.\nLast, while it is not necessary to do, it is often convenient to hold the the value $\\mathsf{Prod}_\\mathsf{Arr}$ at the start of the array $\\mathsf{Acc}$ instead of the end. For this reason, the mathematical explaination below will construct $\\mathsf{Acc}$ \u0026ldquo;backwards\u0026rdquo; (or right-to-left) from the above example, where the last value of $\\mathsf{Acc}$ matches the last value of $\\mathsf{Arr}$, the values are folded in from right to left, and the first (leftmost) value of $\\mathsf{Acc}$ is $\\mathsf{Prod}_\\mathsf{Arr}$:\n$\\mathsf{Arr}= [84,67,11,92,36,67]$ $ \\mathsf{Acc} = [\\bot, \\bot, \\bot, \\bot, \\bot, 67]$ $ \\mathsf{Acc} = [\\bot, \\bot, \\bot, \\bot, 84, 67]$ $\\ldots$ $ \\mathsf{Acc} = [72, 84, 36, 65, 84, 67]$ $\\mathsf{Prod}_\\mathsf{Arr}=72$ Protocol Details # Array Level # $\\mathcal{P}$ holds an array $\\mathsf{Arr} = [a_0, a_1, a_2, \\dots, a_{n-1}]$ of $n$ integers ($a_i \\in \\mathbb{Z}_q$) $\\mathcal{P}$ computes array $\\mathsf{Acc}$ as follows: $\\mathsf{Acc}[n-1]\\leftarrow\\mathsf{Arr}[n-1]$ $\\mathsf{Acc}[i]\\leftarrow\\mathsf{Arr}[i]\\cdot\\mathsf{Acc}[i+1]$ for $i$ from $n-2$ to 0 $\\mathcal{P}$ computes $\\mathsf{Prod}_\\mathsf{Arr}\\leftarrow\\mathsf{Acc}[0]$ Polynomial Level # We assume arrays $\\mathsf{Arr}$ and $\\mathsf{Acc}$ are encoded as the y-coordinates into a univariant polynomial where the x-coordinates (called the domain $\\mathcal{H}_\\kappa$) are chosen as the multiplicative group of order $\\kappa$ with generator $\\omega\\in\\mathbb{G}_\\kappa$ (see Background for more). In short, $\\omega^0$ is the first element and $\\omega^{\\kappa-1}$ is the last element of $\\mathcal{H}_\\kappa$. If $\\kappa$ is larger than the length of the array, the array can be padded with elements of value 1 (which will not change the product).\nRecall the three constraints we want to prove:\nThe first value in $\\mathsf{Acc}$ matches the first value in $\\mathsf{Arr}$, The rest of the values in $\\mathsf{Acc}$ are of the form $\\mathsf{Acc}[i]=\\mathsf{Arr}[i]\\cdot\\mathsf{Acc}[i-1]$, The last value in $\\mathsf{Acc}$ matches $\\mathsf{Prod}_\\mathsf{Arr}$. In polynomial form, the constraints are:\nFor $X=w^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Acc}(X)=\\mathsf{Poly}_\\mathsf{Arr}(X)$, For all $X$ except $X=\\omega^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Acc}(X)=\\mathsf{Poly}_\\mathsf{Arr}(X)\\cdot\\mathsf{Poly}_\\mathsf{Acc}(\\omega\\cdot X)$ For $X=w^0$: $\\mathsf{Poly}_\\mathsf{Acc}(X)=\\mathsf{Prod}_\\mathsf{Arr}$ In constraint 2, $\\mathsf{Poly}_\\mathsf{Acc}(\\omega\\cdot X)$ can also be conceptualized as rotate applied to $\\mathsf{Poly}_\\mathsf{Acc}(X)$ by one element (rightward in the array view). Also note that constraint 2 does not hold at $X=\\omega^{\\kappa-1}$ because this value is defined by constraint 1 (for the last value of $X$, the \u0026ldquo;next\u0026rdquo; value, $\\omega X$, wraps back to the first element of the array which is a boundary condition).\nWe adjust each of these constraints to show an equality with 0:\nFor $X=w^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Acc}(X)-\\mathsf{Poly}_\\mathsf{Arr}(X)=0$, For all $X$ except $X=\\omega^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Acc}(X)-\\mathsf{Poly}_\\mathsf{Arr}(X)\\cdot\\mathsf{Poly}_\\mathsf{Acc}(\\omega\\cdot X)=0$ For $X=w^0$: $\\mathsf{Poly}_\\mathsf{Acc}(X)-\\mathsf{Prod}_\\mathsf{Arr}=0$ Next we take care of the \u0026ldquo;for $X$\u0026rdquo; conditions by zeroing out the rest of the polynomial that is not zero. See the gadget zero1 for more on why this works.\n$\\mathsf{Poly}_\\mathsf{Vanish1}(X)=(\\mathsf{Poly}_\\mathsf{Acc}(X)-\\mathsf{Poly}_\\mathsf{Arr}(X))\\cdot\\frac{(X^\\kappa-1)}{(X-\\omega^{\\kappa-1})}=0$, $\\mathsf{Poly}_\\mathsf{Vanish2}(X)=(\\mathsf{Poly}_\\mathsf{Acc}(X)-\\mathsf{Poly}_\\mathsf{Arr}(X)\\cdot\\mathsf{Poly}_\\mathsf{Acc}(\\omega\\cdot X))\\cdot(X-\\omega^{\\kappa-1})=0$ $\\mathsf{Poly}_\\mathsf{Vanish3}(X)=(\\mathsf{Poly}_\\mathsf{Acc}(X)-\\mathsf{Prod}_\\mathsf{Arr})\\cdot\\frac{(X^\\kappa-1)}{(X-\\omega^0)}=0$ These equations are true for every value of $X \\in \\mathcal{H}_\\kappa$ (but not necessarily true outside of these values). To show this, we divide each polynomial by $X^\\kappa - 1$, which is a minimal vanishing polynomial for $\\mathcal{H}_\\kappa$ that does not require interpolation to create. If the quotients are polynomials (and not rational functions), then $\\mathsf{Poly}_\\mathsf{Vanish1}(X)$, $\\mathsf{Poly}_\\mathsf{Vanish2}(X)$, and $\\mathsf{Poly}_\\mathsf{Vanish3}(X)$ must be vanishing on $\\mathcal{H}_\\kappa$ too. Specifically, the prover computes,\n$Q_1(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish1}(X)}{X^\\kappa - 1}$ $Q_2(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish2}(X)}{X^\\kappa - 1}$ $Q_3(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish3}(X)}{X^\\kappa - 1}$ We can replace polynomials $Q_1(X)$, $Q_2(X)$, and $Q_3(X)$ with a single polynomial $Q(X)$. We can do this because all three constraints have the same format: $\\mathsf{Poly}_\\mathsf{Vanish_i}(X)=0$. The batching technique is to create a new polynomial with all three $\\mathsf{Poly}_\\mathsf{Vanish_i}(X)$ values as coefficients. If and (overwhelmingly) only if all three are vanishing, then so will the new polynomial. This polynomial will be evaluated at a random challenge point $\\rho$ selected after the commitments to the earlier polynomials are fixed.\n$Q(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish1}(X) + \\mathsf{Poly}_\\mathsf{Vanish2}(X) \\rho + \\mathsf{Poly}_\\mathsf{Vanish3}(X)\\rho^2}{X^n - 1}$\nBy rearranging, we can get $\\mathsf{Poly}_\\mathsf{Zero}(X)$ as a true zero polynomial (zero at every value both in $\\mathcal{H}_\\kappa$ and outside of it):\n$\\mathsf{Poly}_\\mathsf{Zero}(X)=\\mathsf{Poly}_\\mathsf{Vanish1}(X) + \\rho \\mathsf{Poly}_\\mathsf{Vanish2}(X) + \\rho^2 \\mathsf{Poly}_\\mathsf{Vanish3}(X) - Q(X)\\cdot (X^n - 1)=0$\nUltimately the mult2 argument will satisfy the following constraints at the Commitment Level:\nShow $Q(X)$ exists (as a polynomial that evenly divides the divisor) Show $\\mathsf{Poly}_\\mathsf{Zero}(X)$ is correctly constructed from $\\mathsf{Poly}_\\mathsf{Acc}(X)$, $\\mathsf{Poly}_\\mathsf{Acc}(\\omega X)$, $\\mathsf{Poly}_\\mathsf{Arr}(X)$, and $\\mathsf{Prod}_\\mathsf{Arr}$ Show $\\mathsf{Poly}_\\mathsf{Zero}(X)$ is the zero polynomial Commitment Level # The verifier will never see the arrays or polynomials themselves. They are undisclosed because they either (i) contain private data or (ii) they are too large to examine and maintain a succinct proof system. Instead the prover will use commitments.\nThe prover will write the following commitments to the transcript:\n$K_\\mathsf{Arr}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr}(X))$ $K_\\mathsf{Acc}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Acc}(X))$ The prover will generate a random challenge evaluation point (using strong Fiat-Shamir) on the polynomial that is outside of $\\mathcal{H}_\\kappa$. Call this point $\\rho$. It will be used by the prover to create polynomial $Q(X)$ (see above) and the prover will write to the transcript:\n$\\rho$ $K_Q=\\mathsf{KZG.Commit}(Q(X))$ The prover will generate a second random challenge evaluation point (using strong Fiat-Shamir) on the polynomial that is outside of $\\mathcal{H}_\\kappa$. Call this point $\\zeta$. The prover will write the point and opening proofs to the transcript:\n$\\zeta$ $\\mathsf{Poly}_\\mathsf{Arr}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Arr},\\zeta)$ $\\mathsf{Poly}_\\mathsf{Arr}(\\zeta\\omega)=\\mathsf{KZG.Open}(K_\\mathsf{Arr},\\zeta\\omega)$ $\\mathsf{Poly}_\\mathsf{Acc}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Acc},\\zeta)$ $Q(\\zeta)=\\mathsf{KZG.Open}(K_Q,\\zeta)$ To check the proof, the verifier uses the transcript to construct the value $Y_\\mathsf{Zero}$ as follows:\n$Y_\\mathsf{Vanish1}=(\\mathsf{Poly}_\\mathsf{Acc}(\\zeta)-\\mathsf{Poly}_\\mathsf{Arr}(\\zeta))\\cdot\\frac{(\\zeta^\\kappa-1)}{(\\zeta-\\omega^{\\kappa-1})}$ $Y_\\mathsf{Vanish2}=(\\mathsf{Poly}_\\mathsf{Acc}(\\zeta)-\\mathsf{Poly}_\\mathsf{Arr}(\\zeta)\\cdot\\mathsf{Poly}_\\mathsf{Acc}(\\omega\\cdot \\zeta))\\cdot(\\zeta-\\omega^{\\kappa-1})$ $Y_\\mathsf{Vanish3}=(\\mathsf{Poly}_\\mathsf{Acc}(\\zeta)-\\mathsf{Prod}_\\mathsf{Arr})\\cdot\\frac{(\\zeta^\\kappa-1)}{(\\zeta-\\omega^0)}$ $Y_\\mathsf{Zero}=Y_\\mathsf{Vanish1} + \\rho Y_\\mathsf{Vanish2} + \\rho^2 Y_\\mathsf{Vanish3} - Q(\\zeta)\\cdot (\\zeta^n - 1)$ Finally, if the constraint system is true, the following constraint will be true (and will be false otherwise with overwhelming probability, due to the Schwartz-Zippel lemma on $\\rho$ and $\\zeta$) :\n$Y_\\mathsf{Zero}\\overset{?}{=}0$ Implementations # Rust Mathematica (Toy Example) Security Proof # Completeness # Any honest prover can do the computations explained above and create an accepting proof.\nSoundness # We prove knowledge soundness in the Algebraic Group Model (AGM). To do so, we must prove that there exists an efficient extractor $\\mathcal{E}$ such that for any algebraic adversary $\\mathcal{A}$ the probability of $\\mathcal{A}$ winning the following game is $\\mathsf{negl}(\\lambda)$.\nGiven $[g, g^\\tau, g^{\\tau^2}, \\dots,g^{\\tau^{n-1}}]$ $\\mathcal{A}$ outputs commitments to $\\mathsf{Poly}_\\mathsf{Acc}(X)$, $\\mathsf{Poly}_\\mathsf{Arr}(X)$, $Q$\n$\\mathcal{E}$, given access to $\\mathcal{A}$\u0026rsquo;s outputs from the previous step, outputs $\\mathsf{Poly}_\\mathsf{Acc}(X)$, $\\mathsf{Poly}_\\mathsf{Arr}(X)$, $Q$\n$\\mathcal{A}$ plays the part of the prover in showing that $Y_\\mathsf{Zero}$ is zero at a random challenge $\\zeta$\n$\\mathcal{A}$ wins if:\ni) $\\mathcal{V}$ accepts at the end of the protocol\nii) $\\mathsf{Prod}_\\mathsf{Arr}\\neq\\prod_{i = 0}^{n-1} \\mathsf{Arr}[i]$\nOur proof is as follows:\nFor the second win condition to be fulfilled, one of the three constraints must be false. But then the $\\mathsf{Poly}_\\mathsf{Vanish}$ corresponding to that constraint is not vanishing on $\\mathcal{H}_\\kappa$, so $Q(X)$ is not a polynomial (it is a rational function). This means that $\\mathcal{A}$ cannot calcuated the correct commitment value $g^{Q(\\tau)}$ without solving the t-SDH. Thus, $\\mathcal{A}$ chooses an arbitrary value for $Q(\\tau)$ and sends $K_Q = g^{Q(\\tau)}$. It also sends commitments to $\\mathsf{Poly}_\\mathsf{Acc}(X)$, and $\\mathsf{Poly}_\\mathsf{Arr}(X)$. Each commitment $\\mathcal{A}$ has outputted is a linear combination of the elements in $[g, g^\\tau, g^{\\tau^2}, \\dots,g^{\\tau^{n-1}}]$. $\\mathcal{E}$ is given these coefficients (since $\\mathcal{A}$ is an algebraic adversary) so $\\mathcal{E}$ can output the original polynomials.\n$\\mathcal{A}$ then obtains the random challenge $\\zeta$ (using strong Fiat-Shamir). By the binding property of KZG commitments, $\\mathsf{Poly}_\\mathsf{Acc}(\\zeta)$, $\\mathsf{Poly}_\\mathsf{Arr}(\\zeta)$, and $\\mathsf{Poly}_\\mathsf{Acc}(\\zeta \\cdot \\omega)$ can only feasibliy be opened to one value each. For $\\mathcal{A}$ to have the verifier accept, they must send a proof that $Q(\\zeta)$ opens to $Q(\\zeta) = \\frac{Y_\\mathsf{Vanish1} + \\rho Y_\\mathsf{Vanish2} + \\rho^2Y_\\mathsf{Vanish3}}{\\zeta^n - 1}$. This means being able to send $g^{q(\\tau)}$ where $q(\\tau) = \\frac{Q(\\tau) - Q(\\zeta)}{\\tau - \\zeta}$ and $Q(\\zeta) = \\frac{Y_\\mathsf{Vanish1} + \\rho Y_\\mathsf{Vanish2} + \\rho^2Y_\\mathsf{Vanish3}}{\\zeta^n - 1}$. Since $Q(\\tau)$ and $Q(\\zeta)$ are known, this implies knowing $g^{\\frac{1}{\\tau - \\zeta}}$. Thus \\mathcal{A} would have found $\\langle\\zeta,g^{\\frac{1}{\\tau - \\zeta}}\\rangle$, which is the t-SDH problem. We have shown that creating an accepting proof reduces to the t-SDH, so $\\mathcal{A}$\u0026rsquo;s probability of success is negligible.\nZero-Knowledge # We prove that the above protocol is zero-knowledge when $\\mathsf{PolyCommit}_\\mathsf{Ped}$ (from the KZG paper) is used for the polynomial commitments. We do so by constructing a probabilistic polynomial time simulator $\\mathcal{S}$ which, for every (possibly malicious) verifier $\\mathcal{V}$, can output a view of the execution of the protocol that is indistinguishable from the view produced by the real execution of the program.\nThe simulator $\\mathcal{S}$ generates an array $\\mathsf{Arr'}$ whose product is equal to the disclosed value $\\mathsf{Prod}_\\mathsf{Arr}$ (this array could just have $\\mathsf{Prod}_\\mathsf{Arr}$ in one entry, and $1$\u0026rsquo;s elsewhere), then follows the same steps a prover would to prove the product of this array. So, $\\mathcal{S}$ computes the accumulator $\\mathsf{Acc'}$ and interpolates the two arrays into their respective polynomials, $\\mathsf{Poly}_\\mathsf{Acc'}(X)$ and $\\mathsf{Poly}_\\mathsf{Arr'}(X)$. It computes $Q(X)'$ using $\\mathsf{Poly}_\\mathsf{Acc'}(X)$ and $\\mathsf{Poly}_\\mathsf{Arr'}(X)$ and the random challenge point $\\rho'$ (by strong Fiat-Shamir). $\\mathcal{S}$ commits to each of these three polynomials (and writes the commitments to the transcript). Then, it generates the random challenge $\\zeta'$ (once again this is by strong Fiat-Shamir). It creates opening proofs for $\\mathsf{Poly}_\\mathsf{Acc}(\\zeta'), \\space \\mathsf{Poly}_\\mathsf{Arr}(\\zeta'), \\space Q(\\zeta')$, and $\\mathsf{Poly}_\\mathsf{Acc}(\\zeta' \\cdot \\omega)$, and writes these to the transcript as well. Since $\\mathcal{S}$ knows each of the above polynomials, it can honestly compute this step and the proof will be accepted by $\\mathcal{V}$. The transcript it generates this way will be indistinguishable from a transcript generated from a real execution, since $\\mathsf{PolyCommit}_\\mathsf{Ped}$ has the property of Indistinguishability of Commitments due to the randomization by $h^{\\hat{\\phi}(x)}$.\nThis proof could also be done by defining a simulator that knows the trapdoor $\\tau$ and cant thus create a passing witness for any commitment. The proof for mult1 is done in this style, but with small alterations would work here as well (and vice versa for this style of proof working for mult1) "},{"id":10,"href":"/docs/gadgets/mult3/","title":"Mult3","section":"Gadgets","content":" Multiplication (Type 3) # Recap of types # Type Description Recap This mult1 $\\mathsf{Arr}_3=\\mathsf{Arr}_1 \\cdot \\mathsf{Arr}_2$ $\\mathsf{Arr}_3$ is the element-wise multiplication of $\\mathsf{Arr}_1$ and $\\mathsf{Arr}_2$. mult2 $\\mathsf{Prod}_\\mathsf{Arr}=\\prod_{i = 0}^{n-1} \\mathsf{Arr}[i]$ $\\mathsf{Prod}_\\mathsf{Arr}$ is the disclosed product of all the elements in $\\mathsf{Arr}$. mult3 $\\prod_{i = 0}^{n-1} \\mathsf{Arr}_1[i]=\\prod_{i = 0}^{n-1} \\mathsf{Arr}_2[i]$ $\\mathsf{Arr}_1$ and $\\mathsf{Arr}_2$ have the same undisclosed product. ‚úÖ Relation # $ \\mathcal{R}_{\\mathtt{mult3}} := \\left\\{ \\begin{array}{l} (K_\\mathsf{Arr_1},K_\\mathsf{Arr2}) \\end{array} \\middle | \\begin{array}{l} \\mathsf{Arr_1} = [a_{(1,0)}, a_{(1,1)}, a_{(1,2)}, \\dots, a_{(1,n-1)}],\\\\ \\mathsf{Arr_2} = [a_{(2,0)}, a_{(2,1)}, a_{(2,2)}, \\dots, a_{(2,n-1)}], \\\\ \\mathsf{Poly}_\\mathsf{Arr_1}=\\mathsf{FFT.Interp}(\\omega,\\mathsf{Arr_1}), \\\\ \\mathsf{Poly}_\\mathsf{Arr_2}=\\mathsf{FFT.Interp}(\\omega,\\mathsf{Arr_2}), \\\\ K_\\mathsf{Arr_1}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr_1}),\\\\ K_\\mathsf{Arr_2}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr_2}), \\end{array} \\right\\} $\nIntuition # The prover ($\\mathcal{P}$) holds two arrays $\\mathsf{Arr_1}$ and $\\mathsf{Arr_2}$ of $n$ integers from $\\mathbb{Z}_q$: $[a_0, a_1, a_2, \\dots, a_{n-1}]$. It will produce a succinct (independent of $n$) proof that they have the same undisclosed product. The prover will encode the two arrays into polynomials, $\\mathsf{Poly}_\\mathsf{Arr_1}$ and $\\mathsf{Poly}_\\mathsf{Arr_2}$ (using evaluation points on the domain $\\mathcal{H}_\\kappa$) and commit to them as $K_\\mathsf{Arr_1}$ and $K_\\mathsf{Arr_2}$. The verifier ($\\mathcal{V}$) cannot check either array directly (they may contain secret information, and even if they do not, it is too long to check) so the verifier only sees $K_\\mathsf{Arr_1}$ and $K_\\mathsf{Arr_2}$.\nIn order to prove $K_\\mathsf{Arr_1}$ and $K_\\mathsf{Arr_2}$ are consistent, the prover will build two helper arrays $\\mathsf{Acc_1}$ and $\\mathsf{Acc_2}$ called accumulators (or accumulating arrays or incremental arrays). This should not be confused with accumulators from cryptography, which are a concept related to succinct proofs but are distinct. As with $\\mathsf{Arr_1}$ and $\\mathsf{Arr_2}$, the prover will also encode $\\mathsf{Acc_1}$ and $\\mathsf{Acc_2}$ as a polynomials and provide a commitment to the verifier of each one. The idea is that the prover will prove a relation between each $\\mathsf{Arr}$ and its $\\mathsf{Acc}$; and a relation between $\\mathsf{Acc_1}$ and $\\mathsf{Acc_2}$. Put together, it will imply the correct relation between $\\mathsf{Arr_1}$ and $\\mathsf{Arr_2}$.\nWe will illustrate a small numerical example in $\\mathbb{Z}_{97}$ of constructing an accumulator $\\mathsf{Acc}$ for the array $\\mathsf{Arr}= [84,67,11,92,36,67]$. The idea is to create a new array, $\\mathsf{Acc}$, that starts the same as $\\mathsf{Arr}$ and ends with the product of all entries of $\\mathsf{Arr}$, by folding in the integers from $\\mathsf{Arr}$ one-by-one with multiplication. Then each value in the new array will depend on only two values, as below.\nThe first value in $\\mathsf{Acc}$ will be a copy of the first value from $\\mathsf{Arr}$:\n$\\mathsf{Arr}= [84,67,11,92,36,67]$\n$\\mathsf{Acc}= [84, \\bot,\\bot,\\bot,\\bot,\\bot] $\nThe next value will be the multiplication (mod 97) of: 67 (the value at the same index in $\\mathsf{Arr}$) and 84 (the previous value in $\\mathsf{Acc}$):\n$\\mathsf{Arr}= [84,67,11,92,36,67]$\n$ \\mathsf{Acc} = [84, (67\\cdot84),\\bot,\\bot,\\bot,\\bot] = [84, 2,\\bot,\\bot,\\bot,\\bot]$\nThe next value will be the multiplication of: 11 (the value at the same index in $\\mathsf{Arr}$) and 2 (the previous value in $\\mathsf{Acc}$):\n$\\mathsf{Arr}= [84,67,11,92,36,67]$ $ \\mathsf{Acc} = [84, 2,(11\\cdot2),\\bot,\\bot,\\bot] = [84,2,22,\\bot,\\bot,\\bot]$ $ \\mathsf{Acc} = [84, 2,22,(92\\cdot22),\\bot,\\bot] = [84,2,22,84,\\bot,\\bot]$ $ \\mathsf{Acc} = [84, 2,22,84,(36\\cdot84),\\bot] = [84,2,22,84,17,\\bot]$ $ \\mathsf{Acc} = [84,2,22,84,17,(67\\cdot17)] = [84, 2, 22, 84, 17, 72]$ Notice the last value in $\\mathsf{Acc}$ is the product of all the entries in $\\mathsf{Arr}$. The prover wants to show five constraints:\nThe first value in $\\mathsf{Acc_1}$ matches the first value in $\\mathsf{Arr_1}$ The first value in $\\mathsf{Acc_2}$ matches the first value in $\\mathsf{Arr_2}$ The rest of the values in $\\mathsf{Acc}_1$ are of the form $\\mathsf{Acc_1}[i]=\\mathsf{Arr_1}[i]\\cdot\\mathsf{Acc_1}[i-1]$ The rest of the values in $\\mathsf{Acc}_2$ are of the form $\\mathsf{Acc_2}[i]=\\mathsf{Arr_2}[i]\\cdot\\mathsf{Acc_2}[i-1]$ The last value in $\\mathsf{Acc_1}$ matches the last value in $\\mathsf{Acc_2}$ If all five constraints are true, then entries of $\\mathsf{Arr_1}$ and $\\mathsf{Arr_2}$ have the same product.\nLast, while it is not necessary to do, it is often convenient to hold the the value of the product at the start of the array $\\mathsf{Acc}$ instead of the end. For this reason, the mathematical explaination below will construct $\\mathsf{Acc}$ \u0026ldquo;backwards\u0026rdquo; (or right-to-left) from the above example, where the last value of $\\mathsf{Acc}$ matches the last value of $\\mathsf{Arr}$, the values are folded in from right to left, and the first (leftmost) value of $\\mathsf{Acc}$ is the product of all entries:\n$\\mathsf{Arr}= [84,67,11,92,36,67]$ $ \\mathsf{Acc} = [\\bot, \\bot, \\bot, \\bot, \\bot, 67]$ $ \\mathsf{Acc} = [\\bot, \\bot, \\bot, \\bot, 84, 67]$ $\\ldots$ $ \\mathsf{Acc} = [72, 84, 36, 65, 84, 67]$ and the product of all entries in $\\mathsf{Arr}$ is 72 Protocol Details # Array Level # $\\mathcal{P}$ holds an array $\\mathsf{Arr_1} = [a_{(1,0)}, a_{(1,1)}, a_{(1,2)}, \\dots, a_{(1,n-1)}]$ of $n$ integers ($a_{(1,i)} \\in \\mathbb{Z}_q$) $\\mathcal{P}$ holds an array $\\mathsf{Arr_2} = [a_{(2,0)}, a_{(2,1)}, a_{(2,2)}, \\dots, a_{(2,n-1)}]$ of $n$ integers ($a_{(2,i)} \\in \\mathbb{Z}_q$) $\\mathcal{P}$ computes array $\\mathsf{Acc_j}$ as follows for $j \\in [1,2]$: $\\mathsf{Acc_j}[n-1]\\leftarrow\\mathsf{Arr_j}[n-1]$ $\\mathsf{Acc_j}[i]\\leftarrow\\mathsf{Arr_j}[i]\\cdot\\mathsf{Acc_j}[i+1]$ for $i$ from $n-2$ to 0 Polynomial Level # We assume arrays $\\mathsf{Arr_1}$, $\\mathsf{Arr_2}$, $\\mathsf{Acc_1}$, and $\\mathsf{Acc_2}$ are encoded as the y-coordinates into a univariant polynomial where the x-coordinates (called the domain $\\mathcal{H}_\\kappa$) are chosen as the multiplicative group of order $\\kappa$ with generator $\\omega\\in\\mathbb{G}_\\kappa$ (see Background for more). In short, $\\omega^0$ is the first element and $\\omega^{\\kappa-1}$ is the last element of $\\mathcal{H}_\\kappa$. If $\\kappa$ is larger than the length of the array, the array can be padded with elements of value 1 (which will not change the product).\nRecall the five constraints we want to prove:\nThe first value in $\\mathsf{Acc_1}$ matches the first value in $\\mathsf{Arr_1}$ The first value in $\\mathsf{Acc_2}$ matches the first value in $\\mathsf{Arr_2}$ The rest of the values in $\\mathsf{Acc}_1$ are of the form $\\mathsf{Acc_1}[i]=\\mathsf{Arr_1}[i]\\cdot\\mathsf{Acc_1}[i-1]$ The rest of the values in $\\mathsf{Acc}_2$ are of the form $\\mathsf{Acc_2}[i]=\\mathsf{Arr_2}[i]\\cdot\\mathsf{Acc_2}[i-1]$ The last value in $\\mathsf{Acc_1}$ matches the last value in $\\mathsf{Acc_2}$ In polynomial form, the constraints are:\nFor $X=w^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Acc_1}(X)=\\mathsf{Poly}_\\mathsf{Arr_1}(X)$, For $X=w^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Acc_2}(X)=\\mathsf{Poly}_\\mathsf{Arr_2}(X)$, For all $X$ except $X=\\omega^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Acc_1}(X)=\\mathsf{Poly}_\\mathsf{Arr_1}(X)\\cdot\\mathsf{Poly}_\\mathsf{Acc_1}(\\omega\\cdot X)$ For all $X$ except $X=\\omega^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Acc_2}(X)=\\mathsf{Poly}_\\mathsf{Arr_2}(X)\\cdot\\mathsf{Poly}_\\mathsf{Acc_2}(\\omega\\cdot X)$ For $X=w^0$: $\\mathsf{Poly}_\\mathsf{Acc_1}(X)=\\mathsf{Poly}_\\mathsf{Acc_2}(X)$ In constraints 2 and 3, $\\mathsf{Poly}_\\mathsf{Acc}(\\omega\\cdot X)$ can also be conceptualized as rotate applied to $\\mathsf{Poly}_\\mathsf{Acc}(X)$ by one element (rightward in the array view). Also note thats constraint 2 and 3 do not hold at $X=\\omega^{\\kappa-1}$ because this value is defined by constraint 1 (for the last value of $X$, the \u0026ldquo;next\u0026rdquo; value, $\\omega X$, wraps back to the first element of the array which is a boundary condition).\nWe adjust each of these constraints to show an equality with 0:\nFor $X=w^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Acc_1}(X)-\\mathsf{Poly}_\\mathsf{Arr_1}(X)=0$, For $X=w^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Acc_2}(X)-\\mathsf{Poly}_\\mathsf{Arr_2}(X)=0$, For all $X$ except $X=\\omega^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Acc_1}(X)-\\mathsf{Poly}_\\mathsf{Arr_1}(X)\\cdot\\mathsf{Poly}_\\mathsf{Acc_1}(\\omega\\cdot X)=0$ For all $X$ except $X=\\omega^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Acc_2}(X)-\\mathsf{Poly}_\\mathsf{Arr_2}(X)\\cdot\\mathsf{Poly}_\\mathsf{Acc_2}(\\omega\\cdot X)=0$ For $X=w^0$: $\\mathsf{Poly}_\\mathsf{Acc_1}(X)-\\mathsf{Poly}_\\mathsf{Acc_2}(X)=0$ Next we take care of the \u0026ldquo;for $X$\u0026rdquo; conditions by zeroing out the rest of the polynomial that is not zero. See the gadget zero1 for more on why this works.\n$\\mathsf{Poly}_\\mathsf{Vanish1}(X)=(\\mathsf{Poly}_\\mathsf{Acc_1}(X)-\\mathsf{Poly}_\\mathsf{Arr_1}(X))\\cdot\\frac{(X^\\kappa-1)}{(X-\\omega^{\\kappa-1})}=0$, $\\mathsf{Poly}_\\mathsf{Vanish2}(X)=(\\mathsf{Poly}_\\mathsf{Acc_2}(X)-\\mathsf{Poly}_\\mathsf{Arr_2}(X))\\cdot\\frac{(X^\\kappa-1)}{(X-\\omega^{\\kappa-1})}=0$, $\\mathsf{Poly}_\\mathsf{Vanish3}(X)=(\\mathsf{Poly}_\\mathsf{Acc_1}(X)-\\mathsf{Poly}_\\mathsf{Arr_1}(X)\\cdot\\mathsf{Poly}_\\mathsf{Acc_1}(\\omega\\cdot X))\\cdot(X-\\omega^{\\kappa-1})=0$ $\\mathsf{Poly}_\\mathsf{Vanish4}(X)=(\\mathsf{Poly}_\\mathsf{Acc_2}(X)-\\mathsf{Poly}_\\mathsf{Arr_2}(X)\\cdot\\mathsf{Poly}_\\mathsf{Acc_2}(\\omega\\cdot X))\\cdot(X-\\omega^{\\kappa-1})=0$ $\\mathsf{Poly}_\\mathsf{Vanish5}(X)=(\\mathsf{Poly}_\\mathsf{Acc_1}(X)-\\mathsf{Poly}_\\mathsf{Acc_2}(X)\\cdot\\frac{(X^\\kappa-1)}{(X-\\omega^0)}=0$ These equations are true for every value of $X \\in \\mathcal{H}_\\kappa$ (but not necessarily true outside of these values). To show this, we divide each polynomial by $X^\\kappa - 1$, which is a minimal vanishing polynomial for $\\mathcal{H}_\\kappa$ that does not require interpolation to create. If the quotients are polynomials (and not rational functions), then $\\mathsf{Poly}_\\mathsf{Vanish1}(X)$, $\\mathsf{Poly}_\\mathsf{Vanish2}(X)$, $\\mathsf{Poly}_\\mathsf{Vanish3}(X)$, $\\mathsf{Poly}_\\mathsf{Vanish4}(X)$, and $\\mathsf{Poly}_\\mathsf{Vanish5}(X)$ must be vanishing on $\\mathcal{H}_\\kappa$ too. Specifically, the prove computes,\n$Q_1(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish1}(X)}{X^\\kappa - 1}$ $Q_2(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish2}(X)}{X^\\kappa - 1}$ $Q_3(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish3}(X)}{X^\\kappa - 1}$ $Q_4(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish4}(X)}{X^\\kappa - 1}$ $Q_5(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish5}(X)}{X^\\kappa - 1}$ We can replace polynomials $Q_1(X)$, $Q_2(X)$, $Q_3(X)$, $Q_4(X)$, and $Q_5(X)$ with a single polynomial $Q(X)$. We can do this because all three constraints have the same format: $\\mathsf{Poly}_\\mathsf{Vanish_i}(X)=0$. The batching technique is to create a new polynomial with all five $\\mathsf{Poly}_\\mathsf{Vanish_i}(X)$ values as coefficients. If and (overwhelmingly) only if all five are vanishing, then so will the new polynomial. This polynomial will be evaluated at a random challenge point $\\rho$ selected after the commitments to the earlier polynomials are fixed.\n$Q(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish1}(X) + \\mathsf{Poly}_\\mathsf{Vanish2}(X) \\rho + \\mathsf{Poly}_\\mathsf{Vanish3}(X)\\rho^2 + \\mathsf{Poly}_\\mathsf{Vanish4}(X)\\rho^3 + \\mathsf{Poly}_\\mathsf{Vanish5}(X)\\rho^4}{X^n - 1}$\nBy rearranging, we can get $\\mathsf{Poly}_\\mathsf{Zero}(X)$ as a true zero polynomial (zero at every value both in $\\mathcal{H}_\\kappa$ and outside of it):\n$\\mathsf{Poly}_\\mathsf{Zero}(X)=\\mathsf{Poly}_\\mathsf{Vanish1}(X) + \\mathsf{Poly}_\\mathsf{Vanish2} (X) \\rho + \\mathsf{Poly}_\\mathsf{Vanish3}(X) \\rho^2 + \\mathsf{Poly}_\\mathsf{Vanish4}(X)\\rho^3 + \\mathsf{Poly}_\\mathsf{Vanish5}(X)\\rho^4 - Q(X)\\cdot (X^n - 1)=0$\nUltimately the mult3 argument will satisfy the following constraints at the Commitment Level:\nShow $Q(X)$ exists (as a polynomial that evenly divides the divisor) Show $\\mathsf{Poly}_\\mathsf{Zero}(X)$ is correctly constructed from $\\mathsf{Poly}_\\mathsf{Acc_1}(X)$, $\\mathsf{Poly}_\\mathsf{Acc_1}(\\omega X)$, $\\mathsf{Poly}_\\mathsf{Arr_1}(X)$, $\\mathsf{Poly}_\\mathsf{Acc_2}(X)$, $\\mathsf{Poly}_\\mathsf{Acc_2}(\\omega X)$, and $\\mathsf{Poly}_\\mathsf{Arr_2}(X)$ Show $\\mathsf{Poly}_\\mathsf{Zero}(X)$ is the zero polynomial Commitment Level # The verifier will never see the arrays or polynomials themselves. They are undisclosed because they either (i) contain private data or (ii) they are too large to examine and maintain a succinct proof system. Instead the prover will use commitments.\nThe prover will write the following commitments to the transcript:\n$K_\\mathsf{Arr_1}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr_1}(X))$ $K_\\mathsf{Acc_1}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Acc_1}(X))$ $K_\\mathsf{Arr_2}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr_2}(X))$ $K_\\mathsf{Acc_2}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Acc_2}(X))$ The prover will generate a random challenge evaluation point (using strong Fiat-Shamir) on the polynomial that is outside of $\\mathcal{H}_\\kappa$. Call this point $\\rho$. It will be used by the prover to create polynomial $Q(X)$ (see above) and the prover will write to the transcript:\n$\\rho$ $K_Q=\\mathsf{KZG.Commit}(Q(X))$ The prover will generate a second random challenge evaluation point (using strong Fiat-Shamir) on the polynomial that is outside of $\\mathcal{H}_\\kappa$. Call this point $\\zeta$. The prover will write the point and opening proofs to the transcript:\n$\\zeta$ $\\mathsf{Poly}_\\mathsf{Arr_1}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Arr_1},\\zeta)$ $\\mathsf{Poly}_\\mathsf{Acc_1}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Arr_1},\\zeta)$ $\\mathsf{Poly}_\\mathsf{Acc_1}(\\zeta\\omega)=\\mathsf{KZG.Open}(K_\\mathsf{Acc_1},\\zeta\\omega)$ $\\mathsf{Poly}_\\mathsf{Arr_2}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Arr_2},\\zeta)$ $\\mathsf{Poly}_\\mathsf{Acc_2}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Arr_2},\\zeta)$ $\\mathsf{Poly}_\\mathsf{Acc_2}(\\zeta\\omega)=\\mathsf{KZG.Open}(K_\\mathsf{Acc_2},\\zeta\\omega)$ $Q(\\zeta)=\\mathsf{KZG.Open}(K_Q,\\zeta)$ To check the proof, the verifier uses the transcript to construct the value $Y_\\mathsf{Zero}$ as follows:\n$Y_\\mathsf{Vanish1}= (\\mathsf{Poly}_\\mathsf{Acc_1}(\\zeta)-\\mathsf{Poly}_\\mathsf{Arr_1}(\\zeta))\\cdot\\frac{(\\zeta^\\kappa-1)}{(\\zeta-\\omega^{\\kappa-1})}$ $Y_\\mathsf{Vanish2}= (\\mathsf{Poly}_\\mathsf{Acc_2}(\\zeta)-\\mathsf{Poly}_\\mathsf{Arr_2}(\\zeta))\\cdot\\frac{(\\zeta^\\kappa-1)}{(\\zeta-\\omega^{\\kappa-1})}$ $Y_\\mathsf{Vanish3}=(\\mathsf{Poly}_\\mathsf{Acc_1}(\\zeta)-\\mathsf{Poly}_\\mathsf{Arr_1}(\\zeta)\\cdot\\mathsf{Poly}_\\mathsf{Acc_1}(\\omega\\zeta))\\cdot(\\zeta-\\omega^{\\kappa-1})$ $Y_\\mathsf{Vanish4}= (\\mathsf{Poly}_\\mathsf{Acc_2}(\\zeta)-\\mathsf{Poly}_\\mathsf{Arr_2}(\\zeta)\\cdot\\mathsf{Poly}_\\mathsf{Acc_2}(\\omega\\zeta))\\cdot(\\zeta-\\omega^{\\kappa-1})$ $Y_\\mathsf{Vanish5}= (\\mathsf{Poly}_\\mathsf{Acc_1}(\\zeta)-\\mathsf{Poly}_\\mathsf{Acc_2}(\\zeta)\\cdot\\frac{(\\zeta^\\kappa-1)}{(\\zeta-\\omega^0)}$ $Y_\\mathsf{Zero}=Y_\\mathsf{Vanish1} + \\rho Y_\\mathsf{Vanish2} + \\rho^2 Y_\\mathsf{Vanish3} + \\rho^3 Y_\\mathsf{Vanish4} + \\rho^4 Y_\\mathsf{Vanish5}- Q(\\zeta)\\cdot (\\zeta^n - 1)$ Finally, if the constraint system is true, the following constraint will be true (and will be false otherwise with overwhelming probability, due to the Schwartz-Zippel lemma on $\\rho$ and $\\zeta$) :\n$Y_\\mathsf{Zero}\\overset{?}{=}0$ Implementations # Security Proof # Completeness # Any honest prover can do the computations explained above and create an accepting proof.\nSoundness # We prove knowledge soundness in the Algebraic Group Model (AGM). To do so, we must prove that there exists an efficient extractor $\\mathcal{E}$ such that for any algebraic adversary $\\mathcal{A}$ the probability of $\\mathcal{A}$ winning the following game is $\\mathsf{negl}(\\lambda)$.\nGiven $[g, g^\\tau, g^{\\tau^2}, \\dots,g^{\\tau^{n-1}}]$ $\\mathcal{A}$ outputs commitments to $\\mathsf{Poly}_\\mathsf{Acc_1}(X)$, $\\mathsf{Poly}_\\mathsf{Arr_1}(X)$, $\\mathsf{Poly}_\\mathsf{Acc_{2}}(X)$, $\\mathsf{Poly}_\\mathsf{Arr_{2}}(X)$, $Q$\n$\\mathcal{E}$, given access to $\\mathcal{A}$\u0026rsquo;s outputs from the previous step, outputs $\\mathsf{Poly}_\\mathsf{Acc_1}(X)$, $\\mathsf{Poly}_\\mathsf{Arr_1}(X)$, $\\mathsf{Poly}_\\mathsf{Acc_{2}}(X)$, $\\mathsf{Poly}_\\mathsf{Arr_{2}}(X)$, $Q$\n$\\mathcal{A}$ plays the part of the prover in showing that $Y_\\mathsf{Zero}$ is zero at a random challenge $\\zeta$\n$\\mathcal{A}A$ wins if:\ni) $\\mathcal{V}$ accepts at the end of the protocol\nii) $\\prod_{i = 0}^{n-1} \\mathsf{Arr_1}[i]\\neq\\prod_{i = 0}^{n-1} \\mathsf{Arr_2}[i]$\nOur proof is as follows:\nFor the second win condition to be fulfilled, one of the five constraints must be false. But then the $\\mathsf{Poly}_\\mathsf{Vanish}$ corresponding to that constraint is not vanishing on $\\mathcal{H}_\\kappa$, so $Q(X)$ is not a polynomial (it is a rational function). This means that $\\mathcal{A}$ cannot calcuated the correct commitment value $g^{Q(\\tau)}$ without solving the t-SDH. Thus, $\\mathcal{A}$ chooses an arbitrary value for $Q(\\tau)$ and sends $K_Q = g^{Q(\\tau)}$. It also sends commitments to $\\mathsf{Poly}_\\mathsf{Acc_1}(X)$, $\\mathsf{Poly}_\\mathsf{Arr_1}(X)$, $\\mathsf{Poly}_\\mathsf{Acc_2}(X)$, and $\\mathsf{Poly}_\\mathsf{Arr_2}(X)$. Each commitment $\\mathcal{A}$ has outputted is a linear combination of the elements in $[g, g^\\tau, g^{\\tau^2}, \\dots,g^{\\tau^{n-1}}]$. $\\mathcal{E}$ is given these coefficients (since $\\mathcal{A}$ is an algebraic adversary) so $\\mathcal{E}$ can output the original polynomials.\n$\\mathcal{A}$ then obtains the random challenge $\\zeta$ (using strong Fiat-Shamir). By the binding property of KZG commitments, $\\mathsf{Poly}_\\mathsf{Arr_1}(\\zeta)$, $\\mathsf{Poly}_\\mathsf{Acc_1}(\\zeta)$, $\\mathsf{Poly}_\\mathsf{Acc_1}(\\zeta\\omega)$, $\\mathsf{Poly}_\\mathsf{Arr_2}(\\zeta)$, $\\mathsf{Poly}_\\mathsf{Acc_2}(\\zeta)$, and $\\mathsf{Poly}_\\mathsf{Acc_2}(\\zeta\\omega)$ can each only feasibliy be opened to one value. For $\\mathcal{A}$ to have the verifier accept, they must send a proof that $Q(\\zeta)$ opens to $Q(\\zeta) = \\frac{Y_\\mathsf{Vanish1} + \\rho Y_\\mathsf{Vanish2} + \\rho^2 Y_\\mathsf{Vanish3} + \\rho^3 Y_\\mathsf{Vanish4} + \\rho^4Y_\\mathsf{Vanish5}}{(\\zeta^n - 1)}$. This means being able to send $g^{q(\\tau)}$ where $q(\\tau) = \\frac{Q(\\tau) - Q(\\zeta)}{\\tau - \\zeta}$ and $Q(\\zeta) = \\frac{Y_\\mathsf{Vanish1} + \\rho Y_\\mathsf{Vanish2} + \\rho^2 Y_\\mathsf{Vanish3} + \\rho^3 Y_\\mathsf{Vanish4} + \\rho^4Y_\\mathsf{Vanish5}}{(\\zeta^n - 1)}$. Since $Q(\\tau)$ and $Q(\\zeta)$ are known, this implies knowing $g^{\\frac{1}{\\tau - \\zeta}}$. Thus $\\mathcal{A}$ would have found $\\langle\\zeta,g^{\\frac{1}{\\tau - \\zeta}}\\rangle$, which is the t-SDH problem. We have shown that creating an accepting proof reduces to the t-SDH, so $\\mathcal{A}$\u0026rsquo;s probability of success is negligible.\nZero-Knowledge # We prove that the above protocol is zero-knowledge when $\\mathsf{PolyCommit}_\\mathsf{Ped}$ (from the KZG paper) is used for the polynomial commitments. We do so by constructing a probabilistic polynomial time simulator $\\mathcal{S}$ that knows the trapdoor $\\tau$, which, for every (possibly malicious) verifier $\\mathcal{V}$, can output a view of the execution of the protocol that is indistinguishable from the view produced by the real execution of the program.\nThe simulator $\\mathcal{S}$ choose arbitrary values for ${\\mathsf{Poly}_\\mathsf{Arr_1}(\\tau)}$, ${\\mathsf{Poly}_\\mathsf{Acc_1}(\\tau)}$, ${\\mathsf{Poly}_\\mathsf{Arr_2}(\\tau)}$ and $\\mathsf{Poly}_\\mathsf{Acc_2}(\\tau)$, then computes $g^{\\mathsf{Poly}_\\mathsf{Arr_1}(\\tau)}$, $g^{\\mathsf{Poly}_\\mathsf{Acc_1}(\\tau)}$, $g^{\\mathsf{Poly}_\\mathsf{Arr_2}(\\tau)}$, and $g^{\\mathsf{Poly}_\\mathsf{Acc_2}(\\tau)}$ to output as the commitments $K_\\mathsf{Arr_1}$, $ K_\\mathsf{Acc_1}$, $K_\\mathsf{Arr_2}$, and $ K_\\mathsf{Acc_2}$. $\\mathcal{S}$ then generates the challenge evaluation pount $\\rho$ (by strong Fiat-Shamir) and computes $Q(\\tau)$ using $\\rho$ and the values they chose for${\\mathsf{Poly}_\\mathsf{Arr_1}(\\tau)}$, ${\\mathsf{Poly}_\\mathsf{Acc_1}(\\tau)}$, ${\\mathsf{Poly}_\\mathsf{Arr_2}(\\tau)}$ and $\\mathsf{Poly}_\\mathsf{Acc_2}(\\tau)$. $\\mathcal{S}$ outputs the commitment $K_Q = g^{Q(\\tau)}$.\nNow, $\\mathcal{S}$ generates the second random challenge point $\\zeta$ (which we assume is not in $\\mathcal{H}_\\kappa$; if it is in $\\mathcal{H}_\\kappa$, $\\mathcal{S}$ simply restarts and runs from the beginning). This is once again by strong Fiat-Shamir. $\\mathcal{S}$ then create fake opening proofs for $\\mathsf{Poly}_\\mathsf{Arr_1}(\\zeta)$, $\\mathsf{Poly}_\\mathsf{Acc_1}(\\zeta)$, $\\mathsf{Poly}_\\mathsf{Acc_1}(\\zeta\\omega)$, $\\mathsf{Poly}_\\mathsf{Arr_2}(\\zeta)$, $\\mathsf{Poly}_\\mathsf{Acc_2}(\\zeta)$, and $\\mathsf{Poly}_\\mathsf{Acc_2}(\\zeta\\omega)$, to arbitrary values. This is done using the knowledge of $\\tau$, calculating the respective witness $q(\\tau) = \\frac{{f(\\tau) - f(\\zeta)}}{\\tau - \\zeta}$ for each of the polynomials.\nFinally, $\\mathcal{S}$ creates a fake opening proof for $Q(\\zeta) = \\frac{Y_\\mathsf{Vanish1} + \\rho Y_\\mathsf{Vanish2} + \\rho^2 Y_\\mathsf{Vanish3} + \\rho^3 Y_\\mathsf{Vanish4} + \\rho^4Y_\\mathsf{Vanish5}}{(\\zeta^n - 1)}$. This is done using knowledge of $\\tau$ to calculate an accepting witness $q(\\tau)$, as above. This means that $Y_\\mathsf{Zero}$ will be zero, and the transcript will be accepted by the verifier. It is indistinguishable from a transcript generates from a real execution, since $\\mathsf{PolyCommit}_\\mathsf{Ped}$ has the property of Indistinguishability of Commitments due to the randomization by $h^{\\hat{\\phi}(x)}$.\nFor mult2, the proof is written with a simulator that doesn\u0026rsquo;t know the trapdoor; however, with small alterations the proof for mult2 should apply here and vice versa "},{"id":11,"href":"/docs/gadgets/range/","title":"Range","section":"Gadgets","content":" Range # Recap of types # Type Description Recap This range $\\mathsf{Arr}[i]\\in[0,r]$ Each element of array $\\mathsf{Arr}$ is in the range $[0,r]$ ‚úÖ Relation # $\\mathcal{R}_{\\mathtt{add1}} := \\left\\{ \\begin{array}{l} (K_\\mathsf{Arr}) \\end{array} \\middle | \\begin{array}{l} 0\\le{\\mathsf{Arr}[i]}\\le{r}, i\\in[0,n), \\\\ \\mathsf{Poly}_\\mathsf{Arr}=\\mathsf{FFT.Interp}(\\omega,\\mathsf{Arr}), \\\\ K_\\mathsf{Arr}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr}), \\end{array} \\right\\}$\nIntuition # To prove each element of array $\\mathsf{Arr}$ is in the range $[0,r]$, one of the most intuitive ways is we create a vector containing the numbers from $0$ to $r$ and run the lookup argument for $\\mathsf{Arr}$. Another approach is we prove each element is in $[0,r]$. Specifically, we decompose the target number to digits in some base $x$ and prove (i) the digits are valid and (ii) the number can be recovered from the digits and the base. The prover ($\\mathcal{P}$) holds a number $\\eta$ and $\\mathsf{Arr}$ of $k=\\lceil\\log_x{\\eta}\\rceil$ integers from $\\mathbb{Z}_q$: $[a_0,a_1,a_2,\\dots,a_{k-1}]$. It will produce a succinct (logarithm base $x$ of $\\eta$. For simplicity, we will use base $2$) proof that the vector $\\mathsf{T}$ satisfies the following conditions: (i) the first value of $\\mathsf{T}$ equals to $\\eta$ (ii) the last value of $\\mathsf{T}$ equals to one or zero (iii) any value minus two times the next value is equal to one or zero in $\\mathsf{T}$. The prover will encode $\\mathsf{Arr}$ and $\\mathsf{T}$ into two polynomials: $\\mathsf{Poly}_\\mathsf{Arr}$ and $\\mathsf{Poly}_\\mathsf{T}$ (using evaluation points on the domain $\\mathcal{H}_\\kappa$). He will commit to each polynomial: $K_\\mathsf{Arr}$ and $K_\\mathsf{T}$. The verifier ($\\mathcal{V}$) cannot check any of the $\\mathsf{Arr}$, $\\mathsf{T}$ or $\\mathsf{Poly}_\\mathsf{Arr}$, $\\mathsf{Poly}_\\mathsf{T}$ values directly. Instead the verifier only sees $K_\\mathsf{Arr}$, and $K_\\mathsf{T}$.\nIn order to prove $K_\\mathsf{Arr}$ and $K_\\mathsf{T}$ satisfy the above three conditions, one of the most straightforward methods is to use the additive homomorphic property of the KZG commitment scheme, i.e., prove $K_\\mathsf{Arr}$ and $K_\\mathsf{T}$ satisfy the conditions through the group addition. This method works if the target condition only involves additive operations. However, there are multiplications in the above conditions, so it is infeasible to calculate the product of two KZG commitments unless the t-SDH can be solved. Even if the verifier is given the powers of the KZG commitments, it is inefficient to perform scalar multiplications for two commitments (imagine the time complexity of multiplying two $d$-degree polynomials is $O(d^2)$), which implies this method is hard to be succinct.\nThe second method is more general and widely used. The basic idea is instead of proving the commitments satisfy the conditions, the prover reveals the evaluations of the polynomials at a random point sent by the verifier to prove the evaluations satisfy the conditions; at the same time, the prover proves the evaluations are valid through the binding property of KZG commitment. This method works because of the Schwartz-Zippel lemma, which tells us if the equation (of the polynomials) holds at a random evaluation point on the domain $\\mathcal{H}_\\kappa$, then it holds at any point on $\\mathcal{H}_\\kappa$ with high probability. The probability is $d/|\\mathbb{F}|$, where $d$ is the number of roots of the equation and $\\mathbb{F}$ is the field of the random evaluation point. This means as long as the field is big enough, the probability of failure is negligible. By rearranging the polynomials, the verifier can challenge any point on the group field rather than $\\mathcal{H}_\\kappa$, which makes the probability of failure tend to $0$.\nProtocol Details # Array Level # $\\mathcal{P}$ holds a number $\\eta\\in\\mathbb{Z}$ $\\mathcal{P}$ computes or holds an array $\\mathsf{T}=[t_0,t_1,t_2,\\dots,t_{k-1}]$ of $k$ (recall $k=\\lceil\\log_2{\\eta}\\rceil$) integers ($t_i\\in\\mathbb{Z}$) such that: $\\mathsf{T}[0]=\\eta$ $\\mathsf{T}[k-1]\\in\\{0,1\\}$ $\\mathsf{T}[i]-2\\cdot\\mathsf{T}[i+1]\\in\\{0,1\\}$ Polynomial Level # We assume the array $\\mathsf{T}$ is encoded as the y-coordinates into a univariant polynomial where the x-coordinates (called the domain $\\mathcal{H}_\\kappa$) are chosen as the multiplicative group of order $\\kappa$ with generator $\\omega\\in\\mathbb{G}_\\kappa$ (see Background for more). In short, $\\omega^0$ is the first element and $\\omega^{\\kappa-1}$ is the last element of $\\mathcal{H}_\\kappa$. If $\\kappa$ is larger than the length of the array, the array can be padded with elements of value 0 (which will not change the sum).\nRecall the constraints we want to prove:\n$\\mathsf{T}[0]=\\eta$ $\\mathsf{T}[k-1]\\in\\{0,1\\}$ $\\mathsf{T}[i]-2\\cdot\\mathsf{T}[i+1]\\in\\{0,1\\}$ In polynomial form, the constraints are:\nFor $X=\\omega^0$: $\\mathsf{Poly}_\\mathsf{T}(X)=\\eta$ For $X=\\omega^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{T}(X)\\in\\{0,1\\}$ For all $X=\\mathcal{H}_\\kappa\\setminus{\\omega^{\\kappa-1}}$: $\\mathsf{Poly}_\\mathsf{T}(X)-2\\cdot\\mathsf{Poly}_\\mathsf{T}(X\\omega)\\in\\{0,1\\}$ Note because the value of $\\eta$ is a secret, $\\mathcal{P}$ will not reveal $\\eta$ to let $\\mathcal{V}$ verify $\\eta$ is the evaluation of $\\mathsf{Poly}_\\mathsf{T}(\\omega^0)$. $\\mathcal{P}$ will leverage the hiding property of KZG (Pedersen) commitment to prove the committed $\\eta$ is the correct evaluation. Specifically, $\\mathcal{P}$ claims the committed $\\eta$ is the correct one and opens $\\mathsf{Poly}_\\mathsf{T}$ at $\\omega^0$. If the committed $\\eta$ satisfy the KZG verification, $\\mathcal{V}$ can believe the first constraint is satisfied.\nWe take care of the \u0026ldquo;for $X$\u0026rdquo; conditions of constraints 2 and 3 by zeroing out the rest of the polynomial that is not zero. See the gadget zero1 for more on why this works.\n$\\mathsf{Poly}_\\mathsf{Vanish1}(X)=\\mathsf{Poly}_\\mathsf{T}(X)\\cdot[\\mathsf{Poly}_\\mathsf{T}(X)-1]\\cdot\\frac{X^\\kappa-1}{X-\\omega^{\\kappa-1}}=0$ $\\mathsf{Poly}_\\mathsf{Vanish2}(X)=[\\mathsf{Poly}_\\mathsf{T}(X)-2\\cdot\\mathsf{Poly}_\\mathsf{T}(X\\omega)]\\cdot[\\mathsf{Poly}_\\mathsf{T}(X)-2\\cdot\\mathsf{Poly}_\\mathsf{T}(X\\omega)-1]\\cdot(X-\\omega^{\\kappa-1})=0$ The two equations are vanishing for every value of $X\\in\\mathcal{H}_\\kappa$ (but not necessarily true outside of these values). To show this, we divide each polynomial by $X^\\kappa-1$, which is a minimal vanishing polynomial for $\\mathcal{H}_\\kappa$ that does not require interpolation to create. If the quotient is polynomial (and not a rational function), then $\\mathsf{Poly}_\\mathsf{Vanish1}(X)$ and $\\mathsf{Poly}_\\mathsf{Vanish2}(X)$ must be vanishing on $\\mathcal{H}_\\kappa$ too. Specifically, the prover computes:\n$Q_1(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish1}(X)}{X^\\kappa - 1}$ $Q_2(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish2}(X)}{X^\\kappa - 1}$ We can replace polynomials $Q_1(X)$, and $Q_2(X)$ with a single polynomial $Q(X)$. We can do this because all three constraints have the same format: $\\mathsf{Poly}_\\mathsf{Vanish_i}(X)=0$. The batching technique is to create a new polynomial with all three $\\mathsf{Poly}_\\mathsf{Vanish_i}(X)$ values as coefficients. If and (overwhelmingly) only if all three are vanishing, then so will the new polynomial. This polynomial will be evaluated at a random challenge point $\\rho$ selected after the commitments to the earlier polynomials are fixed.\n$Q(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish1}(X)+\\rho\\cdot\\mathsf{Poly}_\\mathsf{Vanish2}(X)}{X^n - 1}$\nBy rearranging, we can get $\\mathsf{Poly}_\\mathsf{Zero}(X)$ as a true zero polynomial (zero at every value both in $\\mathcal{H}_\\kappa$ and outside of it):\n$\\mathsf{Poly}_\\mathsf{Zero}(X)=\\mathsf{Poly}_\\mathsf{Vanish1}(X) + \\rho\\cdot\\mathsf{Poly}_\\mathsf{Vanish2}(X)-Q(X)\\cdot(X^{\\kappa-1}-1)=0$\nUltimately the range gadget will satisfy the following constraints at the Commitment Level:\nShow $Q(X)$ exists (as a polynomial that evenly divides the divisor) Show $\\mathsf{Poly}_\\mathsf{Zero}(X)$ is correctly constructed from $\\mathsf{Poly}_\\mathsf{T}(X)$ Show $\\mathsf{Poly}_\\mathsf{Zero}(X)$ is the zero polynomial Commitment Level # The verifier will never see the arrays or polynomials themselves. They are undisclosed because they either (i) contain private data or (ii) are too large to examine and maintain a succinct proof system. Instead, the prover will use commitments.\nThe prover will write the following commitments to the transcript:\n$K_\\mathsf{T}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{T}(X))$ The prover will generate a random challenge evaluation point (using strong Fiat-Shamir) on the polynomial that is outside of $\\mathcal{H}_\\kappa$. Call this point $\\rho$. It will be used by the prover to create polynomial $Q(X)$ (see above) and the prover will write to the transcript:\n$\\rho$ $K_Q=\\mathsf{KZG.Commit}(Q(X))$ The prover will generate a second random challenge evaluation point (using strong Fiat-Shamir) on the polynomial that is outside of $\\mathcal{H}_\\kappa$. Call this point $\\zeta$. The prover will write the point and opening proofs to the transcript:\n$\\zeta$ $\\mathsf{Poly}_\\mathsf{T}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{T},\\zeta)$ $\\mathsf{Poly}_\\mathsf{T}(\\zeta\\omega)=\\mathsf{KZG.Open}(K_\\mathsf{T},\\zeta\\omega)$ $Q(\\zeta)=\\mathsf{KZG.Open}(K_Q,\\zeta)$ To check the proof, the verifier uses the transcript to construct the value $Y_\\mathsf{Zero}$ as follows:\n$Y_\\mathsf{Vanish1}=\\mathsf{Poly}_\\mathsf{T}(\\zeta)\\cdot[\\mathsf{Poly}_\\mathsf{T}(\\zeta)-1]\\cdot\\frac{\\zeta^\\kappa-1}{\\zeta-\\omega^{\\kappa-1}}$ $Y_\\mathsf{Vanish2}=[\\mathsf{Poly}_\\mathsf{T}(\\zeta)-2\\cdot\\mathsf{Poly}_\\mathsf{T}(\\zeta\\omega)]\\cdot[\\mathsf{Poly}_\\mathsf{T}(\\zeta)-2\\cdot\\mathsf{Poly}_\\mathsf{T}(\\zeta\\omega)-1]\\cdot(\\zeta-\\omega^{\\kappa-1})$ $Y_\\mathsf{Zero}=Y_\\mathsf{Vanish1}+\\rho\\cdot{Y_\\mathsf{Vanish2}}-Q(\\zeta)\\cdot(\\zeta^n-1)$ Finally, if the constraint system is true, the following constraint will be true (and will be false otherwise with overwhelming probability, due to the Schwartz-Zippel lemma on $\\rho$ and $\\zeta$) :\n$Y_\\mathsf{Zero}\\overset{?}{=}0$ Security Proof # Completeness # Any honest prover can do the computations explained above and create an accepting proof.\nSoundness # We prove knowledge soundness in the Algebraic Group Model (AGM). To do so, we must prove that there exists an efficient extractor $\\mathcal{E}$ such that for any algebraic adversary $\\mathcal{A}$ the probability of $\\mathcal{A}$ winning the following game is $\\mathsf{negl}(\\lambda)$.\nGiven $[g,g^\\tau,g^{\\tau^2},\\dots,g^{\\tau^{n-1}}]$, $\\mathcal{A}$ outputs commitments to $\\mathsf{Poly}_\\mathsf{T}(X)$ and $Q$ $\\mathcal{E}$, given access to $\\mathcal{A}$\u0026rsquo;s outputs from the previous step, outputs $\\mathsf{Poly}_\\mathsf{T}(X)$ and $Q$ $\\mathcal{A}$ plays the part of the prover in showing that $Y_\\mathsf{Zero}$ is zero at a random challenge $\\zeta$ $\\mathcal{A}$ wins if $\\mathcal{V}$ accepts at the end of the protocol $\\eta\\notin[0,r]$ Our proof is as follows:\nFirst, we prove $\\eta\\ge{0}$. To make $\\mathsf{Poly}_\\mathsf{Vanish1}$ exist, the last value of $\\mathsf{T}$ must be zero or one. From $\\mathsf{Poly}_\\mathsf{Vanish2}$, it can be observed that $\\mathsf{T}[i]\\ge\\mathsf{T}[i+1]$ for all $i\\in[0,\\kappa-2]$. Thus, $\\mathsf{T}[0]$ is equal to or greater than $\\mathsf{T}[\\kappa-1]$, i.e., $\\eta\\ge{0}$.\nSecond, we prove $\\eta\\le{r}$. For simplicity, we assume $r$ is the power of two (recall $\\kappa=\\log_2{r}$). From $\\mathsf{Poly}_\\mathsf{Vanish2}$, we know $\\mathsf{T}[0]$ is less than or equal to $2^\\kappa$. Therefore, $\\eta\\le{r}$.\nZero-Knowledge # To prove the above protocol is zero-knowledge, we do so by constructing a probabilistic polynomial time simulator $\\mathcal{S}$ which, for every (possibly malicious) verifier $\\mathcal{V}$, can output a view of the execution of the protocol that is indistinguishable from the view produced by the real execution of the program.\nThe simulator $\\mathcal{S}$ randomly generates an $\\eta^*$, then follows the same steps a prover would prove the lookup argument. $\\mathcal{S}$ computes $\\mathsf{T^*}$ and interpolates $\\mathsf{Poly}_\\mathsf{T^*}$ from $\\mathsf{T^*}$. It computes $Q^*(X)$ and finally outputs the commitments to each of these polynomials (and writes the commitments to the transcript). Then, it generates the random challenge $\\zeta^*$ (once again this is by strong Fiat-Shamir). It creates opening proofs for $\\mathsf{Poly}_\\mathsf{T^*}(\\zeta^*),\\mathsf{Poly}_\\mathsf{T^*}(\\zeta^*\\omega)$, and $Q^*(\\zeta^*)$, and writes these to the transcript as well. Since $\\mathcal{S}$ knows each of the above polynomials, it can honestly compute this step and the proof will be accepted by $\\mathcal{V}$. The transcript it generates this way will be indistinguishable from a transcript generated from a real execution since $\\mathsf{PolyCommit}_\\mathsf{Ped}$ has the property of Indistinguishability of Commitments due to the randomization by $h^{\\hat{\\phi}(x)}$.\n"},{"id":12,"href":"/docs/gadgets/rotate/","title":"Rotate","section":"Gadgets","content":" Rotate # Assume $\\mathsf{Arr}$ is an array of data of size $n$. It is encoded as the y-coordinates into univariant polynomials where the x-coordinates (called the domain $\\mathcal{H}_\\kappa$) are chosen as the multiplicative group of order $\\kappa$ with generator $\\omega\\in\\mathbb{G}_\\kappa$ (see Background for more). In short, $\\omega^0$ is the first element and $\\omega^{\\kappa-1}$ is the last element of $\\mathcal{H}_\\kappa$. We call our polynomial $\\mathsf{Poly}_\\mathsf{Arr}(X)$. The goal is to construct an output polynomial $\\mathsf{Poly_\\mathsf{Arr_\\alpha}}$ where all the elements in $\\mathsf{Arr}$ have been rotated by $\\alpha$ positions; i.e. $\\mathsf{Arr}[i] \\larr \\mathsf{Arr}[i + \\alpha]$. Here, the index is defined mod $n$.\nWritten in terms the polynomials, the goal is that $\\mathsf{Poly_\\mathsf{Arr_\\alpha}}(\\omega^i) = \\mathsf{Poly_\\mathsf{Arr}}(\\omega^i\\cdot\\omega^\\alpha)$ for all $i \\in [0, n-1]$. To this end, we define $\\mathsf{Poly_\\mathsf{Arr_\\alpha}}(X) = \\mathsf{Poly_\\mathsf{Arr}}(X)\\cdot\\omega^\\alpha$ and demonstrate below why this satisfies the requirements of the output polynomials.\nConsider $\\mathsf{Poly_\\mathsf{Arr}}(X) = c_{n-1}X^{n-1} + \\dots + c_2X^2 + c_1X + c_0$. Then:\n$\\mathsf{Poly_\\mathsf{Arr_\\alpha}}(X)$‚Äã\n$= \\mathsf{Poly_Arr}(X) \\cdot \\omega^\\alpha$‚Äã\n$= (c_{n-1}X^{n-1} + \\dots + c_2X^2 + c_1X + c_0)(\\omega^\\alpha) $‚Äã\n$= c_{n-1}X^{n-1}\\cdot\\omega^\\alpha + \\dots + c_2X^2\\cdot\\omega^\\alpha + c_1X\\cdot\\omega^\\alpha + c_0\\cdot\\omega^\\alpha$\n$= \\mathsf{Poly_\\mathsf{Arr}}(X\\cdot\\omega^\\alpha)$\nIn particular, $\\mathsf{Poly_{Arr_\\alpha}}(\\omega^i) = \\mathsf{Poly_\\mathsf{Arr}}(\\omega^i\\cdot\\omega^\\alpha)$ for $i \\in [0, n-1]$. We also note that $\\omega^n = \\omega^0$, since $\\omega$ is of order $\\kappa$. Thus the exponent of $\\omega$ is defined mod $n$, like the indexing of $\\mathsf{Arr}$. This means that $\\omega^i\\cdot\\omega^\\alpha$ wraps around to have the rotation defined as it should be for $i + \\alpha \\gt n-1$.\n"},{"id":13,"href":"/docs/gadgets/shuffle1/","title":"Shuffle1","section":"Gadgets","content":" Shuffle (Type 1) # Recap of types # Type Description Recap This shuffle1 $\\mathsf{Arr}_2=\\mathsf{Permute}(\\mathsf{Arr}_1)$ Array $\\mathsf{Arr}_2$ is a shuffle of $\\mathsf{Arr}_1$ for some undisclosed permutation $\\pi$. ‚úÖ shuffle2 $\\mathsf{Arr}_2=\\mathsf{Permute}(\\mathsf{Arr}_1 ,\\pi)$ Array $\\mathsf{Arr}_2$ is a shuffle of $\\mathsf{Arr}_1$ under a disclosed permutation $\\pi$. Relation # $ \\mathcal{R}_{\\mathtt{shuffle1}} := \\left\\{ \\begin{array}{l} (K_\\mathsf{Arr_1},K_\\mathsf{Arr2}) \\end{array} \\middle | \\begin{array}{l} \\mathsf{Arr_1} = [a_{(1,0)}, a_{(1,1)}, a_{(1,2)}, \\dots, a_{(1,n-1)}],\\\\ \\mathsf{Arr_2} = [a_{(2,0)}, a_{(2,1)}, a_{(2,2)}, \\dots, a_{(2,n-1)}], \\\\ \\mathsf{Poly}_\\mathsf{Arr_1}=\\mathsf{FFT.Interp}(\\omega,\\mathsf{Arr_1}), \\\\ \\mathsf{Poly}_\\mathsf{Arr_2}=\\mathsf{FFT.Interp}(\\omega,\\mathsf{Arr_2}), \\\\ K_\\mathsf{Arr_1}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr_1}),\\\\ K_\\mathsf{Arr_2}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr_2}), \\end{array} \\right\\} $\nIntuition # The prover ($\\mathcal{P}$) holds 2 arrays, $\\mathsf{Arr_1 }$ and $\\mathsf{Arr_2}$, of $n$ integers from $\\mathbb{Z}_q$: $[a_0, a_1, a_2, \\dots, a_{n-1}]$. It will produce a succinct (independent of $n$) proof that $\\mathsf{Arr}_2$ is a shuffle of $\\mathsf{Arr}_1$ for some undisclosed permutation $\\pi$. The prover will encode the two arrays into polynomials, $\\mathsf{Poly}_\\mathsf{Arr_1}$ and $\\mathsf{Poly}_\\mathsf{Arr_2}$ (using evaluation points on the domain $\\mathcal{H}_\\kappa$) and commit to them as $K_\\mathsf{Arr_1}$ and $K_\\mathsf{Arr_2}$. The verifier ($\\mathcal{V}$) cannot check either array directly (they may contain secret information, and even if they do not, it is too long to check) so the verifier only sees $K_\\mathsf{Arr_1}$ and $K_\\mathsf{Arr_2}$.\nOne idea to check that $\\mathsf{Arr_2}$ is a permutation of $\\mathsf{Arr_1}$ might be to perform a product check on the two arrays. If the permutation relation holds, then the products will be equal; however, many arrays can have their entries multiply to the same number, without necessarily containing the same elements.\nInstead, the prover constructs two new arrays, $\\mathsf{Arr_1}'$ and $\\mathsf{Arr_2}'$, where $\\mathsf{Arr_j}'$ contains the points $ \\{r - \\mathsf{Arr_j}[i] \\}_{i \\in [0, n-1]}$ for $r$ a random field element. Then, a product check is run on these two arrays. One way to understand why this works is to think of it as creating two auxilary polynomials, ${\\mathsf{Poly}}_\\mathsf{Arr_1'}$ and ${\\mathsf{Poly}}_\\mathsf{Arr_2'}$, where $\\mathsf{Poly}_\\mathsf{Arr_j'}(X) = \\prod^{n-1}_{i = 1}(X - \\mathsf{Arr_j}[i])$. If ${\\mathsf{Poly}}_\\mathsf{Arr_1'}$ = $\\mathsf{Poly}_\\mathsf{Arr_2'}$, then they have the same factorization. This means that $\\mathsf{Arr}_1$ and $\\mathsf{Arr}_2$ must contain the same elements (in possibly different orders); in other words, $\\mathsf{Arr}_2$ is a permutation of $\\mathsf{Arr}_1$. To check this equality, a random challenge point $r$ is generated and the products are checked at that point. If they are equal at that point then (with overwhelming probabiltiy) the polynomials are equal.\nIn addition to demontrasting the equality of the product of $\\mathsf{Arr_1}'$ and $\\mathsf{Arr_2}'$, it must also be shown that these two arrays are defined correctly in terms of the original arrays. In other words, it must be shown that $\\mathsf{Arr_j}'[i]= r - \\mathsf{Arr_j}[i]$ for $i \\in [0, n-1]$. Once this, in addition to the product check, has been done, we have shown that $\\mathsf{Arr}_2$ is a shuffle of $\\mathsf{Arr}_1$ for some undisclosed permutation $\\pi$.\nProtocol Details # Array Level # $\\mathcal{P}$ holds an array $\\mathsf{Arr_1} = [a_{(1,0)}, a_{(1,1)}, a_{(1,2)}, \\dots, a_{(1,n-1)}]$ of $n$ integers ($a_{(1,i)} \\in \\mathbb{Z}_q$) $\\mathcal{P}$ holds an array $\\mathsf{Arr_2} = [a_{(2,0)}, a_{(2,1)}, a_{(2,2)}, \\dots, a_{(2,n-1)}]$ of $n$ integers ($a_{(2,i)} \\in \\mathbb{Z}_q$) $\\mathcal{P}$ computes $\\mathsf{Arr_j}'$ as follows for $j \\in [1,2]$: $\\mathsf{Arr_j}'[i]= r - \\mathsf{Arr_j}[i]$ Polynomial Level # We assume that $\\mathsf{Arr_1}$ and $\\mathsf{Arr_2}$ are encoded as the y-coordinates into a univariant polynomial where the x-coordinates (called the domain $\\mathcal{H}_\\kappa$) are chosen as the multiplicative group of order $\\kappa$ with generator $\\omega\\in\\mathbb{G}_\\kappa$ (see Background for more). In short, $\\omega^0$ is the first element and $\\omega^{\\kappa-1}$ is the last element of $\\mathcal{H}_\\kappa$. If $\\kappa$ is larger than the length of the arrays, the arrays can be padded with elements all of value 1 (or any other value, as long as it is the same for both arrays).\nRecall the two steps we want to prove:\n$\\prod^{n-1}_{i=0}\\{r - \\mathsf{Arr_1[i]}\\} = \\prod^{n-1}_{i=0}\\{r - \\mathsf{Arr_2[i]}\\}$ $\\mathsf{Arr_j}'[i]= r - \\mathsf{Arr_j}[i]$ for $j \\in [1,2]$, $0 \\leq 1 \\leq n-1$ The first step is done as a mult3 product check, and we write the second step as two constraints in polynomial form. From this point on we focus on the polynomial details of the second step.\nFor all $X$ from $\\omega^0$ to $\\omega^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Arr_1'}(X) = (r - \\mathsf{Poly}_\\mathsf{Arr_1}(X))$ For all $X$ from $\\omega^0$ to $\\omega^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Arr_2'}(X) = (r - \\mathsf{Poly}_\\mathsf{Arr_2}(X))$ We adjust each of these constraints to show an equality with 0 and label them:\n$\\mathsf{Poly}_\\mathsf{Vanish1}(X)= \\mathsf{Poly}_\\mathsf{Arr_1'}(X) - (r - \\mathsf{Poly}_\\mathsf{Arr_1}(X)) = 0$ $\\mathsf{Poly}_\\mathsf{Vanish2}(X)= \\mathsf{Poly}_\\mathsf{Arr_2'}(X) - (r - \\mathsf{Poly}_\\mathsf{Arr_2}(X)) = 0$ This equation is true for every value of $X \\in \\mathcal{H}_\\kappa$ (but not necessarily true outside of these values). To show this, we divide each polynomial by $X^\\kappa - 1$, which is a minimal vanishing polynomial for $\\mathcal{H}_\\kappa$ that does not require interpolation to create. If the quotients are polynomials (and not rational functions), then $\\mathsf{Poly}_\\mathsf{Vanish}(X)$ must be vanishing on $\\mathcal{H}_\\kappa$ too. Specifically, the prover computes:\n$Q_1(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish1}(X)}{X^\\kappa - 1}$ $Q_2(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish2}(X)}{X^\\kappa - 1}$ We can replace polynomials $Q_1(X)$ and $Q_2(X)$ with a single polynomial $Q(X)$. We can do this because both constraints have the same format: $\\mathsf{Poly}_\\mathsf{Vanish_i}(X)=0$. The batching technique is to create a new polynomial with both $\\mathsf{Poly}_\\mathsf{Vanish_i}(X)$ values as coefficients. If and (overwhelmingly) only if both are vanishing, then so will the new polynomial. This polynomial will be evaluated at a random challenge point $\\rho$ selected after the commitments to the earlier polynomials are fixed.\n$Q(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish1}(X) + \\mathsf{Poly}_\\mathsf{Vanish2}(X) \\rho}{X^n - 1}$\nBy rearranging, we can get $\\mathsf{Poly}_\\mathsf{Zero}(X)$ as a true zero polynomial (zero at every value both in $\\mathcal{H}_\\kappa$ and outside of it):\n$\\mathsf{Poly}_\\mathsf{Zero}(X)=\\mathsf{Poly}_\\mathsf{Vanish1}(X) + \\rho \\mathsf{Poly}_\\mathsf{Vanish2}(X) - Q(X)\\cdot (X^n - 1)=0$\nUltimately the shuffle1 argument will satisfy the following constraints at the Commitment Level:\nShow $Q(X)$ exists (as a polynomial that evenly divides the divisor) Show $\\mathsf{Poly}_\\mathsf{Zero}(X)$ is correctly constructed from $\\mathsf{Poly}_\\mathsf{Arr}(X)$ Show $\\mathsf{Poly}_\\mathsf{Zero}(X)$ is the zero polynomial In addition, it will show that $\\prod^{n-1}_{i=0}(r - \\mathsf{Arr_1}[i]) = \\prod^{n-1}_{i=0}(r - \\mathsf{Arr_2}[i])$ using a mult3 product check.\nCommitment Level # The verifier will never see the arrays or polynomials themselves. They are undisclosed because they either (i) contain private data or (ii) they are too large to examine and maintain a succinct proof system. Instead the prover will use commitments.\nThe prover will create a transcript for the product check, as decribed in mult3. Below, we give details specific to the second step, showing that $\\mathsf{Arr_j}'[i]= r - \\mathsf{Arr_j}[i]$ for $j \\in [1,2]$, $0 \\leq 1 \\leq n-1$.\nThe prover will write the following commitments to the transcript:\n$K_\\mathsf{Arr_1}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr_1}(X))$ $K_\\mathsf{Arr_2}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr_2}(X))$ The prover will generate a random challenge evaluation point (using strong Fiat-Shamir) on the polynomials that is outside of $\\mathcal{H}_\\kappa$. Call this point $r$. It will use this point to define the sets $ \\{r - \\mathsf{Poly}_\\mathsf{Arr_j}(a) \\}_{a \\in \\mathcal{H}_\\kappa}$ and run the product check. It will write the product check into the transcript. However, here we focus only on what is relevant to the second step, the point $r$ and the following polynomials:\n$r$ $K_\\mathsf{Arr_1'}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr_1'}(X))$ $K_\\mathsf{Arr_2'}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr_2'}(X))$ $K_Q=\\mathsf{KZG.Commit}(Q(X))$ The prover will generate a random challenge evaluation point (using strong Fiat-Shamir) on the polynomials that is outside of $\\mathcal{H}_\\kappa$. Call this point $\\zeta$. The prover will write the point and opening proofs to the transcript:\n$\\zeta$ $\\mathsf{Poly}_\\mathsf{Arr_1}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Arr_1},\\zeta)$ $\\mathsf{Poly}_\\mathsf{Arr_2}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Arr_2},\\zeta)$ $\\mathsf{Poly}_\\mathsf{Arr_1'}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Arr_1'},\\zeta)$ $\\mathsf{Poly}_\\mathsf{Arr_2'}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Arr_2'},\\zeta)$ $Q(\\zeta)=\\mathsf{KZG.Open}(K_Q,\\zeta)$ To check the proof, the verifier uses the transcript to construct the value $Y_\\mathsf{Zero}$ as follows:\n$Y_\\mathsf{Vanish1}= \\mathsf{Poly}_\\mathsf{Arr_1'}(\\zeta) - (r - \\mathsf{Poly}_\\mathsf{Arr_1}(\\zeta))$ $Y_\\mathsf{Vanish2}= \\mathsf{Poly}_\\mathsf{Arr_2'}(\\zeta) - (r - \\mathsf{Poly}_\\mathsf{Arr_2}(\\zeta))$ $Y_\\mathsf{Zero}=Y_\\mathsf{Vanish1} + \\rho Y_\\mathsf{Vanish2} - Q(\\zeta)\\cdot (\\zeta^n - 1)$ Finally, if the constraint system is true, the following constraint will be true (and will be false otherwise with overwhelming probability, due to the Schwartz-Zippel lemma on $\\zeta$) :\n$Y_\\mathsf{Zero}\\overset{?}{=}0$ Implementations # Security Proof # Completeness # Any honest prover can do the computations explained above and create an accepting proof.\nSoundness # We prove knowledge soundness in the Algebraic Group Model (AGM). We assume soundness of the product check (it is proven in mult3) and conduct a proof of soundness for the rest of the protocol. To do so, we must prove that there exists an efficient extractor $\\mathcal{E}$ such that for any algebraic adversary $\\mathcal{A}$, the probability of $\\mathcal{A}$ winning the following game is $\\mathsf{negl}(\\lambda)$.\nGiven $[g, g^\\tau, g^{\\tau^2}, \\dots,g^{\\tau^{n-1}}]$ $\\mathcal{A}$ outputs commitments to $\\mathsf{Poly}_\\mathsf{Arr_1}(X)$, $\\mathsf{Poly}_\\mathsf{Arr_2}(X)$, $\\mathsf{Poly}_\\mathsf{Arr_1'}(X)$, $\\mathsf{Poly}_\\mathsf{Arr_2'}(X)$, $Q$\n$\\mathcal{E}$, given access to $\\mathcal{A}$\u0026rsquo;s outputs from the previous step, outputs $\\mathsf{Poly}_\\mathsf{Arr_1}(X)$, $\\mathsf{Poly}_\\mathsf{Arr_2}(X)$, $\\mathsf{Poly}_\\mathsf{Arr_1'}(X)$, $\\mathsf{Poly}_\\mathsf{Arr_2'}(X)$, $Q$\n$\\mathcal{A}$ plays the part of the prover in showing that $Y_{\\mathsf{Zero}}$ is zero at a random challenge $\\zeta$\n$\\mathcal{A}$ wins if:\ni) $\\mathcal{V}$ accepts at the end of the protocol\nii) $\\mathsf{Arr}_2 \\neq \\mathsf{Permute}(\\mathsf{Arr}_1)$\nOur proof is as follows:\nFor the second win condition to be fulfilled, there must be some $a \\in \\mathsf{Arr_2}, a \\notin \\mathsf{Arr_1}$, or vice versa. Since $\\mathsf{Arr_1}$ and $\\mathsf{Arr_2}$ have different entries, $\\prod^{n-1}_{i = 1}(X - \\mathsf{Arr_1}[i]$ and $\\prod^{n-1}_{i = 1}(X - \\mathsf{Arr_2}[i]$ have different factorizations and are thus different polynomials. By the Schwartz-Zippel lemma, there is negligible probability that they are equal at $r$. Any strategy to increase this probability to greater than negligible means $\\mathcal{A}$ must pass in $\\mathsf{Arr_j'}$ such that $\\mathsf{Arr_j'}[i] \\neq r - \\mathsf{Arr_j}[i]$ for some index $i$ and $j \\in [1, 2]$. But then $\\mathsf{Poly}_\\mathsf{Vanishj}(X)$ is not vanishing on $\\mathcal{H}_\\kappa$, so $Q(X)$ is not a polynomial (it is a rational function). This means that $\\mathcal{A}$ cannot calcuated the correct commitment value $g^{Q(\\tau)}$ without solving the t-SDH. Thus, $\\mathcal{A}$ chooses an arbitrary value for $Q(\\tau)$ and sends $K_Q = g^{Q(\\tau)}$. It also sends a commitment to $\\mathsf{Poly}_\\mathsf{Arr}(X)$. Both commitments $\\mathcal{A}$ has outputted are linear combinations of the elements in $[g, g^\\tau, g^{\\tau^2}, \\dots,g^{\\tau^{n-1}}]$. $\\mathcal{E}$ is given these coefficients (since $\\mathcal{A}$ is an algebraic adversary) so $\\mathcal{E}$ can output the original polynomials.\n$\\mathcal{A}$ then obtains the random challenge $\\zeta$ (using strong Fiat-Shamir). By the binding property of KZG commitments, $\\mathsf{Poly}_\\mathsf{Arr_1}(\\zeta)$, $\\mathsf{Poly}_\\mathsf{Arr_2}(\\zeta)$, $\\mathsf{Poly}_\\mathsf{Arr_1'}(\\zeta)$, and $\\mathsf{Poly}_\\mathsf{Arr_2'}(\\zeta)$ can each only feasibliy be opened to one value. For $\\mathcal{A}$ to have the verifier accept, it must send a proof that $Q(\\zeta)$ opens to $Q(\\zeta) = \\frac{Y_\\mathsf{Vanish1} + \\rho Y_\\mathsf{Vanish2}}{(\\zeta^n - 1)}$. This means being able to send $g^{q(\\tau)}$ where $q(\\tau) = \\frac{Q(\\tau) - Q(\\zeta)}{\\tau - \\zeta}$ and $Q(\\zeta) = \\frac{Y_\\mathsf{Vanish1} + \\rho Y_\\mathsf{Vanish2}}{(\\zeta^n - 1)}$. Since $Q(\\tau)$ and $Q(\\zeta)$ are known, this implies knowing $g^{\\frac{1}{\\tau - \\zeta}}$. Thus $\\mathcal{A}$ would have found $\\langle\\zeta,g^{\\frac{1}{\\tau - \\zeta}}\\rangle$, which is the t-SDH problem. We have shown that creating an accepting proof reduces to the t-SDH, so $\\mathcal{A}$\u0026rsquo;s probability of success is negligible.\nZero-Knowledge # We prove that the above protocol is zero-knowledge when $\\mathsf{PolyCommit}_\\mathsf{Ped}$ (from the KZG paper) is used for the polynomial commitments. We assume the product check is zero-knowledge (it is proven in mult3), and conduct a proof for the rest of the protocol. We do so by constructing a probabilistic polynomial time simulator $\\mathcal{S}$ that knows the trapdoor $\\tau$, which, for every (possibly malicious) verifier $\\mathcal{V}$, can output a view of the execution of the protocol that is indistinguishable from the view produced by the real execution of the program.\nThe simulator $\\mathcal{S}$ choose arbitrary values for ${\\mathsf{Poly}_\\mathsf{Arr_1}(\\tau)}$ and ${\\mathsf{Poly}_\\mathsf{Arr_2}(\\tau)}$, then computes $g^{\\mathsf{Poly}_\\mathsf{Arr_1}(\\tau)}$ and $g^{\\mathsf{Poly}_\\mathsf{Arr_2}(\\tau)}$ to output as the commitments $ K_\\mathsf{Arr_1}$ and $K_\\mathsf{Arr_1}$. $\\mathcal{S}$ then generates the random challenge $r$ (by strong Fiat-Shamir). It chooses arbitrary values for ${\\mathsf{Poly}_\\mathsf{Arr_1'}(\\tau)}$ and ${\\mathsf{Poly}_\\mathsf{Arr_2'}(\\tau)}$, then computes $g^{\\mathsf{Poly}_\\mathsf{Arr_1'}(\\tau)}$ and $g^{\\mathsf{Poly}_\\mathsf{Arr_2'}(\\tau)}$ to output as the commitments $ K_\\mathsf{Arr_1'}$ and $K_\\mathsf{Arr_1'}$. It creates a view of the product check as described in the zero-knowledge proof for mult3.\n$\\mathcal{S}$ generates the challenge evaluation point $\\rho$ (by strong Fiat-Shamir) and computes $Q(\\tau)$ using $\\rho$ and the values it chose for ${\\mathsf{Poly}_\\mathsf{Arr_1}(\\tau)}$, ${\\mathsf{Poly}_\\mathsf{Arr_2}(\\tau)}$, ${\\mathsf{Poly}_\\mathsf{Arr_1'}(\\tau)}$, and ${\\mathsf{Poly}_\\mathsf{Arr_2'}(\\tau)}$. $\\mathcal{S}$ outputs the commitment $K_Q = g^{Q(\\tau)}$.\nNow, $\\mathcal{S}$ generates the random challenge point $\\zeta$ (which we assume is not in $\\mathcal{H}_\\kappa$; if it is in $\\mathcal{H}_\\kappa$, $\\mathcal{S}$ simply restarts and runs from the beginning). This is once again by strong Fiat-Shamir. $\\mathcal{S}$ then create fake opening proofs for ${\\mathsf{Poly}_\\mathsf{Arr_1}(\\zeta)}$, ${\\mathsf{Poly}_\\mathsf{Arr_2}(\\zeta)}$, ${\\mathsf{Poly}_\\mathsf{Arr_1'}(\\zeta)}$, and ${\\mathsf{Poly}_\\mathsf{Arr_2'}(\\zeta)}$, to arbitrary values. This is done using the knowledge of $\\tau$, calculating the respective witness $q(\\tau) = \\frac{{f(\\tau) - f(\\zeta)}}{\\tau - \\zeta}$ for each of the polynomials.\nFinally, $\\mathcal{S}$ creates a fake opening proof for $Q(\\zeta) = \\frac{Y_\\mathsf{Vanish1} + \\rho Y_\\mathsf{Vanish2}}{(\\zeta^n - 1)}$. This is done using knowledge of $\\tau$ to calculate an accepting witness $q(\\tau)$, as above. This means that $Y_\\mathsf{Zero}$ will be zero, and the transcript will be accepted by the verifier. It is indistinguishable from a transcript generates from a real execution, since $\\mathsf{PolyCommit}_\\mathsf{Ped}$ has the property of Indistinguishability of Commitments due to the randomization by $h^{\\hat{\\phi}(x)}$.\n"},{"id":14,"href":"/docs/gadgets/shuffle2/","title":"Shuffle2","section":"Gadgets","content":" Shuffle (Type 2) # Recap of types # Type Description Recap This shuffle1 $\\mathsf{Arr}_2=\\mathsf{Permute}(\\mathsf{Arr}_1)$ Array $\\mathsf{Arr}_2$ is a shuffle of $\\mathsf{Arr}_1$ for some undisclosed permutation $\\pi$. shuffle2 $\\mathsf{Arr}_2=\\mathsf{Permute}(\\mathsf{Arr}_1 ,\\pi)$ Array $\\mathsf{Arr}_2$ is a shuffle of $\\mathsf{Arr}_1$ under a disclosed permutation $\\pi$. ‚úÖ Relation # $\\mathcal{R}_{\\mathtt{shuffle2}} := \\left\\{ \\begin{array}{l} (K_\\mathsf{Arr_1},K_\\mathsf{Arr2}, K_\\pi) \\end{array} \\middle | \\begin{array}{l} \\mathsf{Arr_1} = [a_{(1,0)}, a_{(1,1)}, a_{(1,2)}, \\dots, a_{(1,n-1)}],\\\\ \\mathsf{Arr_2} = [a_{(2,0)}, a_{(2,1)}, a_{(2,2)}, \\dots, a_{(2,n-1)}], \\\\ \\mathsf{Arr_\\pi} = [\\pi(\\omega^0), \\pi(\\omega^1), \\pi(\\omega^2), \\dots, \\pi(\\omega^{n-1})], \\\\ \\mathsf{Poly}_\\mathsf{Arr_1}=\\mathsf{FFT.Interp}(\\omega,\\mathsf{Arr_1}), \\\\ \\mathsf{Poly}_\\mathsf{Arr_2}=\\mathsf{FFT.Interp}(\\omega,\\mathsf{Arr_2}), \\\\ \\mathsf{Poly_\\pi} = \\mathsf{FFT.Interp}(\\omega, \\mathsf{Arr_\\pi}), \\\\ K_\\mathsf{Arr_1}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr_1}),\\\\ K_\\mathsf{Arr_2}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr_2}),\\\\K_\\pi = \\mathsf{KZG.Commit(Poly_{\\pi})} \\end{array} \\right\\}$\nIntuition # The prover ($\\mathcal{P}$) holds 2 arrays, $\\mathsf{Arr_1 }$ and $\\mathsf{Arr_2}$, of $n$ integers from $\\mathbb{Z}_q$: $[a_0, a_1, a_2, \\dots, a_{n-1}]$. It also holds an array $\\mathsf{Arr_\\pi}$, which represents the disclosed permutation $\\pi$. It will produce a succinct (independent of $n$) proof that $\\mathsf{Arr}_2$ is a shuffle of $\\mathsf{Arr}_1$ under the disclosed permutation $\\pi$. The prover will encode the three arrays into polynomials, $\\mathsf{Poly}_\\mathsf{Arr_1}$, $\\mathsf{Poly}_\\mathsf{Arr_2}$, and $\\mathsf{Poly_\\pi}$ (using evaluation points on the domain $\\mathcal{H}_\\kappa$) and commit to them as $K_\\mathsf{Arr_1}$, $K_\\mathsf{Arr_2}$, and $K_\\pi$. The verifier ($\\mathcal{V}$) cannot check any array directly ($\\mathsf{Arr_1 }$ and $\\mathsf{Arr_2}$ may contain secret information, and even if they do not, it is too long to check) so the verifier only sees $K_\\mathsf{Arr_1}$, $K_\\mathsf{Arr_2}$ and $K_\\pi$.\nThe idea behind this check is that if $(\\mathsf{Arr_\\pi}[i], \\mathsf{Arr_2}[i]) = (i, \\mathsf{Arr_1}[i])$ for all $0 \\leq i \\leq n-1$, then $\\mathsf{Arr}_2=\\mathsf{Permute}(\\mathsf{Arr}_1 ,\\pi)$. To gain some intuition on why this is true, pair up tuples from the left and right hand sides of the equation by matching the first entries. Then, if each pair is equal, it means that $\\mathsf{Arr_2}[i] = \\mathsf{Arr_1}[\\mathsf{Arr_\\pi}[i]]$ for $0 \\leq i \\leq n-1$. In other words, $\\mathsf{Arr}_2=\\mathsf{Permute}(\\mathsf{Arr}_1 ,\\pi)$.\nTo check that $(\\mathsf{Arr_\\pi}[i], \\mathsf{Arr_2}[i]) = (i, \\mathsf{Arr_1}[i])$ for all $0 \\leq j \\leq n-1$, we use a similar trick to shuffle1. The prover constructs two arrays: $\\mathsf{Arr_1'} = \\{ r - s\\cdot i - \\mathsf{Arr_1}[i]\\}_{i \\in [0, n-1]}$ and $\\mathsf{Arr_2'} = \\{ r - s\\cdot\\mathsf{Arr_\\pi}[i] - \\mathsf{Arr_2}[i]\\}_{i \\in [0, n-1]}$ for random field elements $r, s$. Then, a product check is conducted on the two arrays. One way to understand why this works is to think of it as creating two auxilary polynomials, ${\\mathsf{Poly}}_\\mathsf{Arr_1'}$ and ${\\mathsf{Poly}}_\\mathsf{Arr_2'}$. Here, $\\mathsf{Poly}_\\mathsf{Arr_1'}(X) = \\prod^{n-1}_{i = 1}(X - Y\\cdot i - \\mathsf{Arr_1}[i])$ and $\\mathsf{Poly}_\\mathsf{Arr_2'}(X) = \\prod^{n-1}_{i = 1}(X - Y\\cdot \\mathsf{Arr_\\pi}[i] - \\mathsf{Arr_2}[i])$. If ${\\mathsf{Poly}}_\\mathsf{Arr_1'}$ = $\\mathsf{Poly}_\\mathsf{Arr_2'}$, then they have the same factorization. This means that $\\mathsf{Arr}_1'$ and $\\mathsf{Arr}_2'$ must contain the same elements (in possibly different orders). By the same intuition of matching first entries as above (in this case, we are pairing up factors where $i$ in $\\mathsf{Poly}_\\mathsf{Arr_1'}(X)$ equals $\\mathsf{Arr_\\pi}[i]$ in $\\mathsf{Poly}_\\mathsf{Arr_2'}(X)$) this shows that $\\mathsf{Arr}_2$ is a permutation of $\\mathsf{Arr}_1$ under $\\pi$. To check the equality of the two auxilary polynomials, random challenge values $r$ and $s$ are generated and the products are checked at that point. If they are equal at that point then (with overwhelming probabiltiy) the polynomials are equal.\nIn addition to demontrasting the equality of the product of $\\mathsf{Arr_1}'$ and $\\mathsf{Arr_2}'$, it must also be shown that these two arrays are defined correctly in terms of the original arrays. In other words, it must be shown that $\\mathsf{Arr_1}'[i]= (i, \\mathsf{Arr_1}[i])$ and $\\mathsf{Arr_2}'[i]= (\\mathsf{Arr_\\pi}[i], \\mathsf{Arr_2}[i])$. Once this, in addition to the product check, has been done, it has been shown that $\\mathsf{Arr}_2$ is a shuffle of $\\mathsf{Arr}_1$ under the disclosed permutation $\\pi$.\nProtocol Details # Array Level # $\\mathcal{P}$ holds an array $\\mathsf{Arr_1} = [a_{(1,0)}, a_{(1,1)}, a_{(1,2)}, \\dots, a_{(1,n-1)}]$ of $n$ integers ($a_{(1,i)} \\in \\mathbb{Z}_q$) $\\mathcal{P}$ holds an array $\\mathsf{Arr_2} = [a_{(2,0)}, a_{(2,1)}, a_{(2,2)}, \\dots, a_{(2,n-1)}]$ of $n$ integers ($a_{(2,i)} \\in \\mathbb{Z}_q$‚Äã) $\\mathcal{P}$ holds an array $\\mathsf{Arr_\\pi} = [\\pi(\\omega^0), \\pi(\\omega^1), \\pi(\\omega^2), \\dots, \\pi(\\omega^{n-1})]$ of $n$ integers ($a_{(2,i)} \\in \\mathbb{Z}_q$) $\\mathcal{P}$ computes $\\mathsf{Arr_1}'$ as follows: $\\mathsf{Arr_1}'[i]= r - s\\cdot i - \\mathsf{Arr_1}[i]$ $\\mathcal{P}$ computes $\\mathsf{Arr_2}'$ as follows: $\\mathsf{Arr_2}'[i]= r - s\\cdot \\mathsf{Arr_\\pi}[i] - \\mathsf{Arr_2}[i]$ Polynomial Level # We assume that $\\mathsf{Arr_1}$, $\\mathsf{Arr_2}$, and $\\mathsf{Arr_\\pi}[i]$ are encoded as the y-coordinates into a univariant polynomial where the x-coordinates (called the domain $\\mathcal{H}_\\kappa$) are chosen as the multiplicative group of order $\\kappa$ with generator $\\omega\\in\\mathbb{G}_\\kappa$ (see Background for more). In short, $\\omega^0$ is the first element and $\\omega^{\\kappa-1}$ is the last element of $\\mathcal{H}_\\kappa$. If $\\kappa$ is larger than the length of the arrays, the arrays can be padded with elements all of value 1 (or any other value, as long as it is the same for both arrays).\nRecall the two components we want to prove. First, the product check:\n$\\prod^{n-1}_{i = 1}(r - s\\cdot i - \\mathsf{Arr_1}[i]) = \\prod^{n-1}_{i = 1}(r - s\\cdot \\mathsf{Arr_\\pi}[i] - \\mathsf{Arr_2}[i])$\nAs well as the two constraints:\n$\\mathsf{Arr_1}'[i]= r - s\\cdot i - \\mathsf{Arr_1}[i]$ $\\mathsf{Arr_2}'[i]= r - s\\cdot \\mathsf{Arr_\\pi}[i] - \\mathsf{Arr_2}[i]$ The first component is done as a mult3 product check, and we write the second component in polynomial form. From this point on we focus on the polynomial details of the second component.\nFor all $X$ from $\\omega^0$ to $\\omega^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Arr_1'}(X) = r - s\\cdot X - \\mathsf{Poly}_\\mathsf{Arr_1}(X)$ For all $X$ from $\\omega^0$ to $\\omega^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Arr_2'}(X) = r - s\\cdot \\mathsf{Poly_\\pi}(X) - \\mathsf{Poly}_\\mathsf{Arr_2}(X)$ We adjust each of these constraints to show an equality with 0 and label them:\n$\\mathsf{Poly}_\\mathsf{Vanish1}(X)= \\mathsf{Poly}_\\mathsf{Arr_1'}(X) - (r - s\\cdot X - \\mathsf{Poly}_\\mathsf{Arr_1}(X)) = 0$ $\\mathsf{Poly}_\\mathsf{Vanish2}(X)= \\mathsf{Poly}_\\mathsf{Arr_2'}(X) - (r - s\\cdot \\mathsf{Poly_\\pi}(X) - \\mathsf{Poly}_\\mathsf{Arr_2}(X)) = 0$ This equation is true for every value of $X \\in \\mathcal{H}_\\kappa$ (but not necessarily true outside of these values). To show this, we divide each polynomial by $X^\\kappa - 1$, which is a minimal vanishing polynomial for $\\mathcal{H}_\\kappa$ that does not require interpolation to create. If the quotients are polynomials (and not rational functions), then $\\mathsf{Poly}_\\mathsf{Vanish}(X)$ must be vanishing on $\\mathcal{H}_\\kappa$ too. Specifically, the prover computes:\n$Q_1(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish1}(X)}{X^\\kappa - 1}$ $Q_2(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish2}(X)}{X^\\kappa - 1}$ We can replace polynomials $Q_1(X)$ and $Q_2(X)$ with a single polynomial $Q(X)$. We can do this because both constraints have the same format: $\\mathsf{Poly}_\\mathsf{Vanish_i}(X)=0$. The batching technique is to create a new polynomial with both $\\mathsf{Poly}_\\mathsf{Vanish_i}(X)$ values as coefficients. If and (overwhelmingly) only if both are vanishing, then so will the new polynomial. This polynomial will be evaluated at a random challenge point $\\rho$ selected after the commitments to the earlier polynomials are fixed.\n$Q(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish1}(X) + \\mathsf{Poly}_\\mathsf{Vanish2}(X) \\rho}{X^n - 1}$\nBy rearranging, we can get $\\mathsf{Poly}_\\mathsf{Zero}(X)$ as a true zero polynomial (zero at every value both in $\\mathcal{H}_\\kappa$ and outside of it):\n$\\mathsf{Poly}_\\mathsf{Zero}(X)=\\mathsf{Poly}_\\mathsf{Vanish1}(X) + \\rho \\mathsf{Poly}_\\mathsf{Vanish2}(X) - Q(X)\\cdot (X^n - 1)=0$\nUltimately the shuffle1 argument will satisfy the following constraints at the Commitment Level:\nShow $Q(X)$ exists (as a polynomial that evenly divides the divisor) Show $\\mathsf{Poly}_\\mathsf{Zero}(X)$ is correctly constructed from $\\mathsf{Poly}_\\mathsf{Arr}(X)$ Show $\\mathsf{Poly}_\\mathsf{Zero}(X)$ is the zero polynomial In addition, it will show that $\\prod^{n-1}_{i = 1}(X - Y\\cdot i - \\mathsf{Arr_1}[i]) = \\prod^{n-1}_{i = 1}(X - Y\\cdot \\mathsf{Arr_\\pi}[i] - \\mathsf{Arr_2}[i])$ using a mult3 product check.\nCommitment Level # The verifier will never see the arrays or polynomials themselves. They are undisclosed because they either (i) contain private data or (ii) they are too large to examine and maintain a succinct proof system. Instead the prover will use commitments.\nThe prover will create a transcript for the product check, as decribed in mult3. Below, we give details specific to the second component, verifing the two constraints.\nThe prover will write the following commitments to the transcript:\n$K_\\mathsf{Arr_1}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr_1}(X))$ $K_\\mathsf{Arr_2}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr_2}(X))$‚Äã $K_\\pi = \\mathsf{KZG.Commit(Poly_\\pi}(X))$ The prover will generate two random challenge evaluation points (using strong Fiat-Shamir) on the polynomials that is outside of $\\mathcal{H}_\\kappa$. Call these points $r$ and $s$. It will use these points to define the arrays $\\mathsf{Arr_1'} = \\{ r - s\\cdot i - \\mathsf{Arr_1}[i]\\}_{i \\in [0, n-1]}$ and $\\mathsf{Arr_2'} = \\{ r - s\\cdot\\mathsf{Arr_\\pi}[i] - \\mathsf{Arr_2}[i]\\}_{i \\in [0, n-1]}$ and run the product check. It will write the product check into the transcript, but here we focus only on what is relevant to the second component, the points $r$ and $s$, and the following polynomials:\n$r$ $K_\\mathsf{Arr_1'}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr_1'}(X))$ $K_\\mathsf{Arr_2'}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr_2'}(X))$ $K_Q=\\mathsf{KZG.Commit}(Q(X))$ The prover will generate a random challenge evaluation point (using strong Fiat-Shamir) on the polynomials that is outside of $\\mathcal{H}_\\kappa$. Call this point $\\zeta$. The prover will write the point and opening proofs to the transcript:\n$\\zeta$ $\\mathsf{Poly}_\\mathsf{Arr_1}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Arr_1},\\zeta)$ $\\mathsf{Poly}_\\mathsf{Arr_2}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Arr_2},\\zeta)$‚Äã $\\mathsf{Poly_\\pi}(\\zeta) = \\mathsf{KZG.Open}(K_\\pi, \\zeta)$ $\\mathsf{Poly}_\\mathsf{Arr_1'}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Arr_1'},\\zeta)$ $\\mathsf{Poly}_\\mathsf{Arr_2'}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Arr_2'},\\zeta)$ $Q(\\zeta)=\\mathsf{KZG.Open}(K_Q,\\zeta)$ To check the proof, the verifier uses the transcript to construct the value $Y_\\mathsf{Zero}$ as follows:\n$Y_\\mathsf{Vanish1}= \\mathsf{Poly}_\\mathsf{Arr_1'}(\\zeta) - (r - s\\cdot \\zeta - \\mathsf{Poly}_\\mathsf{Arr_1}(\\zeta))$ $Y_\\mathsf{Vanish2}= \\mathsf{Poly}_\\mathsf{Arr_2'}(\\zeta) - (r - s\\cdot \\mathsf{Poly_\\pi}(\\zeta) - \\mathsf{Poly}_\\mathsf{Arr_2}(\\zeta))$ $Y_\\mathsf{Zero}=Y_\\mathsf{Vanish1} + \\rho Y_\\mathsf{Vanish2} - Q(\\zeta)\\cdot (\\zeta^n - 1)$ Finally, if the constraint system is true, the following constraint will be true (and will be false otherwise with overwhelming probability, due to the Schwartz-Zippel lemma on $\\zeta$) :\n$Y_\\mathsf{Zero}\\overset{?}{=}0$ Implementations # Security Proof # Completeness # Any honest prover can do the computations explained above and create an accepting proof.\nSoundness # We prove knowledge soundness in the Algebraic Group Model (AGM). We assume soundness of the product check (it is proven in mult3) and conduct a proof of soundness for the rest of the protocol. To do so, we must prove that there exists an efficient extractor $\\mathcal{E}$ such that for any algebraic adversary $\\mathcal{A}$ the probability of $\\mathcal{A}$ winning the following game is $\\mathsf{negl}(\\lambda)$.\nGiven $[g, g^\\tau, g^{\\tau^2}, \\dots,g^{\\tau^{n-1}}]$ $\\mathcal{A}$ outputs commitments to $\\mathsf{Poly}_\\mathsf{Arr_1}(X)$, $\\mathsf{Poly}_\\mathsf{Arr_2}(X)$, $\\mathsf{Poly_\\pi}$, $\\mathsf{Poly}_\\mathsf{Arr_1'}(X)$, $\\mathsf{Poly}_\\mathsf{Arr_2'}(X)$, $Q$\n$\\mathcal{E}$, given access to $\\mathcal{A}$\u0026rsquo;s outputs from the previous step, outputs $\\mathsf{Poly}_\\mathsf{Arr_1}(X)$, $\\mathsf{Poly}_\\mathsf{Arr_2}(X)$, $\\mathsf{Poly_\\pi}$, $\\mathsf{Poly}_\\mathsf{Arr_1'}(X)$, $\\mathsf{Poly}_\\mathsf{Arr_2'}(X)$, $Q$\n$\\mathcal{A}$ plays the part of the prover in showing that $Y_{\\mathsf{Zero}}$ is zero at a random challenge $\\zeta$\n$\\mathcal{A}$ wins if:\ni) $\\mathcal{V}$ accepts at the end of the protocol\nii) $\\mathsf{Arr}_2 \\neq \\mathsf{Permute}(\\mathsf{Arr}_1 ,\\pi)$\nOur proof is as follows:\nFor the second win condition to be fulfilled, it must be that $(\\mathsf{Arr_\\pi}[i], \\mathsf{Arr_2}[i]) \\neq (i, \\mathsf{Arr_1}[i])$ for some $i \\in [0, n-1]$. But then, $\\mathsf{Arr_1'}$ and $\\mathsf{Arr_2'}$ contain differing element. This means that $\\mathsf{Poly}_\\mathsf{Arr_1'}(X) = \\prod^{n-1}_{i = 1}(X - Y\\cdot i - \\mathsf{Arr_1}[i])$ and $\\mathsf{Poly}_\\mathsf{Arr_2'}(X) = \\prod^{n-1}_{i = 1}(X - Y\\cdot \\mathsf{Arr_\\pi}[i] - \\mathsf{Arr_2}[i])$ and different polynomials, and thus by the Schwartz-Zippel lemma, there is negligible probability that they are equal at $X=r$ and $Y=2$ for the random challenge $r, s$. Any strategy to increase this probability to greater than negligible means $\\mathcal{A}$ must pass in $\\mathsf{Arr_j'}$ for $j = 1$ or $j = 2$ that is not defined according to the its corresponding constraint. But then $\\mathsf{Poly}_\\mathsf{Vanishj}(X)$ is not vanishing on $\\mathcal{H}_\\kappa$, so $Q(X)$ is not a polynomial (it is a rational function). This means that $\\mathcal{A}$ cannot calcuated the correct commitment value $g^{Q(\\tau)}$ without solving the t-SDH. Thus, $\\mathcal{A}$ chooses an arbitrary value for $Q(\\tau)$ and sends $K_Q = g^{Q(\\tau)}$. It also sends a commitment to $\\mathsf{Poly}_\\mathsf{Arr}(X)$. Both commitments $\\mathcal{A}$ has outputted is are linear combinations of the elements in $[g, g^\\tau, g^{\\tau^2}, \\dots,g^{\\tau^{n-1}}]$. $\\mathcal{E}$ is given these coefficients (since $\\mathcal{A}$ is an algebraic adversary) so $\\mathcal{E}$ can output the original polynomials.\n$\\mathcal{A}$ then obtains the random challenge $\\zeta$ (using strong Fiat-Shamir). By the binding property of KZG commitments, $\\mathsf{Poly}_\\mathsf{Arr_1}(\\zeta)$, $\\mathsf{Poly}_\\mathsf{Arr_2}(\\zeta)$, $\\mathsf{Poly_\\pi(\\zeta)}$, $\\mathsf{Poly}_\\mathsf{Arr_1'}(\\zeta)$, and $\\mathsf{Poly}_\\mathsf{Arr_2'}(\\zeta)$ can only feasibliy be opened to one value. For $\\mathcal{A}$ to have the verifier accept, it must send a proof that $Q(\\zeta)$ opens to $Q(\\zeta) = \\frac{Y_\\mathsf{Vanish1} + \\rho Y_\\mathsf{Vanish2}}{(\\zeta^n - 1)}$. This means being able to send $g^{q(\\tau)}$ where $q(\\tau) = \\frac{Q(\\tau) - Q(\\zeta)}{\\tau - \\zeta}$ and $Q(\\zeta) = \\frac{Y_\\mathsf{Vanish1} + \\rho Y_\\mathsf{Vanish2}}{(\\zeta^n - 1)}$. Since $Q(\\tau)$ and $Q(\\zeta)$ are known, this implies knowing $g^{\\frac{1}{\\tau - \\zeta}}$. Thus $\\mathcal{A}$ would have found $\\langle\\zeta,g^{\\frac{1}{\\tau - \\zeta}}\\rangle$, which is the t-SDH problem. We have shown that creating an accepting proof reduces to the t-SDH, so $\\mathcal{A}$\u0026rsquo;s probability of success is negligible.\nZero-Knowledge # We prove that the above protocol is zero-knowledge when $\\mathsf{PolyCommit}_\\mathsf{Ped}$ (from the KZG paper) is used for the polynomial commitments. We assume the product check is zero-knowledge (it is proven in mult3), and conduct a proof for the rest of the protocol. We do so by constructing a probabilistic polynomial time simulator $\\mathcal{S}$ that knows the trapdoor $\\tau$, which, for every (possibly malicious) verifier $\\mathcal{V}$, can output a view of the execution of the protocol that is indistinguishable from the view produced by the real execution of the program.\nThe simulator $\\mathcal{S}$ choose arbitrary values for ${\\mathsf{Poly}_\\mathsf{Arr_1}(\\tau)}$, ${\\mathsf{Poly}_\\mathsf{Arr_2}(\\tau)}$, and $\\mathsf{Poly_\\pi}(\\tau)$, then computes $g^{\\mathsf{Poly}_\\mathsf{Arr_1}(\\tau)}$, $g^{\\mathsf{Poly}_\\mathsf{Arr_2}(\\tau)}$, $g^{\\mathsf{Poly_\\pi}(\\tau)}$ to output as the commitments $ K_\\mathsf{Arr_1}$, $K_\\mathsf{Arr_1}$, $K_\\pi$. $\\mathcal{S}$ then generates $r$ and $s$ as values for the ranom challenge (by strong Fiat-Shamir). It then chooses arbitrary values for ${\\mathsf{Poly}_\\mathsf{Arr_1'}(\\tau)}$ and ${\\mathsf{Poly}_\\mathsf{Arr_2'}(\\tau)}$, then computes $g^{\\mathsf{Poly}_\\mathsf{Arr_1'}(\\tau)}$ and $g^{\\mathsf{Poly}_\\mathsf{Arr_2'}(\\tau)}$ to output as the commitments $ K_\\mathsf{Arr_1'}$ and $K_\\mathsf{Arr_1'}$. It creates a view of the product check as described in the zero-knowledge proof for mult3.\n$\\mathcal{S}$ generates the challenge evaluation point $\\rho$ (by strong Fiat-Shamir) and computes $Q(\\tau)$ using $\\rho$ and the values it chose for ${\\mathsf{Poly}_\\mathsf{Arr_1}(\\tau)}$, ${\\mathsf{Poly}_\\mathsf{Arr_2}(\\tau)}$, $\\mathsf{Poly_\\pi}(\\tau)$, ${\\mathsf{Poly}_\\mathsf{Arr_1'}(\\tau)}$, and ${\\mathsf{Poly}_\\mathsf{Arr_2'}(\\tau)}$. $\\mathcal{S}$ outputs the commitment $K_Q = g^{Q(\\tau)}$.\nNow, $\\mathcal{S}$ generates the second random challenge, $\\zeta$ (which we assume is not in $\\mathcal{H}_\\kappa$; if it is in $\\mathcal{H}_\\kappa$, $\\mathcal{S}$ simply restarts and runs from the beginning). This is once again by strong Fiat-Shamir. $\\mathcal{S}$ then create fake opening proofs for ${\\mathsf{Poly}_\\mathsf{Arr_1}(\\zeta)}$, ${\\mathsf{Poly}_\\mathsf{Arr_2}(\\zeta)}$, $\\mathsf{Poly_\\pi}(\\zeta)$, ${\\mathsf{Poly}_\\mathsf{Arr_1'}(\\zeta)}$, and ${\\mathsf{Poly}_\\mathsf{Arr_2'}(\\zeta)}$, to arbitrary values. This is done using the knowledge of $\\tau$, calculating the respective witness $q(\\tau) = \\frac{{f(\\tau) - f(\\zeta)}}{\\tau - \\zeta}$ for each of the polynomials.\nFinally, $\\mathcal{S}$ creates a fake opening proof for $Q(\\zeta) = \\frac{Y_\\mathsf{Vanish1} + \\rho Y_\\mathsf{Vanish2}}{(\\zeta^n - 1)}$. This is done using knowledge of $\\tau$ to calculate an accepting witness $q(\\tau)$, as above. This means that $Y_\\mathsf{Zero}$ will be zero, and the transcript will be accepted by the verifier. It is indistinguishable from a transcript generates from a real execution, since $\\mathsf{PolyCommit}_\\mathsf{Ped}$ has the property of Indistinguishability of Commitments due to the randomization by $h^{\\hat{\\phi}(x)}$.\n"},{"id":15,"href":"/docs/gadgets/zero1/","title":"Zero1","section":"Gadgets","content":" Zeroing Parts of an Array # Assuming an input array of size $n$: $\\langle \\mathsf{data}_0,\\mathsf{data}_1,\\ldots,\\mathsf{data}_{n-1}\\rangle$ and input array encoded into the polynomial. This uses \u0026ldquo;Encoding 2\u0026rdquo; from above (evaluation points) and uses \u0026ldquo;Roots of Unity + FFT\u0026rdquo; from above where $\\omega\\in\\mathbb{G}_\\kappa$ is a generator for the x-coordinates of the points.\n$\\bot$ is an arbitrary non-zero integer.\nOperation Input Array Input Polynomial Output Array Output Polynomial Zero all $\\langle 3,1,3,3,7 \\rangle$ $P(X)$ $\\langle 0,0,0,0,0 \\rangle$ $P(X)\\cdot(X^\\kappa-1)$ Zero first $\\langle 3,1,3,3,7 \\rangle$ $P(X)$ $\\langle 0,\\bot,\\bot,\\bot,\\bot \\rangle$ $P(X)\\cdot(X-\\omega^0)$ Zero last $\\langle 3,1,3,3,7 \\rangle$ $P(X)$ $\\langle \\bot,\\bot,\\bot,\\bot,0 \\rangle$ $P(X)\\cdot(X-\\omega^{\\kappa-1})$ Zero all but first $\\langle 3,1,3,3,7 \\rangle$ $P(X)$ $\\langle \\bot,0,0,0,0 \\rangle$ $P(X)\\cdot\\frac{(X^\\kappa-1)}{(X-\\omega^0)}$ Zero all but last $\\langle 3,1,3,3,7 \\rangle$ $P(X)$ $\\langle 0,0,0,0,\\bot \\rangle$ $P(X)\\cdot\\frac{(X^\\kappa-1)}{(X-\\omega^{\\kappa-1})}$ Why are these useful? Consider a range proof from Boneh, Fisch, Gabizon, and Williamson. At a certain point in the protocol, we reach the following:\nFirst note that $w$ and $\\omega$ look the same but are different: $w$ are three new polynomials we are creating, while $\\omega$ is the generator of $\\mathbb{G}_\\kappa$ we are using to pick x-coordinates for the polynomials.\nIn the first constraint, we want to prove the value of f(1) and g(1) are the same. So we subtract (g-f) which leaves a zero in the first element of the array but the rest of the array will contain other stuff. By applying \u0026ldquo;zero all but first\u0026rdquo;, we can zero out the rest of the array. We now have an array that is all zero (in polynomial form, this is called a vanishing polynomial and we can prove a polynomial vanishes easily and in a batch). In the second constraint, we prove the last element in g is a binary bit (0 or 1) and then we apply the \u0026ldquo;zero all but last\u0026rdquo; to make an array that is all zero (and vanishing polynomial). In the third constraint, the first two terms of the multiplication are proving $g(X)$ has a certain form that does not need to be understood here. What is important is that there is a relationship between each integer in the array ($g(X)$) and the integer right beside it ($g(X\\omega)$) in the array. When the relationship holds, the result is a zero in $w_3$. Unfortunately, there is a corner case: for the last element in the array, the \u0026ldquo;next\u0026rdquo; integer wraps back to the first integer and the relationship does not hold across this boundary. So we use \u0026ldquo;zero last\u0026rdquo; to manually zero out the last integer in the array, leaving us with a zero array (and vanishing polynomial). "},{"id":16,"href":"/docs/gadgets/zero2/","title":"Zero2","section":"Gadgets","content":"#Zeroing Parts of an Array (2)\nAssume both $\\mathsf{Arr}$ (an array of data) and $\\mathsf{Sel}$ (a binary array) are of size $n$. They are encoded as the y-coordinates into univariant polynomials where the x-coordinates (called the domain $\\mathcal{H}_\\kappa$) are chosen as the multiplicative group of order $\\kappa$ with generator $\\omega\\in\\mathbb{G}_\\kappa$ (see Background for more). In short, $\\omega^0$ is the first element and $\\omega^{\\kappa-1}$ is the last element of $\\mathcal{H}_\\kappa$. We call our polynomials $\\mathsf{Poly}_\\mathsf{Arr}(X)$ and $\\mathsf{Poly}_\\mathsf{Sel}(X)$. The goal is to construct an output polynomial where all the elements in $\\mathsf{Arr}$ that share an index with a zero in $\\mathsf{Sel}$ are zeroed (and non-zero elements in $\\mathsf{Arr}$ that share an index with a one in $\\mathsf{Sel}$ are kept non-zero).\nNote that $\\mathsf{Poly}_\\mathsf{Sel}(X)$ has a root at every point in $\\mathcal{H}_\\kappa$ that corresponds to a zero entry in $\\mathsf{Sel}$, since it has a $y$ value of zero at each of these values of $x$. Denote this set of roots $R = [r_0, r_1, \\dots, r_{m-1}]$, where $m$ is the number of zero entries in $\\mathsf{Sel}$. Denote also $S = [s_0, s_1, \\dots, s_{l-1}]$ the (possibly empty) set of remaining roots of $\\mathsf{Poly}_\\mathsf{Sel}(X)$, for some $l \\in \\mathbb{N}$. Then written in root form we have $\\mathsf{Poly}_\\mathsf{Sel}(X) = \\prod^{i \\lt m}_{i = 0} (X - r_i) \\cdot \\prod^{i \\lt l}_{i=0}(X-s_i)$. We express $\\mathsf{Poly}_\\mathsf{Arr}(X)$ in root form as well, writing: $\\mathsf{Poly}_\\mathsf{Arr}(X) = \\prod^{i \\lt h}_{i=0}(X - t_i)$ for some $h \\in \\mathbb{N}$.\nNow, consider $\\mathsf{Poly}_\\mathsf{Arr}(X) \\cdot \\mathsf{Poly}_\\mathsf{Sel}(X) = \\prod^{i \\lt m}_{i = 0} (X - r_i) \\cdot \\prod^{i \\lt l}_{i=0}(X-s_i) \\cdot \\prod^{i \\lt h}_{i=0}(X-t_i)$. First, note it has roots at each $r \\in R$, thus this new polynomial has zeroed out all the elements of $\\mathsf{Arr}$ corresponding to a zero entries in $\\mathsf{Sel}$. Further, the only other roots it has are from $S$ or from $T = [t_0, t_1,\\dots, t_{h-1}]$. No value $s \\in S$ is also in $\\mathcal{H}_\\kappa$, and $T$ is the set of values that were already roots of $\\mathsf{Poly}_\\mathsf{Arr}$. Thus, all non-zero entries in $\\mathsf{Arr}$ are left non-zero, and $\\mathsf{Poly}_\\mathsf{Arr}(X) \\cdot \\mathsf{Poly}_\\mathsf{Sel}(X)$ is our desired output polynomial.\n"}]