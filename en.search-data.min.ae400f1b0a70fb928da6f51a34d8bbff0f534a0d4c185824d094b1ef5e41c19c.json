[{"id":0,"href":"/2024-Gadgets/docs/background/","title":"Background","section":"Docs","content":"Select a background topic from the menu.\n"},{"id":1,"href":"/2024-Gadgets/docs/background/poly-iop/","title":"Poly Iop","section":"Background","content":" Notes on Polynomial Interactive Oracle Proofs (Draft) # Definitions # Definition 1 (Polynomial Commitment Scheme). A polynomial commitment scheme (PCS) is an interactive proof system that enables $\\mathcal{P}$ to convince $\\mathcal{V}$ that he knows a polynomial, without revealing the polynomial directly. $\\mathcal{P}$ and $\\mathcal{V}$ run the protocol in three moves: gen, com, and open. [Plonk]\nDefinition 2 (Polynomial IOP). Let $\\mathcal{R}$ be a set of the relations among polynomials $\\{P_i\\}$. Let $\\mathcal{C}_f$ is the commitment to $f$. Given common input $\\mathcal{R}(\\{P_i\\})$ to $\\mathcal{P}$ and $\\mathcal{V}$, and private input $\\{P_i\\}$ to $\\mathcal{P}$, they run the following protocol:\n$\\mathcal{P}$ converts the relations into polynomials $\\{Q_j\\}$ $\\mathcal{P}$ commits to $\\{P_i\\}$ and $\\{Q_j\\}$, and sends the commitments to $\\mathcal{V}$ $\\mathcal{V}$ sends a random challenge $\\xi$ $\\mathcal{P}$ runs open for $\\{P_i(\\xi)\\}$ and $\\{Q_j(\\xi)\\}$ and outputs the result $\\mathcal{V}$ checks: the evaluations of $P_i(\\xi)$ and $Q_j(\\xi)$ are correct $\\{Q_j\\}$ satisfy $\\mathcal{R}(\\{P_i\\})$ At the end of the protocol, $\\mathcal{V}$ outputs $\\textbf{acc}$ if and only if the two conditions hold, otherwise $\\textbf{rej}$.\nMoreover, a Poly-IOP has to satisfy the following properties.\nDefinition 3 (Completeness). If each pair of $(\\mathcal{C}_{P_i},P_i)$ and $(\\mathcal{C}_{Q_j},Q_j)$ is valid and $\\{Q_j\\}$ satisfy $\\mathcal{R}(\\{P_i\\})$, $\\text{Pr}[out_{\\mathcal{V}}=\\textbf{acc}]=1$.\nDefinition 4 (Soundness). If $(\\mathcal{C}_{P_i},P_i)$ or $(\\mathcal{C}_{Q_j},Q_j)$ are not a valid pair, or $\\{Q_j\\}$ does not satisfy $\\mathcal{R}(\\{P_i\\})$, $\\text{Pr}[out_{\\mathcal{V}}=\\textbf{rej}]\\ge{1-\\text{negl}(k)}$.\nDefinition 5 (Zero Knowledge). For every possible set of relations $\\mathcal{R}$, there exists a probabilistic polynomial time simulator $\\mathcal{S}$ that can produce $\\{\\mathcal{C}_{P_i}^*\\},\\{\\mathcal{C}_{Q_i}^*\\}$ and the corresponding proofs making $\\mathcal{V}$ output $\\textbf{acc}$; the proofs generated by $\\mathcal{S}$ are computationally indistinguishable from those produced by $\\mathcal{P}$.\nEncoding Arrays of Data into Polynomials # Data starts as a array of integers where integers in each slot are between 0 and $q-1$, where $q$ is a large (generally 256 bit) prime number. Recall that we call this set of integers $\\mathbb{Z}_q$.\n$\\mathsf{data}_0$ $\\mathsf{data}_1$ $\\mathsf{data}_2$ $\\mathsf{data}_3$ $\\mathsf{data}_4$ It is common to denote a polynomial like $P(X)$ where $X$ is the variable of the polynomial. We are going denote the variable with an empty box $\\square$ which can be interpreted as a place where you can put any integer in $\\mathbb{Z}_q$ you want evaluated (or equivalent, where you place an x-coordinate to learn what the y-coordinate is).\nA polynomial in this notation looks like:\n$P(\\square)=c_0+c_1\\cdot\\square+c_2\\cdot\\square^2+c_3\\cdot\\square^3+c_4\\cdot\\square^4=\\sum_{i=0}^d c_i\\cdot\\square^i$ The values $c_i$ are called coefficients. Different arrays of data will (depending on how data is encoded, next) result in different coefficients and thus different polynomials. The degree of the polynomial is the largest exponent. So the polynomial above has degree 4 and thus will have 5 coefficients and 5 terms of the form $c_i\\cdot\\square^i$ (including $i=0$). Sometimes the coefficient will be zero: the term is thus not written down but in a list of coefficients, it will be included as a 0.\nThe main question to tackle is how to \u0026ldquo;encode\u0026rdquo; a array of integers into a polynomial. This is generally done one of three ways:\nCoefficients Evaluation Points Roots Each has its advantages and disadvantages, which we discuss next.\nFast forwarding a bit, once the polynomial is created, it is not shared directly with anyone. Instead a commitment to it is shared. The commitment does two things: (1) it makes it succinct: e.g., constant size regardless of how long the array is; and (2) it can hide the data in the array as necessary. We will discuss one specific polynomial commitment scheme called KZG. KZG needs the polynomial in the format of a list of its coefficients. If we have the polynomial in a different form, we will have to convert to coefficients. Thus this needs to be considered when weighing the pros/cons of the three encoding methods.\nEncoding 1: Coefficients # Create polynomial as: $P_1(\\square)=\\mathsf{data}_0+\\square+\\mathsf{data}_2\\cdot\\square^2+\\mathsf{data}_3\\cdot\\square^3+\\mathsf{data}_4\\cdot\\square^4=\\sum_{i=0}^d \\mathsf{data}_i\\cdot\\square^i$\nProperties:\nFast üëç: fastest path to commitment as the output is already in coefficient form. Addition üëç: two arrays can be added together (slot-by-slot) by simply adding the polynomials together Multiplication üëé: no support for multiplication of arrays (Remark: multiplying the polynomials does not multiply the coefficients. It results in a cross multiplication of every term in the first polynomial with every term in the second polynomial. Further the degree of the resulting polynomial will double that of the starting polynomials). Opening ü§∑üèª: proving the value of the $i$th element in the array is $\\mathsf{data}_i$ doing polynomial math on $P_1(\\square)$ is not possible. However $\\Sigma$-protocols done directly on KZG may enable this kind of proof. In any case, this is not particularly well explored. Other useful properties üëç: the sum of all values in a array can be computed by evaluating the polynomial at $P_1(\\boxed{1})$! $\\sum_{i=0}^d \\mathsf{data}_i\\cdot\\boxed{1}^i=\\sum_{i=0}^d \\mathsf{data}_i$ . You can also show two arrays have the same sum (called a \u0026ldquo;sum check\u0026rdquo;) by subtracting them and showing $P(\\boxed{1})=0$. Other useful properties üëç: when all coefficients are 0, the polynomial will be the zero polynomial ($P_1(\\square)=0$). Coefficients can be entire polynomials, not just integers. A common optimization in Poly-IOP systems is taking a set of equations of polynomials that should equal 0, placing each into the coefficient of a super-polynomial, and showing the super-polynomial is the zero polynomial (which can be proven overwhelmingly by showing it is 0 at a randomly selected point). Encoding 2: Evaluation Points # Create a list of points $\\{x,y\\}$ for the data: $\\langle\\{0,\\mathsf{data}_0\\},\\{1,\\mathsf{data}_1\\},\\{2,\\mathsf{data}_2\\},\\{3,\\mathsf{data}_3\\},\\{4,\\mathsf{data}_4\\}\\rangle$ and interpolate a polynomial $P_2(\\square)$ through these points.\nProperties:\nSlow (or moderate) üëé: converting a set of points into a set of coefficients is called interpolation and is $O(n^2)$ time generally. A certain optimization allows $O(n\\log n)$ time by chosing $x$ coordinates with a mathematical relationship (more on this later). Addition üëç: two arrays can be added together (slot-by-slot) by simply adding the polynomials together Multiplication üëç: two arrays can be multiplied together (slot-by-slot) by simply multiplying the polynomials together Opening üëç: proving the value of the $i$th element in the array is $\\mathsf{data}_i$ is possible with polynomial math by showing $P_2(\\boxed{i})=\\mathsf{data}_i$ and KZG has a precise algorithm for this. Encoding 3: Roots # Create polynomial as: $P_3(\\square)=(\\square-\\mathsf{data}_0)(\\square-\\mathsf{data}_1)(\\square-\\mathsf{data}_2)(\\square-\\mathsf{data}_3)(\\square-\\mathsf{data}_4)$\nAlternatively, create a list of roots $\\{x,0\\}$ for the data: $\\langle\\{\\mathsf{data}_0,0\\},\\{\\mathsf{data}_1,0\\},\\{\\mathsf{data}_2,0\\},\\{\\mathsf{data}_3,0\\},\\{\\mathsf{data}_4,0\\}\\rangle$ and interpolate a polynomial $P_3(\\square)$ through these points.\nProperties:\nSlow üëé (or moderate): multiplying out naively requires $O(n^2)$ time. Treating as a set of points and interpolating also requires $O(n^2)$ time (because the x-coordinates are the data, they cannot be chosen freely to optimize interpolation). Applying divide and conquer can provide $O(n \\log^2 n)$.^[1] Addition üëé: two arrays cannot be added from adding (or otherwise manipulating) the polynomials. Multiplication üëé: two arrays cannot be multiplied from multiplying (or otherwise manipulating) the polynomials (but you can do a \u0026ldquo;union\u0026rdquo; operation below). Opening üëç: proving that a value is in the array somewhere is easy and KZG as a precise algorithm for this (opening a root is the same as opening a point, where the y-coordinate is 0). However you cannot show a value is specifically the $i$th value in the array because the polynomial loses the order of the data in the array (see next property). Other useful properties üëç: the order of the data in the array does not matter. The same polynomial will be produced even if the order is changed. This is useful when the array represents a \u0026ldquo;bag\u0026rdquo; of unordered data. You can easily prove two \u0026ldquo;bags\u0026rdquo; of data are the same because the polynomials will be the same. One use-case of this is proving the output of a shuffle/permutation is the same data as the input (just in a different order). Other useful properties üëç: multiplying two polynomials results in a concatenation of the data in the arrays (or conjunction/union of the data in both bags). This might be useful in some protocols. ^[1]: Hat tip Pratyush Mishra.\nDecision Tree for Encoding # Basically we decide if we specifically need unordered \u0026ldquo;bags\u0026rdquo; of data. If so, encoding as roots is the only option. If not, we consider if we need to ever get the data back from the polynomial. Generally we do and encoding as evaluation points is the most common encoding technique. When do we encode the data and never want it back? Usually when (1) the coefficients are all supposed to be zero so we are just showing that property, or (2) we want back the sum of the data and not the data itself. In these cases, you can still work with evaluation point encoding but it will be faster to just do coefficient encoding.\nflowchart LR; A[Array to Polynomial] --\u003e B{Is the data unordered?}; B -- Unordered --\u003e C[Roots]; B -- Ordered or don't care --\u003e D{Open data from polynomial later?}; D -- Yes --\u003e E[Evaluation Points]; D -- No --\u003e F[Coefficients]; The short answer is to start with evaluation point encoding until you realize you need something different.\nOptimizing Interpolation (Roots of Unity + FFT) # Moving forward, we will assume we are using Encoding 2: Evaluation Points. In short, this means placing the elements of our array into the $y$-coordinates ($\\mathsf{data}_i=P(\\boxed{x_i})$) of points on the polynomial. Before commiting to $P(\\square)$, we need to use interpolation to find the coefficients of the polynomial that is fitted to these points. General interpolation algorithms are $O(n^2)$ work for $n$ evaluation points but this can be reduced to $O(n\\log n)$ with an optimization.\nThe optimization we will explore enables interpolation via the fast Fourier transform (FFT). It concerns how to choose the $x$-coordinates, which will serve as the index for accessing the data: evaluating $P(X)$ at $x_i$ will reveal $\\mathsf{data}_i$. First note, $x$-coordinates are from the exponent group ($Z_q$) and the choices exceed what is feasible to use ($2^{255}$ values in bls). Any subset can be used and interpolated. The optimization is to chose them with a mathematical structure. Specifically, instead an additive sequence (e.g., $0,1,2,3,\\ldots$), we use a multiplicative sequence $1,\\omega,\\omega\\cdot\\omega,\\omega\\cdot\\omega\\cdot\\omega,\\ldots$ or equivalently: $\\omega^0,\\omega^1,\\omega^2,\\ldots,\\omega^{\\kappa-1}$. Further, the sequence is closed under multiplication which means that next index after $\\omega^{\\kappa-1}$ wraps back to the first index: $\\omega^{k-1} \\cdot \\omega = \\omega^\\kappa = \\omega^0=1$ (this property is also useful in proving relationships between data in the array and its neighbouring values).\nFor terminology, we say $\\omega$ is a generator with multiplicative order $\\kappa$ in $\\mathbb{Z}_q$ (or $\\omega \\in \\mathbb{G}_\\kappa$). This implies $\\omega^\\kappa=1$. Rearranging, $\\omega=\\sqrt[\\kappa]{1}$. Thus we can equivalently describe $\\omega$ as a $\\kappa$-th root of 1. Finally, as 1 is the unity element in $Z_q$, $\\omega$ is commonly called a $\\kappa$-th root of unity.\nFor practical purposes, $\\kappa$ represents the length of the longest array of data we can use in our protocol. Where does $\\kappa$ come from? Different elements of $Z_q$ will have different multiplicative orders but every order must be a divisor of $q-1$. Thus $\\kappa$ is the largest divisor of the exact value of $q$ used in an elliptic curve standard. BLS12-384 has $\\kappa=2^{32}$ (for terminology, this called a $2$-adicity of $32$). In summary, we can only encode data arrays of length up to $2^{32}=4,294,967,296$.\nZeroing Parts of an Array # Assuming an input array of size $n$: $\\langle \\mathsf{data}_0,\\mathsf{data}_1,\\ldots,\\mathsf{data}_{n-1}\\rangle$ and input array encoded into the polynomial. This uses \u0026ldquo;Encoding 2\u0026rdquo; from above (evaluation points) and uses \u0026ldquo;Roots of Unity + FFT\u0026rdquo; from above where $\\omega\\in\\mathbb{G}_\\kappa$ is a generator for the x-coordinates of the points.\n$\\bot$ is an arbitrary non-zero integer.\nOperation Input Array Input Polynomial Output Array Output Polynomial Zero all $\\langle 3,1,3,3,7 \\rangle$ $P(X)$ $\\langle 0,0,0,0,0 \\rangle$ $P(X)\\cdot(X^n-1)$ Zero first $\\langle 3,1,3,3,7 \\rangle$ $P(X)$ $\\langle 0,\\bot,\\bot,\\bot,\\bot \\rangle$ $P(X)\\cdot(X-\\omega^0)$ Zero last $\\langle 3,1,3,3,7 \\rangle$ $P(X)$ $\\langle \\bot,\\bot,\\bot,\\bot,0 \\rangle$ $P(X)\\cdot(X-\\omega^{n-1})$ Zero all but first $\\langle 3,1,3,3,7 \\rangle$ $P(X)$ $\\langle \\bot,0,0,0,0 \\rangle$ $P(X)\\cdot\\frac{(X^n-1)}{(X-\\omega^0)}$ Zero all but last $\\langle 3,1,3,3,7 \\rangle$ $P(X)$ $\\langle 0,0,0,0,\\bot \\rangle$ $P(X)\\cdot\\frac{(X^n-1)}{(X-\\omega^{n-1})}$ Why are these useful? Consider a range proof from Boneh, Fisch, Gabizon, and Williamson. At a certain point in the protocol, we reach the following:\nFirst note that $w$ and $\\omega$ look the same but are different: $w$ are three new polynomials we are creating, while $\\omega$ is the generator of $\\mathbb{G}_\\kappa$ we are using to pick x-coordinates for the polynomials.\nIn the first constraint, we want to prove the value of f(1) and g(1) are the same. So we subtract (g-f) which leaves a zero in the first element of the array but the rest of the array will contain other stuff. By applying \u0026ldquo;zero all but first\u0026rdquo;, we can zero out the rest of the array. We now have an array that is all zero (in polynomial form, this is called a vanshing polynomial and we can prove a polynomial vanishes easily and in a batch). In the second constraint, we prove the last element in g is a binary bit (0 or 1) and then we apply the \u0026ldquo;zero all but last\u0026rdquo; to make an array that is all zero (and vanishing polynomial). In the third constraint, the first two terms of the multiplication are proving $g(X)$ has a certain form that does not need to be understood here. What is important is that there is a relationship between each integer in the array ($g(X)$) and the integer right beside it ($g(X\\omega)$) in the array. When the relationship holds, the result is a zero in $w_3$. Unfortunately, there is a corner case: for the last element in the array, the \u0026ldquo;next\u0026rdquo; integer wraps back to the first integer and the relationship does not hold across this boundary. So we use \u0026ldquo;zero last\u0026rdquo; to manually zero out the last integer in the array, leaving us with a zero array (and vanishing polynomial). Additional Text to Merge # The prover interpolates $A$ and $B$ to get $P_A(x)$ and $P_B(x)$. To do so, an $n$th root of unity (which we will call $\\omega$) is used, and the values of $A$ and $B$ are paired with the powers of this root of unity as follows: $(\\omega^0, a_0), (\\omega^1, a_1), \\dots, (\\omega^{n-1}, a_{n-1})$ and similarly for $B$. Then the interpolation (using the fast fourier transform (FFT)) creates a polynomial that passes through the points represented by these tuples. We also define $H$ as the set $[\\omega^0, \\omega^1, \\dots, \\omega^{n-1}]$. We are assuming that $n$ is a power of 2, so that we can use FFT. In practice, if it is not, then a power of 2 greater than $n$, say $2^m$, is used and the last $2^m - n$ entries of $A$ are padded with 1s.\n"},{"id":2,"href":"/2024-Gadgets/docs/gadgets/","title":"Gadgets","section":"Docs","content":"Select a gadget from the menu.\n"},{"id":3,"href":"/2024-Gadgets/docs/gadgets/mult2/","title":"Mult2","section":"Gadgets","content":" Multiplication (Type 2) # Recap of types # Type Description Recap This mult1 $\\mathsf{Arr}_3=\\mathsf{Arr}_1 \\cdot \\mathsf{Arr}_2$ $\\mathsf{Arr}_3$ is the element-wise multiplication of $\\mathsf{Arr}_1$ and $\\mathsf{Arr}_2$. mult2 $\\mathsf{Prod}_\\mathsf{Arr}=\\prod_{i = 0}^{n-1} \\mathsf{Arr}[i]$ $\\mathsf{Prod}_\\mathsf{Arr}$ is the disclosed product of all the elements in $\\mathsf{Arr}$. ‚úÖ mult3 $\\prod_{i = 0}^{n-1} \\mathsf{Arr}_1[i]=\\prod_{i = 0}^{n-1} \\mathsf{Arr}_2[i]$ $\\mathsf{Arr}_1$ and $\\mathsf{Arr}_2$ have the same undisclosed product. Relation # $ \\mathcal{R}_{\\mathtt{mult2}} := \\left\\{ \\begin{array}{l} (K_\\mathsf{Arr},\\mathsf{Prod}_\\mathsf{Arr}) \\end{array} \\middle | \\begin{array}{l} \\mathsf{Arr} = [a_0, a_1, a_2, \\dots, a_{n-1}], \\\\ \\mathsf{Prod}_\\mathsf{Arr} = \\prod_{i = 0}^{n-1} a_i, \\\\ \\mathsf{Poly}_\\mathsf{Arr}=\\mathsf{FFT.Interp}(\\omega,\\mathsf{Arr}), \\\\ K_\\mathsf{Arr}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr}) \\end{array} \\right\\} $\nIntuition # The prover ($\\mathcal{P}$) holds an array $\\mathsf{Arr} = [a_0, a_1, a_2, \\dots, a_{n-1}]$ of $n$ integers (from $\\mathbb{Z}_q$) and a disclosed integer $\\mathsf{Prod}_\\mathsf{Arr}$. It will produce a succinct (independent of $n$) proof that $\\mathsf{Prod}_\\mathsf{Arr}$ is the product of all the elements in the array. The prover will encode the array into a polynomial $\\mathsf{Poly}_\\mathsf{Arr}$ (using evaluation points) and commit to the polynomial $K_\\mathsf{Arr}$. The verifier ($\\mathcal{V}$) cannot check $\\textsf{Arr}$ or $\\mathsf{Poly}_\\mathsf{Arr}$ directly (they may contain secret information, and even if they do not, it is too long to check) so the verifier only sees $K_\\mathsf{Arr}$ and the asserted value $\\mathsf{Prod_\\mathsf{Arr}}$.\nIn order to prove $K_\\mathsf{Arr}$ and $\\mathsf{Prod}_\\mathsf{Arr}$ are consistent, the prover will build a helper array $\\mathsf{Acc}_\\mathsf{Arr}$ called an accumulator (or accumulating array or incremental array). This should not be confused with accumulators from cryptography, which are a concept related to succinct proofs but are distinct. As with $\\mathsf{Arr}$, the prover will also encode $\\mathsf{Acc}$ as a polynomial and provide a commitment of it to the verifier. The idea is that the prover will prove a relation between $\\mathsf{Arr}$ and $\\mathsf{Acc}$; and a relation between $\\mathsf{Acc}$ and $\\mathsf{Prod_\\mathsf{Arr}}$. Put together, it will imply the correct relation between $\\mathsf{Arr}$ and $\\mathsf{Prod_\\mathsf{Arr}}$.\nConsider a small numeric example in $\\mathbb{Z}_{97}$ where $\\mathsf{Arr}= [84,67,11,92,36,67]$ and $\\mathsf{Prod}_\\mathsf{Arr}=72$. The first idea is to get $\\mathsf{Prod}_\\mathsf{Arr}$ into an array. Say, we just append it: $\\mathsf{Arr}''= [84,67,11,92,36,67,72] $. How does the prover show $\\mathsf{Arr}''$ is correct? The last value of the array depends on every single element that precedes it, which will be a complex constraint to prove.\nAn alternative idea is to create a new array that starts the same as $\\mathsf{Arr}$ and ends up at $\\mathsf{Prod}_\\mathsf{Arr}$ by folding in the integers from $\\mathsf{Arr}$ one-by-one with multiplication. Then each value in the new array will depend on only two values, as below.\nThe first value in $\\mathsf{Acc}$ will be a copy of the first value from $\\mathsf{Arr}$:\n$\\mathsf{Arr}= [84,67,11,92,36,67]$\n$\\mathsf{Acc}= [84, \\bot,\\bot,\\bot,\\bot,\\bot] $\nThe next value will be the multiplication (mod 97) of: 67 (the value at the same index in $\\mathsf{Arr}$) and 84 (the previous value in $\\mathsf{Acc}$):\n$\\mathsf{Arr}= [84,67,11,92,36,67]$\n$ \\mathsf{Acc} = [84, (67\\cdot84),\\bot,\\bot,\\bot,\\bot] = [84, 2,\\bot,\\bot,\\bot,\\bot]$\nThe next value will be the multiplication of: 11 (the value at the same index in $\\mathsf{Arr}$) and 2 (the previous value in $\\mathsf{Acc}$):\n$\\mathsf{Arr}= [84,67,11,92,36,67]$ $ \\mathsf{Acc} = [84, 2,(11\\cdot2),\\bot,\\bot,\\bot] = [84,2,22,\\bot,\\bot,\\bot]$ $ \\mathsf{Acc} = [84, 2,22,(92\\cdot22),\\bot,\\bot] = [84,2,22,84,\\bot,\\bot]$ $ \\mathsf{Acc} = [84, 2,22,84,(36\\cdot84),\\bot] = [84,2,22,84,17,\\bot]$ $ \\mathsf{Acc} = [84,2,22,84,17,(67\\cdot17)] = [84, 2, 22, 84, 17, 72]$ $\\mathsf{Prod}_\\mathsf{Arr}=72$ Notice the last value in $\\mathsf{Acc}$ is $\\mathsf{Prod_\\mathsf{Arr}}$. The prover wants to show three constraints:\nThe first value in $\\mathsf{Acc}$ matches the first value in $\\mathsf{Arr}$, The rest of the values in $\\mathsf{Acc}$ are of the form $\\mathsf{Acc}[i]=\\mathsf{Arr}[i]\\cdot\\mathsf{Acc}[i-1]$, The last value in $\\mathsf{Acc}$ matches $\\mathsf{Prod}_\\mathsf{Arr}$. If all three constraints are true, then $\\mathsf{Prod}_\\mathsf{Arr}$ is the product of the elements of $\\mathsf{Arr}$.\nLast, while it is not necessary to do, it is often convenient to hold the the value $\\mathsf{Prod}_\\mathsf{Arr}$ at the start of the array $\\mathsf{Acc}$ instead of the end. For this reason, the mathematical explaination below will construct $\\mathsf{Acc}$ \u0026ldquo;backwards\u0026rdquo; (or right-to-left) from the above example, where the last value of $\\mathsf{Acc}$ matches the last value of $\\mathsf{Arr}$, the values are folded in from right to left, and the first (leftmost) value of $\\mathsf{Acc}$ is $\\mathsf{Prod}_\\mathsf{Arr}$:\n$\\mathsf{Arr}= [84,67,11,92,36,67]$ $ \\mathsf{Acc} = [\\bot, \\bot, \\bot, \\bot, \\bot, 67]$ $ \\mathsf{Acc} = [\\bot, \\bot, \\bot, \\bot, 84, 67]$ $\\ldots$ $ \\mathsf{Acc} = [72, 84, 36, 65, 84, 67]$ $\\mathsf{Prod}_\\mathsf{Arr}=72$ Protocol Details # Array Level # $\\mathcal{P}$ holds an array $\\mathsf{Arr} = [a_0, a_1, a_2, \\dots, a_{n-1}]$ of $n$ integers ($a_i \\in \\mathbb{Z}_q$) $\\mathcal{P}$ computes array $\\mathsf{Acc}$ as follows: $\\mathsf{Acc}[n-1]\\leftarrow\\mathsf{Arr}[n-1]$ $\\mathsf{Acc}[i]\\leftarrow\\mathsf{Arr}[i]\\cdot\\mathsf{Acc}[i+1]$ for $i$ from $n-2$ to 0 $\\mathcal{P}$ computes $\\mathsf{Prod}_\\mathsf{Arr}\\leftarrow\\mathsf{Acc}[0]$ Polynomial Level # We assume arrays $\\mathsf{Arr}$ and $\\mathsf{Acc}$ are encoded as the y-coordinates into a univariant polynomial where the x-coordinates (called the domain $\\mathcal{H}_\\kappa$) are chosen as the multiplicative group of order $\\kappa$ with generator $\\omega\\in\\mathbb{G}_\\kappa$ (see Background for more). In short, $\\omega^0$ is the first element and $\\omega^{\\kappa-1}$ is the last element of $\\mathcal{H}_\\kappa$. If $\\kappa$ is larger than the length of the array, the array can be padded with elements of value 1 (which will not change the product).\nRecall the three constraints we want to prove:\nThe first value in $\\mathsf{Acc}$ matches the first value in $\\mathsf{Arr}$, The rest of the values in $\\mathsf{Acc}$ are of the form $\\mathsf{Acc}[i]=\\mathsf{Arr}[i]\\cdot\\mathsf{Acc}[i-1]$, The last value in $\\mathsf{Acc}$ matches $\\mathsf{Prod}_\\mathsf{Arr}$. In polynomial form, the constraints are:\nFor $X=w^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Acc}(X)=\\mathsf{Poly}_\\mathsf{Arr}(X)$, For all $X$ except $X=\\omega^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Acc}(X)=\\mathsf{Poly}_\\mathsf{Arr}(X)\\cdot\\mathsf{Poly}_\\mathsf{Acc}(\\omega\\cdot X)$ For $X=w^0$: $\\mathsf{Poly}_\\mathsf{Acc}(X)=\\mathsf{Prod}_\\mathsf{Arr}$ In constraint 2, $\\mathsf{Poly}_\\mathsf{Acc}(\\omega\\cdot X)$ can also be conceptualized as rotate applied to $\\mathsf{Poly}_\\mathsf{Acc}(X)$ by one element (rightward in the array view). Also note that constraint 2 does not hold at $X=\\omega^{\\kappa-1}$ because this value is defined by constraint 1 (for the last value of $X$, the \u0026ldquo;next\u0026rdquo; value, $\\omega X$, wraps back to the first element of the array which is a boundary condition).\nWe adjust each of these constraints to show an equality with 0:\nFor $X=w^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Acc}(X)-\\mathsf{Poly}_\\mathsf{Arr}(X)=0$, For all $X$ except $X=\\omega^{\\kappa-1}$: $\\mathsf{Poly}_\\mathsf{Acc}(X)-\\mathsf{Poly}_\\mathsf{Arr}(X)\\cdot\\mathsf{Poly}_\\mathsf{Acc}(\\omega\\cdot X)=0$ For $X=w^0$: $\\mathsf{Poly}_\\mathsf{Acc}(X)-\\mathsf{Prod}_\\mathsf{Arr}=0$ Next we take care of the \u0026ldquo;for $X$\u0026rdquo; conditions by zeroing out the rest of the polynomial that is not zero. See the gadget zero1 for more on why this works.\n$\\mathsf{Poly}_\\mathsf{Vanish1}(X)=(\\mathsf{Poly}_\\mathsf{Acc}(X)-\\mathsf{Poly}_\\mathsf{Arr}(X))\\cdot\\frac{(X^\\kappa-1)}{(X-\\omega^{\\kappa-1})}=0$, $\\mathsf{Poly}_\\mathsf{Vanish2}(X)=(\\mathsf{Poly}_\\mathsf{Acc}(X)-\\mathsf{Poly}_\\mathsf{Arr}(X)\\cdot\\mathsf{Poly}_\\mathsf{Acc}(\\omega\\cdot X))\\cdot(X-\\omega^{\\kappa-1})=0$ $\\mathsf{Poly}_\\mathsf{Vanish3}(X)=(\\mathsf{Poly}_\\mathsf{Acc}(X)-\\mathsf{Prod}_\\mathsf{Arr})\\cdot\\frac{(X^\\kappa-1)}{(X-\\omega^0)}=0$ These equations are true for every value of $X \\in \\mathcal{H}_\\kappa$ (but not necessarily true outside of these values). To show this, we divide each polynomial by $X^\\kappa - 1$, which is a minimal vanishing polynomial for $\\mathcal{H}_\\kappa$ that does not require interpolation to create. If the quotients are polynomials (and not rational functions), then $\\mathsf{Poly}_\\mathsf{Vanish1}(X)$, $\\mathsf{Poly}_\\mathsf{Vanish2}(X)$, and $\\mathsf{Poly}_\\mathsf{Vanish2}(X)$ must be vanishing on $\\mathcal{H}_\\kappa$ too. Specifically, the prove computes,\n$Q_1(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish1}(X)}{X^\\kappa - 1}$ $Q_2(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish2}(X)}{X^\\kappa - 1}$ $Q_3(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish3}(X)}{X^\\kappa - 1}$‚Äã‚Äã We can replace polynomials $Q_1(X)$, $Q_2(X)$, and $Q_3(X)$ with a single polynomial $Q(X)$. We can do this because all three constraints have the same format: $\\mathsf{Poly}_\\mathsf{Vanish_i}(X)=0$. The batching technique is to create a new polynomial with all three $\\mathsf{Poly}_\\mathsf{Vanish_i}(X)$ values as coefficients. If and (overwhelmingly) only if all three are vanishing, then so will the new polynomial. This polynomial will be evaluated at a random challenge point $\\rho$ selected after the commitments to the earlier polynomials are fixed.\n$Q(X) = \\frac{\\mathsf{Poly}_\\mathsf{Vanish1}(X) + \\mathsf{Poly}_\\mathsf{Vanish2}(X) \\rho + \\mathsf{Poly}_\\mathsf{Vanish3}(X)\\rho^2}{X^n - 1}$\nBy rearranging, we can get $\\mathsf{Poly}_\\mathsf{Zero}(X)$ as a true zero polynomial (zero at every value both in $\\mathcal{H}_\\kappa$ and outside of it):\n$\\mathsf{Poly}_\\mathsf{Zero}(X)=\\mathsf{Poly}_\\mathsf{Vanish1}(X) + \\rho \\mathsf{Poly}_\\mathsf{Vanish2}(X) + \\rho^2 \\mathsf{Poly}_\\mathsf{Vanish3}(X) - Q(X)\\cdot (X^n - 1)=0$‚Äã‚Äã‚Äã\nUltimately the mult2 argument will satisfy the following constraints at the Commitment Level:\nShow $Q(X)$‚Äã exists (as a polynomial that evenly divides the divisor) Show $\\mathsf{Poly}_\\mathsf{Zero}(X)$ is correctly constructed from $\\mathsf{Poly}_\\mathsf{Acc}(X)$, $\\mathsf{Poly}_\\mathsf{Acc}(\\omega X)$, $\\mathsf{Poly}_\\mathsf{Arr}(X)$, and $\\mathsf{Prod}_\\mathsf{Arr}$ Show $\\mathsf{Poly}_\\mathsf{Zero}(X)$ is the zero polynomial Commitment Level # The verifier will never see the arrays or polynomials themselves. They are undisclosed because they either (i) contain private data or (ii) they are too large to examine and maintain a succinct proof system. Instead the prover will use commitments.\nThe prover will write the following commitments to the transcript:\n$K_\\mathsf{Arr}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Arr}(X))$‚Äã $K_\\mathsf{Acc}=\\mathsf{KZG.Commit}(\\mathsf{Poly}_\\mathsf{Acc}(X))$‚Äã‚Äã The prover will generate a random challenge evaluation point (using strong Fiat-Shamir) on the polynomial that is outside of $\\mathcal{H}_\\kappa$. Call this point $\\rho$. It will be used by the prover to create polynomial $Q(X)$ (see above) and the prover will write to the transcript:\n$\\rho$ $K_Q=\\mathsf{KZG.Commit}(Q(X))$ The prover will generate a second random challenge evaluation point (using strong Fiat-Shamir) on the polynomial that is outside of $\\mathcal{H}_\\kappa$. Call this point $\\zeta$. The prover will write the three points and opening proofs to the transcript:\n$\\zeta$ $\\mathsf{Poly}_\\mathsf{Arr}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Arr},\\zeta)$‚Äã $\\mathsf{Poly}_\\mathsf{Arr}(\\zeta\\omega)=\\mathsf{KZG.Open}(K_\\mathsf{Arr},\\zeta\\omega)$ $\\mathsf{Poly}_\\mathsf{Acc}(\\zeta)=\\mathsf{KZG.Open}(K_\\mathsf{Acc},\\zeta)$‚Äã $Q(\\zeta)=\\mathsf{KZG.Open}(K_Q,\\zeta)$ To check the proof, the verifier uses the transcript to construct the value $Y_\\mathsf{Zero}$ as follows:\n$Y_\\mathsf{Vanish1}=(\\mathsf{Poly}_\\mathsf{Acc}(\\zeta)-\\mathsf{Poly}_\\mathsf{Arr}(\\zeta))\\cdot\\frac{(\\zeta^\\kappa-1)}{(\\zeta-\\omega^{\\kappa-1})}$ $Y_\\mathsf{Vanish2}=(\\mathsf{Poly}_\\mathsf{Acc}(\\zeta)-\\mathsf{Poly}_\\mathsf{Arr}(\\zeta)\\cdot\\mathsf{Poly}_\\mathsf{Acc}(\\omega\\cdot \\zeta))\\cdot(\\zeta-\\omega^{\\kappa-1})$ $Y_\\mathsf{Vanish3}=(\\mathsf{Poly}_\\mathsf{Acc}(\\zeta)-\\mathsf{Prod}_\\mathsf{Arr})\\cdot\\frac{(\\zeta^\\kappa-1)}{(\\zeta-\\omega^0)}$‚Äã $Y_\\mathsf{Zero}=Y_\\mathsf{Vanish1} + \\rho Y_\\mathsf{Vanish2} + \\rho^2 Y_\\mathsf{Vanish3} - Q(\\zeta)\\cdot (\\zeta^n - 1)$‚Äã‚Äã Finally, if the constraint system is true, the following constraint will be true (and will be false otherwise with overwhelming probability, due to the Schwartz-Zippel lemma on $\\rho$ and $\\zeta$) :\n$Y_\\mathsf{Zero}\\overset{?}{=}0$ Implementations # Rust Mathematica (Toy Example) Security Proof # Completeness # Any honest verifier can do the computations explained above and create a successful proof. Soundness # We show that the probability that an adversarial prover $P$ can convince a verifier $V$ that $a), \\space b), \\space c)$ hold while conditions $1, 2$, or $3$ do not, is negligible. If any of the conditions (WLOG $1$) do not hold, then (WLOG) $Q_1$ is not a polynomial (instead it is a rational function). This means that $P$ cannot create a valid commitment to it, so when $P$ sends $Com(Q_1)$ it is simply choosing a value (but this value does not have the properties of a real commitment in relation to the \u0026ldquo;polynomial\u0026rdquo; it is a commitment to). Then same is true for $Q_1(u)$ and $q(\\tau)$ in the opening proof. Thus, creating a valid opening proof for $Q_1(u)$ becomes equivalent to the t-BSDH. Then $P$‚Äã‚Äã\u0026rsquo;s probability of success is negligible. $P$ select values for the \u0026ldquo;commitments\u0026rdquo; of $\\mathsf{Poly}_\\mathsf{Acc}(\\zeta), \\mathsf{Poly}_\\mathsf{Arr}(\\zeta), Q_1(\\zeta), Q_2(\\zeta),$ $Q_3(\\zeta)$, and $\\mathsf{Poly}_\\mathsf{Acc}(\\zeta \\cdot \\omega)$ such that the three equalities hold. As above, WLOG we look at $Q_1$, so $\\mathsf{Poly}_\\mathsf{Arr}(\\zeta) - \\mathsf{Poly}_\\mathsf{Acc}(\\zeta) = (\\zeta - \\omega^{k-1}) \\cdot Q_1(\\zeta)$ must hold. $P$ is then tasked with finding $g^{q(\\tau)}$ where $q(\\tau) = \\frac{Q_1(\\tau) - Q_1(\\zeta)}{\\tau - \\zeta}$ such that the evaluation proof is accepting, i.e. $e(g,g)^{Q_1(\\tau) - Q_1(\\zeta)}= e(g,g)^{(\\tau - \\zeta)q(\\tau)}$. This is the same as finding $e(g,g)^{\\frac{Q_1(\\tau) - Q_1(\\zeta)}{\\tau - \\zeta}}$, and since $Q_1(\\tau)$ and $Q_1(\\zeta)$ are known, this implies knowing $e(g,g)^{\\frac{1}{\\tau - \\zeta}}$. Thus, the prover has found $\\langle \\zeta, e(g,g)^{\\frac{1}{\\tau - \\zeta}}$‚Äã, which is the t-BSDH problem. Note that we could have tried to my $Q_1$ depend on what makes the opening proof hold, but then we end up with a set value for $\\mathsf{Poly}_\\mathsf{Arr}(\\zeta)$ or $\\mathsf{Poly}_\\mathsf{Acc}(\\zeta)$, and the same issue and producing an accepting evalutation proof would appear there. Thus we assume that $\\mathsf{Poly}_\\mathsf{Arr}(\\zeta)$ and $\\mathsf{Poly}_\\mathsf{Acc}(\\zeta)$‚Äã are set (and allow them to have accepting evaluation proofs) and show we cannot achieve an accepting transcript for the entire protocol Should I show how using with the ability described above $P$ would enable one to construct an algortihm that break t-BSDH? Zero-Knowledge # Here we used $\\mathsf{PolyCommit}_\\mathsf{Ped}$ (from the KZG paper) is used for our commitments The simulator $S$ generates an array $\\mathsf{Arr'}$ whose product is equal to the disclosed value $\\mathsf{Prod}_\\mathsf{Arr}$ (this array could just have $\\mathsf{Prod}_\\mathsf{Arr}$ in one entry, and $1$\u0026rsquo;s elsewhere), then follows the same steps a prover would to prove the product of this array. So, $S$ computes the accumulator $\\mathsf{Acc'}$ and interpolates the two arrays into there respective polynomials, $\\mathsf{Poly}_\\mathsf{Acc}(X)$ and $\\mathsf{Poly}_\\mathsf{Arr}(X)$. It computes $Q_1$, $Q_2$, and $Q3$ using $\\mathsf{Poly}_\\mathsf{Acc}(X)$ and $\\mathsf{Poly}_\\mathsf{Arr}(X)$. It commits to each of these five polynomials, then hashes the commitments to get the random challenge $\\zeta'$. It then sends creates commitments to $\\mathsf{Poly}_\\mathsf{Acc}(\\zeta'), \\mathsf{Poly}_\\mathsf{Arr}(\\zeta'), Q_1(\\zeta'), Q_2(\\zeta'),$ $Q_3(\\zeta')$, and $\\mathsf{Poly}_\\mathsf{Acc}(\\zeta' \\cdot \\omega)$, as well as a proof that each of these commitments is correct. The transcript it generates this way will be indistinguishable from a transcript generated from a real execution, since $\\mathsf{PolyCommit}_\\mathsf{Ped}$ has the property of Indistinguishability of Commitments due to the randomization by $h^{\\hat{\\phi}(x)}$‚Äã. (This is the specific version of KZG commitments used in the zk adjustment). Could also define a simulator that know $\\tau$ and thus can create a passing witness for any commitment, would also have an indistinguishable transcript, again because of the indistinguishability of commitments that $\\mathsf{PolyCommit}_\\mathsf{Ped}$ has Here is my previous (unsuccessful) attempt at a simulator. I\u0026rsquo;ve left it in case the above attempt is incorrect and we need to work with a more complicated simulator using rewinding, in which case perhaps the ideas below are still useful.\nWe define a simulator $S$ which selects a random value $\\zeta'$ and compute commitments to $\\mathsf{Poly}_\\mathsf{Acc}(X)$, $\\mathsf{Poly}_\\mathsf{Arr}(X)$, $Q_1$, $Q_2$, and $Q3$ as well as $\\mathsf{Poly}_\\mathsf{Acc}(\\zeta'), \\mathsf{Poly}_\\mathsf{Arr}(\\zeta'), Q_1(\\zeta'), Q_2(\\zeta'),$ $Q_3(\\zeta')$, and $\\mathsf{Poly}_\\mathsf{Acc}(\\zeta' \\cdot \\omega)$ such that the three equalities $a), b),$ and $c)$ above hold and each polynomial correctly opens to it\u0026rsquo;s evaluation at $\\zeta$. It then hashes the commitments to the five polynomials to get the random challenge $\\zeta$; if $\\zeta' \\neq \\zeta$, then it rewinds and selects a new random value $\\zeta'$. Expected number of iterations to get a random value $\\zeta'$ such that $\\zeta' = \\zeta$ is $| \\mathbb{F} |$, so we rewind and run it up to $| \\mathbb{F} |$ times (or $n \\cdot | \\mathbb{F} |$) times for some value $n$?). It outputs fail if it has not succeeded in generating $\\zeta'$ such that $\\zeta' = \\zeta$ by then. Thus it terminates after at most $| \\mathbb{F} |$ iterations (or $n \\cdot |\\mathbb{F}|$ iterations?) and it fails with negligible probability. The distribution for the view from this simulation is (perfectly? computationally?) indistinguishable from that of a real execution (when we use Pedersen commitments to make it zk), since Pedersen commmitments are perfectly hiding. "},{"id":4,"href":"/2024-Gadgets/docs/gadgets/zero1/","title":"Zero1","section":"Gadgets","content":" Zeroing Parts of an Array # Assuming an input array of size $n$: $\\langle \\mathsf{data}_0,\\mathsf{data}_1,\\ldots,\\mathsf{data}_{n-1}\\rangle$ and input array encoded into the polynomial. This uses \u0026ldquo;Encoding 2\u0026rdquo; from above (evaluation points) and uses \u0026ldquo;Roots of Unity + FFT\u0026rdquo; from above where $\\omega\\in\\mathbb{G}_\\kappa$ is a generator for the x-coordinates of the points.\n$\\bot$ is an arbitrary non-zero integer.\nOperation Input Array Input Polynomial Output Array Output Polynomial Zero all $\\langle 3,1,3,3,7 \\rangle$ $P(X)$ $\\langle 0,0,0,0,0 \\rangle$ $P(X)\\cdot(X^\\kappa-1)$ Zero first $\\langle 3,1,3,3,7 \\rangle$ $P(X)$ $\\langle 0,\\bot,\\bot,\\bot,\\bot \\rangle$ $P(X)\\cdot(X-\\omega^0)$ Zero last $\\langle 3,1,3,3,7 \\rangle$ $P(X)$ $\\langle \\bot,\\bot,\\bot,\\bot,0 \\rangle$ $P(X)\\cdot(X-\\omega^{\\kappa-1})$ Zero all but first $\\langle 3,1,3,3,7 \\rangle$ $P(X)$ $\\langle \\bot,0,0,0,0 \\rangle$ $P(X)\\cdot\\frac{(X^\\kappa-1)}{(X-\\omega^0)}$ Zero all but last $\\langle 3,1,3,3,7 \\rangle$ $P(X)$ $\\langle 0,0,0,0,\\bot \\rangle$ $P(X)\\cdot\\frac{(X^\\kappa-1)}{(X-\\omega^{\\kappa-1})}$ Why are these useful? Consider a range proof from Boneh, Fisch, Gabizon, and Williamson. At a certain point in the protocol, we reach the following:\nFirst note that $w$ and $\\omega$ look the same but are different: $w$ are three new polynomials we are creating, while $\\omega$ is the generator of $\\mathbb{G}_\\kappa$ we are using to pick x-coordinates for the polynomials.\nIn the first constraint, we want to prove the value of f(1) and g(1) are the same. So we subtract (g-f) which leaves a zero in the first element of the array but the rest of the array will contain other stuff. By applying \u0026ldquo;zero all but first\u0026rdquo;, we can zero out the rest of the array. We now have an array that is all zero (in polynomial form, this is called a vanshing polynomial and we can prove a polynomial vanishes easily and in a batch). In the second constraint, we prove the last element in g is a binary bit (0 or 1) and then we apply the \u0026ldquo;zero all but last\u0026rdquo; to make an array that is all zero (and vanishing polynomial). In the third constraint, the first two terms of the multiplication are proving $g(X)$ has a certain form that does not need to be understood here. What is important is that there is a relationship between each integer in the array ($g(X)$) and the integer right beside it ($g(X\\omega)$) in the array. When the relationship holds, the result is a zero in $w_3$. Unfortunately, there is a corner case: for the last element in the array, the \u0026ldquo;next\u0026rdquo; integer wraps back to the first integer and the relationship does not hold across this boundary. So we use \u0026ldquo;zero last\u0026rdquo; to manually zero out the last integer in the array, leaving us with a zero array (and vanishing polynomial). "}]